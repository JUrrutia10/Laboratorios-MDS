{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyPTffTLug7i"
      },
      "source": [
        "**<h1><center>Laboratorio 11: LLM y Agentes Aut√≥nomos ü§ñ</center></h1>**\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "737a4540885f41acb34b9863a968b907",
        "deepnote_cell_type": "markdown",
        "id": "UD8X1uhGzAHq"
      },
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesor: Ignacio Meza, Sebastian Tinoco\n",
        "- Auxiliar: Catherine Benavides, Consuelo Rojas\n",
        "- Ayudante: Eduardo Moya, Nicol√°s Ojeda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e4a6f26138654eb49ee963fb4c7ecf46",
        "deepnote_cell_type": "markdown",
        "id": "tXflExjqzAHr"
      },
      "source": [
        "### **Equipo:**\n",
        "\n",
        "- Nombre de alumno 1: Manuel Zamorano\n",
        "- Nombre de alumno 2: Javier Urrutia\n",
        "\n",
        "**SUPER IMPORTANTE** - notebooks sin nombre no ser√°n revisados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7dd4aaebd4f44063aedbb47ea36349a5",
        "deepnote_cell_type": "markdown",
        "id": "AD-V0bbZzAHr",
        "owner_user_id": "badcc427-fd3d-4615-9296-faa43ec69cfb"
      },
      "source": [
        "### **Link de repositorio de GitHub:** `https://github.com/JUrrutia10/Laboratorios-MDS`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "abe08e51696a471e8cc8ac1fa4216f0b",
        "deepnote_cell_type": "markdown",
        "id": "EcnsiQMkzAHr"
      },
      "source": [
        "### **Indice**\n",
        "\n",
        "1. [Temas a tratar](#Temas-a-tratar:)\n",
        "3. [Descripcci√≥n del laboratorio](#Descripci√≥n-del-laboratorio.)\n",
        "4. [Desarrollo](#Desarrollo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0174e9377ebb43eaa0d12718db4c81ec",
        "deepnote_cell_type": "markdown",
        "id": "6uBLPj1PzAHs"
      },
      "source": [
        "## **Temas a tratar**\n",
        "\n",
        "- Implementaci√≥n de modelos de LLM y Reinforcement Learning.\n",
        "- Utilizaci√≥n e implementaci√≥n de agentes.\n",
        "\n",
        "## **Reglas:**\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: 7 d√≠as desde la publicaci√≥n, 3 d√≠as de atraso con 1 punto de descuento c/u.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria.\n",
        "- Prohibidas las copias. Cualquier intento de copia ser√° debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est√©n en u-cursos no ser√°n revisados. Recuerden que el repositorio tambi√©n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "Pueden usar cualquer material del curso que estimen conveniente.\n",
        "\n",
        "### **Objetivos principales del laboratorio**\n",
        "\n",
        "- Generar un modelo LLM generativo interactivo.\n",
        "- Entrenar un modelo de Reinforce Learning.\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is4P4NDMurx6"
      },
      "source": [
        "## **1. Large Language Models (4.0 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ3yV96HwN75"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://trestristescriticos.com/wp-content/uploads/2021/07/telefono-gratuito-cinesur.jpg\" width=\"350\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB8z1qrGww4o"
      },
      "source": [
        "Joaqu√≠n no es un aficionado del cine, pero a principios de a√±o, se propuso ver m√°s peliculas para poder tener m√°s temas de conversaci√≥n con sus amigos y familia. Sin embargo, ya es junio y Joaqu√≠n no ha visto ninguna pelicula nueva o relevante de las que ten√≠a en su lista y su reuni√≥n familiar bi-anual se acerca y necesita la mayor informaci√≥n que pueda recopilar de dichas peliculas sin tener que verlas.\n",
        "\n",
        "Para esto, usted con su compa√±erx, tendr√° que crear una aplicaci√≥n utilizando LangChain.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOIeEP9Ey_lF"
      },
      "source": [
        "**Instalaci√≥n de librer√≠as**\n",
        "\n",
        "Para la creaci√≥n de la aplicaci√≥n, se utilizara un modelo de lenguaje (LLM) ofrecido gratuitamente por Google.\n",
        "\n",
        "Para ello, se utilizar√° la API de Gemini, por lo que si no tienen acceso, se pueden crear una cuenta en el siguiente [enlace a Google AI](https://ai.google.dev/). Ah√≠, ir a la pesta√±a superior y seleccione la opci√≥n que dice ``Gemini API``.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.42.32_PM.png' width='450' />\n",
        "\n",
        "Luego, seleccione el bot√≥n que dice ``Get API key in Google AI Studio`` y hacer click en ``Crear clave de API`` para generar la llave con la que se podr√° consultar al modelo de lenguaje.\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-06-13_at_12.45.10_PM.png?ref_type=heads' width='450' />\n",
        "\n",
        "**Importante:** Debido a las restricciones de esta API, lo ideal es utilizar la llave a la API de manera personal.\n",
        "\n",
        "\n",
        "Para mayor informaci√≥n sobre **LangChain**, pueden revisar la documentaci√≥n en el [presente enlace](https://python.langchain.com/v0.2/docs/tutorials/summarization/ )."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LLbYWURudw2c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain\n",
        "!pip install langchain_google_genai\n",
        "!pip install langchain-community\n",
        "!pip install langchain-experimental\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "82aJnnH0b0Oo"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = #aqui va el key de api\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUgbzVtWUYq2"
      },
      "source": [
        "### **1.1 Carga y limpieza (0.5 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I10Li9a7nez"
      },
      "source": [
        "Para iniciar su titanica tarea de ense√±arle a Joaqu√≠n sobre las mejores peliculas del √∫ltimo tiempo, tiene que revisar los script de las siguientes 3 peliculas:\n",
        "* Dune 2\n",
        "* Under Paris\n",
        "* Joker\n",
        "Debe encontrar un patr√≥n y obtener solamente el gui√≥n de las pel√≠culas. Para ello se recomienda utilizar m√©todos de b√∫squeda y reemplazo que tienen los ``string`` en Python. Adicionalmente, puede usar filtros de expresiones regulares.\n",
        "\n",
        "Posterior a la limpieza de los guiones, debe considerar que el patr√≥n se repite y es generalizable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HpYuwfO_F0pD"
      },
      "outputs": [],
      "source": [
        "# Scripts de peliculas\n",
        "dune2_script=\"https://scrapsfromtheloft.com/movies/dune-part-two-2024-transcript/\"\n",
        "underparis_script=\"https://scrapsfromtheloft.com/movies/under-paris-2024-transcript/\"\n",
        "joker_script=\"https://scrapsfromtheloft.com/movies/joker-2019-transcript/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tT_Z3owKyqZf"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "def load_website_data(url):\n",
        "    \"\"\"\n",
        "    Carga el contenido de un sitio web dado una URL.\n",
        "    \"\"\"\n",
        "    loader = WebBaseLoader(url)\n",
        "    data = loader.load()\n",
        "    website_data = data[0].page_content if data else \"\"\n",
        "    return website_data\n",
        "\n",
        "def clean_script(text, start_marker=\"[\"):\n",
        "    \"\"\"\n",
        "    Limpia el texto para obtener solo el gui√≥n de la pel√≠cula.\n",
        "    \"\"\"\n",
        "    # Encontrar el inicio del gui√≥n (usando un marcador espec√≠fico)\n",
        "    start_pattern = re.compile(re.escape(start_marker))\n",
        "    start_marker_match = start_pattern.search(text)\n",
        "    start_index = start_marker_match.start() if start_marker_match else 0\n",
        "\n",
        "    # Eliminar contenido innecesario despu√©s del gui√≥n\n",
        "    end_marker = re.search(r\"\\bSHARE THIS ARTICLE\\b\", text, re.IGNORECASE)\n",
        "    end_index = end_marker.start() if end_marker else len(text)\n",
        "\n",
        "    # Recortar el texto para obtener solo el gui√≥n\n",
        "    text_cleaned = text[start_index:end_index].strip()\n",
        "\n",
        "    return text_cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1O67NVYs0t7",
        "outputId": "20e901a0-a198-41c7-d162-9628085a8e3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[male voice in alien language] Power over Spice is power over all\n",
            "[suspenseful music playing]\n",
            "[Irulan] Imperial Diary. Year 10,191. Third comment. The battle for Arrakis took everyone by surprise. There were no witnesses.\n",
            "[somber music playing]\n",
            "The Harkonnen operation was perpetrated overnight, without warning or declaration of war. By morning, the Atreides were no more. All died in the dark.\n",
            "And the Emperor said‚Ä¶ nothing. Since that night, my father has not been the same. Nor have I. His inacti\n"
          ]
        }
      ],
      "source": [
        "# Cargar el contenido de los guiones\n",
        "dune2 = load_website_data(dune2_script)\n",
        "underparis = load_website_data(underparis_script)\n",
        "joker = load_website_data(joker_script)\n",
        "\n",
        "# Limpiar el texto para obtener solo el gui√≥n\n",
        "dune2_script_clean = clean_script(dune2)\n",
        "underparis_script_clean = clean_script(underparis)\n",
        "joker_script_clean = clean_script(joker)\n",
        "\n",
        "# Imprimir una muestra del gui√≥n limpio de Dune 2\n",
        "print(dune2_script_clean[:500])  # Mostrar los primeros 500 caracteres del gui√≥n limpio para ver el resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toysrYqR2Wl9",
        "outputId": "07d35228-e0c9-4283-ebfb-18e7e7516404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " heavily]\n",
            "[stomps]\n",
            "[inhales deeply]\n",
            "My Lord, the Great Houses have answered.\n",
            "They refuse to honor your ascendancy.\n",
            "We await your orders, Lisan al-Gaib.\n",
            "Lead them to Paradise.\n",
            "[female Fremen] Lisan al-Gaib!\n",
            "[all chanting] Lisan al-Gaib! Lisan al-Gaib!\n",
            "[speaking Chakobsa]\n",
            "[all chanting] Lisan al-Gaib! Lisan al-Gaib!\n",
            "[Alia] What is happening, Mother?\n",
            "Your brother attacks the Great Houses.\n",
            "The Holy War begins.\n",
            "[breathing heavily]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "More:\n",
            "\n",
            "Denis Villeneuve, Dune: Part Two, Movie Transcripts\n"
          ]
        }
      ],
      "source": [
        "print(dune2_script_clean[-500:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Btad-nZ9EyS"
      },
      "source": [
        "### **1.2 Aplicaci√≥n (3.5 puntos)**\n",
        "\n",
        "Luego de limpiar los guiones, es posible generar la aplicaic√≥n deseada con el LLM. Esta aplicaci√≥n tiene que ser capaz de realizar las siguientes tareas.\n",
        "\n",
        "1. Utilizando una plantilla sobre el nombre del archivo o la URL, identifique el supuesto nombre de la pel√≠cula.\n",
        "\n",
        "2. Genere un resumen en espa√±ol de la pel√≠cula y una nota evaluativa sobre la misma. El resumen debe tener entre 3 a 5 p√°rrafos. Adem√°s, obtener una evaluaci√≥n de la pel√≠cula con una calificaci√≥n del 1 al 10, utilizando una LLM y el contexto entregado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcS80oN2-Gq4"
      },
      "source": [
        "#### **1.2.1 T√≠tulo de la pel√≠cula (0.5 puntos)**\n",
        "\n",
        "Para obtener el t√≠tulo, utilic√© la siguiente plantilla:\n",
        "```\n",
        " template = \"\"\"\n",
        "  What is the movie that appears in the description of this file or url?\n",
        "  You only give me the movie name, nothing more.\n",
        "  document/url: {script_path_url}\n",
        "  \"\"\"\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yNIU3mmh-F5W"
      },
      "outputs": [],
      "source": [
        "# Plantilla para obtener el t√≠tulo de la pel√≠cula\n",
        "template = \"\"\"\n",
        "What is the movie that appears in the description of this file or url?\n",
        "You only give me the movie name, nothing more.\n",
        "document/url: {script_path_url}\n",
        "\"\"\"\n",
        "\n",
        "def get_movie_title(script_path_url):\n",
        "    \"\"\"\n",
        "    Utiliza el modelo de lenguaje para obtener el t√≠tulo de la pel√≠cula\n",
        "    basado en la plantilla y la URL del gui√≥n.\n",
        "    \"\"\"\n",
        "    # Completar la plantilla con la URL del gui√≥n\n",
        "    prompt = template.format(script_path_url=script_path_url)\n",
        "\n",
        "    # Generar la respuesta utilizando el modelo de lenguaje\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    # Limpiar y obtener el t√≠tulo de la pel√≠cula de la respuesta generada\n",
        "    movie_title = response.content\n",
        "\n",
        "    return movie_title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "R6eydsZc5MK7",
        "outputId": "02e7ea7d-b1de-48d7-df99-f63676318622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Movie title: Dune: Part Two \n",
            "\n"
          ]
        }
      ],
      "source": [
        "movie_title = get_movie_title(dune2_script)\n",
        "print(\"Movie title:\", movie_title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Movie title: Under Paris \n",
            "\n"
          ]
        }
      ],
      "source": [
        "movie_title = get_movie_title(underparis_script)\n",
        "print(\"Movie title:\", movie_title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Movie title: Joker \n",
            "\n"
          ]
        }
      ],
      "source": [
        "movie_title = get_movie_title(joker_script)\n",
        "print(\"Movie title:\", movie_title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muDXLfr0CabX"
      },
      "source": [
        "#### **1.2.2 Resumen (1.0 puntos)**\n",
        "\n",
        "Como se vi√≥ en clases, las LLM no pueden manejar cadenas de texto muy largas, esto es debido a que, dependiendo de su naturaleza, solo manejan ventanas de contexto que estan asociadas a caracteristicas de la red y del entrenamiento utilizado.\n",
        "\n",
        "Por ello, es altamente importante que si se desea hacer un resumen del texto, este se haga realizando un tipo de map/reduce sobre el texto. De manera que en cada una de las iteraciones se vaya disminuyendo el tama√±o del texto, pero hay que tener cuidado con que le modelo vaya guardando el contexto de escenas previas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "9sxX87HpDZiV"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
        "from langchain.chains import StuffDocumentsChain, LLMChain\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "HsEJR0IGEZ8V"
      },
      "outputs": [],
      "source": [
        "# crear templates\n",
        "\n",
        "map_template_summary = \"\"\"\n",
        "Genera un resumen de la pel√≠cula basado en el guion proporcionado:\n",
        "{script}\n",
        "\"\"\"\n",
        "\n",
        "reduce_template_summary = \"\"\"\n",
        "Reduce el resumen anterior para hacerlo m√°s conciso:\n",
        "{script_resume}\n",
        "\"\"\"\n",
        "\n",
        "# Respuesta final del resumen\n",
        "answer_summary = \"\"\"\n",
        "Resumen de la pel√≠cula:\n",
        "{summary}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [],
      "source": [
        "def map_reduce_text(script_imput, map_template, reduce_template):\n",
        "\n",
        "\n",
        "    \n",
        "    document_prompt = PromptTemplate(\n",
        "    input_variables=[\"script\"],\n",
        "    template=map_template\n",
        "    )\n",
        "    document_variable_name = \"script_resume\"\n",
        "\n",
        "    # The prompt here should take as an input variable the\n",
        "    # `document_variable_name`\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        template=reduce_template\n",
        "    )\n",
        "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    chain = StuffDocumentsChain(\n",
        "        llm_chain=llm_chain,\n",
        "        document_prompt=document_prompt,\n",
        "        document_variable_name=document_variable_name\n",
        "    )\n",
        "    \n",
        "    # Map/Reduce\n",
        "    \"\"\"\n",
        "    Utilizar MapReduceDocumentsChain\n",
        "    \"\"\"\n",
        "    reduce_documents_chain = ReduceDocumentsChain(\n",
        "    combine_documents_chain=chain,\n",
        "    )\n",
        "    MRchain = MapReduceDocumentsChain(\n",
        "        llm_chain=llm_chain,\n",
        "        reduce_documents_chain=reduce_documents_chain,\n",
        "    )\n",
        "\n",
        "    # Text splitter\n",
        "    \"\"\"\n",
        "    Usar RecursiveCharacterTextSplitter\n",
        "    \"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "    split_script = text_splitter.split_text(script_imput)\n",
        "\n",
        "    # Resultado\n",
        "    result = MRchain({\"input_documents\": split_script})\n",
        "\n",
        "    return result[\"output_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'page_content'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[158], line 13\u001b[0m\n\u001b[0;32m      3\u001b[0m map_template_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124mGenera un resumen de la pel√≠cula basado en el guion proporcionado:\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;132;01m{script}\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      7\u001b[0m reduce_template_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124mReduce el resumen anterior para hacerlo m√°s conciso:\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;132;01m{script_resume}\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 13\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mmap_reduce_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_template_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_template_summary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResumen de la pel√≠cula:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msummary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[157], line 43\u001b[0m, in \u001b[0;36mmap_reduce_text\u001b[1;34m(script_imput, map_template, reduce_template)\u001b[0m\n\u001b[0;32m     40\u001b[0m split_script \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_text(script_imput)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Resultado\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mMRchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_documents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_script\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:168\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     emit_warning()\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\langchain\\chains\\base.py:383\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    376\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    381\u001b[0m }\n\u001b[1;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\langchain\\chains\\base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
            "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\langchain\\chains\\base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:137\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[0;32m    136\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[1;32m--> 137\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_keys\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
            "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\langchain\\chains\\combine_documents\\map_reduce.py:228\u001b[0m, in \u001b[0;36mMapReduceDocumentsChain.combine_docs\u001b[1;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_docs\u001b[39m(\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    216\u001b[0m     docs: List[Document],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    220\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Combine documents in a map reduce manner.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m    Combine by mapping first chain over all documents, then reducing the results.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m    This reducing can be done recursively if needed (if there are many documents).\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     map_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;66;03m# FYI - this is parallelized and so it is fast.\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m         \u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocument_variable_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[0;32m    229\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    230\u001b[0m     )\n\u001b[0;32m    231\u001b[0m     question_result_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39moutput_key\n\u001b[0;32m    232\u001b[0m     result_docs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    233\u001b[0m         Document(page_content\u001b[38;5;241m=\u001b[39mr[question_result_key], metadata\u001b[38;5;241m=\u001b[39mdocs[i]\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;66;03m# This uses metadata from the docs, and the textual results from `results`\u001b[39;00m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(map_results)\n\u001b[0;32m    236\u001b[0m     ]\n",
            "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\langchain\\chains\\combine_documents\\map_reduce.py:228\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_docs\u001b[39m(\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    216\u001b[0m     docs: List[Document],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    220\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Combine documents in a map reduce manner.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m    Combine by mapping first chain over all documents, then reducing the results.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m    This reducing can be done recursively if needed (if there are many documents).\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     map_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;66;03m# FYI - this is parallelized and so it is fast.\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m         [{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocument_variable_name: \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs} \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m docs],\n\u001b[0;32m    229\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    230\u001b[0m     )\n\u001b[0;32m    231\u001b[0m     question_result_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39moutput_key\n\u001b[0;32m    232\u001b[0m     result_docs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    233\u001b[0m         Document(page_content\u001b[38;5;241m=\u001b[39mr[question_result_key], metadata\u001b[38;5;241m=\u001b[39mdocs[i]\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;66;03m# This uses metadata from the docs, and the textual results from `results`\u001b[39;00m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(map_results)\n\u001b[0;32m    236\u001b[0m     ]\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
          ]
        }
      ],
      "source": [
        "# Ejemplo de uso\n",
        "script = \"This is a sample movie script...\"\n",
        "map_template_summary = \"\"\"\n",
        "Genera un resumen de la pel√≠cula basado en el guion proporcionado:\n",
        "{script}\n",
        "\"\"\"\n",
        "reduce_template_summary = \"\"\"\n",
        "Reduce el resumen anterior para hacerlo m√°s conciso:\n",
        "{script_resume}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "summary = map_reduce_text(script, map_template_summary, reduce_template_summary)\n",
        "print(f\"Resumen de la pel√≠cula:\\n{summary}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [],
      "source": [
        "def map_reduce_text(script, map_template, reduce_template):\n",
        "\n",
        "    \n",
        "    document_prompt = PromptTemplate(\n",
        "    input_variables=[\"script\"],\n",
        "     template=map_template\n",
        "    )\n",
        "    document_variable_name = \"context\"\n",
        "    # The prompt here should take as an input variable the\n",
        "    # `document_variable_name`\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        template=reduce_template\n",
        "    )\n",
        "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    # We now define how to combine these summaries\n",
        "    reduce_prompt = PromptTemplate.from_template(\n",
        "        template=reduce_template\n",
        "    )\n",
        "    reduce_llm_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
        "    combine_documents_chain = StuffDocumentsChain(\n",
        "        llm_chain=reduce_llm_chain,\n",
        "        document_prompt=document_prompt,\n",
        "        document_variable_name=document_variable_name\n",
        "    )\n",
        "    reduce_documents_chain = ReduceDocumentsChain(\n",
        "        combine_documents_chain=combine_documents_chain,\n",
        "    )\n",
        "    chain = MapReduceDocumentsChain(\n",
        "        llm_chain=llm_chain,\n",
        "        reduce_documents_chain=reduce_documents_chain,\n",
        "    )\n",
        "\n",
        "    # Invocar el proceso de Map/Reduce sobre el texto\n",
        "    result = chain({\"input_documents\": script})\n",
        "\n",
        "    return result[\"output_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#No cambiar funci√≥n\n",
        "\n",
        "def map_reduce_text(script, map_template, reduce_template):\n",
        "    # Crear el prompt para el Map\n",
        "    map_prompt = PromptTemplate(input_variables=[\"script\"],template=map_template)\n",
        "    map_chain = LLMChain(prompt=map_prompt)\n",
        "    \n",
        "\n",
        "    # Crear el prompt para el Reduce\n",
        "    reduce_prompt = PromptTemplate(template=reduce_template, input_variables=[\"script_resume\"])\n",
        "    reduce_chain = LLMChain(reduce_prompt)\n",
        "\n",
        "    # Combinar y reducir los documentos usando StuffDocumentsChain y ReduceDocumentsChain\n",
        "    combine_chain = StuffDocumentsChain(ReduceDocumentsChain(reduce_chain), max_tokens=4000)\n",
        "\n",
        "    # Utilizar MapReduceDocumentsChain\n",
        "    map_reduce_chain = MapReduceDocumentsChain(map_chain, combine_chain)\n",
        "\n",
        "    # Dividir el texto utilizando RecursiveCharacterTextSplitter\n",
        "    text_splitter = RecursiveCharacterTextSplitter()\n",
        "    split_script = text_splitter(script)\n",
        "\n",
        "    # Invocar el proceso de Map/Reduce sobre el texto\n",
        "    result = map_reduce_chain.invoke(split_script)\n",
        "\n",
        "    return result[\"output_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "nDQneeFM9Mqw"
      },
      "outputs": [],
      "source": [
        "def evaluate_movie(script, evaluation_template):\n",
        "    # Crear el prompt para la evaluaci√≥n\n",
        "    evaluation_prompt = PromptTemplate(template=evaluation_template)\n",
        "    evaluation_chain = LLMChain(prompt=evaluation_prompt,llm=llm)\n",
        "\n",
        "    # Generar la evaluaci√≥n utilizando la LLM\n",
        "    evaluation_response = evaluation_chain.run({\"script\": script})\n",
        "    \n",
        "    return evaluation_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "ZvxEZywW9635"
      },
      "outputs": [],
      "source": [
        "# Plantilla para la evaluaci√≥n de la pel√≠cula\n",
        "evaluation_template = \"\"\"\n",
        "Eval√∫a la pel√≠cula en una escala del 1 al 10, basada en el guion proporcionado:\n",
        "{script}, solo dando la nota final\n",
        "\"\"\"\n",
        "\n",
        "# Respuesta final de la evaluaci√≥n\n",
        "answer_evaluation = \"\"\"\n",
        "Evaluaci√≥n de la pel√≠cula: {evaluation}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "ijib42GaIFSI",
        "outputId": "48ae0cd3-978f-4ec8-a370-23c0324617d6"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'llm_chain'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[140], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# imprimir resumenes de pel√≠culas.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Generar resumen para Dune 2\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m dune2_summary \u001b[38;5;241m=\u001b[39m \u001b[43mmap_reduce_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdune2_script_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_template_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_template_summary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer_summary\u001b[38;5;241m.\u001b[39mformat(summary\u001b[38;5;241m=\u001b[39mdune2_summary))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluar pel√≠culas\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[139], line 13\u001b[0m, in \u001b[0;36mmap_reduce_text\u001b[1;34m(script, map_template, reduce_template)\u001b[0m\n\u001b[0;32m     10\u001b[0m reduce_chain \u001b[38;5;241m=\u001b[39m LLMChain(prompt\u001b[38;5;241m=\u001b[39mreduce_prompt, llm\u001b[38;5;241m=\u001b[39mllm)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Configurar ReduceDocumentsChain para combinar los res√∫menes parciales\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m combine_chain \u001b[38;5;241m=\u001b[39m \u001b[43mStuffDocumentsChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Utilizar MapReduceDocumentsChain\u001b[39;00m\n\u001b[0;32m     16\u001b[0m map_reduce_chain \u001b[38;5;241m=\u001b[39m MapReduceDocumentsChain(\n\u001b[0;32m     17\u001b[0m     llm_chain\u001b[38;5;241m=\u001b[39mmap_chain,\n\u001b[0;32m     18\u001b[0m     combine_documents_chain\u001b[38;5;241m=\u001b[39mcombine_chain\n\u001b[0;32m     19\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\pydantic\\v1\\main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
            "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\pydantic\\v1\\main.py:1048\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, input_data, cls)\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m validator \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39m__pre_root_validators__:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1048\u001b[0m         input_data \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {}, \u001b[38;5;28mset\u001b[39m(), ValidationError([ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY)], cls_)\n",
            "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:158\u001b[0m, in \u001b[0;36mStuffDocumentsChain.get_default_document_variable_name\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;129m@root_validator\u001b[39m(pre\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_default_document_variable_name\u001b[39m(\u001b[38;5;28mcls\u001b[39m, values: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[0;32m    152\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get default document variable name, if not provided.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m    If only one variable is present in the llm_chain.prompt,\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m    we can infer that the formatted documents should be passed in\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    with this variable name.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m     llm_chain_variables \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllm_chain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39minput_variables\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument_variable_name\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m values:\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(llm_chain_variables) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
            "\u001b[1;31mKeyError\u001b[0m: 'llm_chain'"
          ]
        }
      ],
      "source": [
        "# imprimir resumenes de pel√≠culas.\n",
        "\n",
        "# Generar resumen para Dune 2\n",
        "dune2_summary = map_reduce_text(dune2_script_clean, map_template_summary, reduce_template_summary)\n",
        "print(answer_summary.format(summary=dune2_summary))\n",
        "\n",
        "# Evaluar pel√≠culas\n",
        "dune2_evaluation = evaluate_movie(dune2_script_clean, evaluation_template)\n",
        "print(answer_evaluation.format(evaluation=dune2_evaluation))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD7YHYZSIWbJ"
      },
      "source": [
        "Adicionalmente, Joaqu√≠n sabe que su primo favorito le gusta ``Dune: Part 2`` por lo que le gustar√≠a tener mayor informaci√≥n al respecto, para ello realice las siguientes tareas:\n",
        "\n",
        "\n",
        "3. Genere un gr√°fico que muestre los personajes de la pel√≠cula con m√°s apariciones en la misma.\n",
        "4. Genere una tabla en pandas con los 3 personajes que m√°s aparecen, indicando el nombre del actor y su edad actual m√°s uno (ojo edad + 1).\n",
        "5. Cree una funci√≥n que responda preguntas sobre la pel√≠cula bas√°ndose en la informaci√≥n del texto entregado (OJO: las preguntas y salidas deben ser en espa√±ol). Luego, responda las siguientes preguntas:\n",
        "* ¬øQu√© y qui√©n es Lisan al-Gaib?\n",
        "* ¬øQu√© personaje no cree en la profec√≠a pero es parte de ella?\n",
        "* ¬øCu√°l es el objetivo de Feyd-Rautha?\n",
        "6. Utilizando el top 3 de personajes que m√°s aparecen en la pel√≠cula, genere con el modelo LLM y utilizando el contexto del guion, las 6 estad√≠sticas que demuestren las habilidades de los personajes: Intelligence, Strength, Charisma, Wisdom, Emotional Resilience, y Creativity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_vdMMceJZBu"
      },
      "source": [
        "#### **1.2.3 Personajes (0.5 puntos)**\n",
        "\n",
        "En la siguiente secci√≥n, tiene que entregar un template de personajes y redicci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIM5JVC5JWNt"
      },
      "outputs": [],
      "source": [
        "map_template_characters = \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "reduce_template_characters = \"\"\"\n",
        "  \"\"\"\n",
        "\n",
        "answer_character_list = map_reduce_text(\n",
        "    website_data_1,\n",
        "    map_template_characters,\n",
        "    reduce_template_characters\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJQ-RPYJKOKU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from itertools import count\n",
        "import ast\n",
        "import re\n",
        "\n",
        "def plot_characters(answer_character_list):\n",
        "  # Clear answer\n",
        "  answer_character_list = # ...\n",
        "  characters = #...\n",
        "\n",
        "  # distil the characters output\n",
        "  \"\"\"\n",
        "  Recomendaci√≥n, utilizar un diccionario para ordenar los personajes\n",
        "  \"\"\"\n",
        "\n",
        "  # Create dataframe\n",
        "  \"\"\"\n",
        "  De diccionario a DataFrame\n",
        "  \"\"\"\n",
        "\n",
        "  # Graficar datos\n",
        "\n",
        "  #Retornar los personajes\n",
        "  return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G2dx0XoLis4"
      },
      "source": [
        "#### **1.2.4 Actores principales (0.75 puntos)**\n",
        "\n",
        "Importante saber que el script **no** maneja informaci√≥n de los actores, por ello, es importante que nuestra LLM tenga acceso a internet, de manera de poder realizar b√∫squedas que nos ayuden a completar la informaci√≥n consultada.\n",
        "\n",
        "Para esto, utilizaremos agentes combinados con react para realzar la consulta y asegurarnos de que la respuesta es correcta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9CHzsLDKPeL"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentType, initialize_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZSclMoFMGSO"
      },
      "outputs": [],
      "source": [
        "# Key para realizar una busqueda\n",
        "os.environ[\"SERPER_API_KEY\"] = 'd63e62662ef63eb9e44ab133d191f7a99a0024a3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbGuaD6PMMA5"
      },
      "outputs": [],
      "source": [
        "def get_actors_and_age(character):\n",
        "\n",
        "  # Inicializar tools y agente.\n",
        "  tools = # ...\n",
        "  agent = # ...\n",
        "\n",
        "  # Crear template de query\n",
        "  query_template = \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Crear prompt y usar agente para la b√∫squeda.\n",
        "\n",
        "  # Retornar Nombre y Edad + 1\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpf9H61qMxal"
      },
      "source": [
        "**Explicar metodolog√≠a utilizada**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtQqA40sM09E"
      },
      "source": [
        "#### **1.2.5 Personajes Stats (0.5 puntos)**\n",
        "\n",
        "Esta parte es similar al punto 2. La clave esta en crear un buen prompting que nos permita generar las estad√≠sticas basandonos en una b√∫squeda por map/reduce.\n",
        "\n",
        "Tras la b√∫squeda, la idea es tener una funci√≥n de Python que nos permita generar el gr√°fico deseado y tener el resumen de los personajes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha1zVrtkNaF-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def map_reduce_text(script, character):\n",
        "  # Map\n",
        "  map_template = \"\"\"\n",
        "  Crear template, utilizar las palabras claves:\n",
        "  Intelligence, Charisma, Strength, Wisdom, Emotional Resilience and Creativity.\n",
        "  \"\"\"\n",
        "\n",
        "  # crear prompt y cadena\n",
        "  map_template += template_complemt\n",
        "  map_prompt = # ...\n",
        "  map_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  reduce_template = \"\"\"\n",
        "  Crear prompt de reducci√≥n.\n",
        "  Reducir, dado el perfil, en escala del 1 al 10 las cualidades mencionadas\n",
        "  \"\"\"\n",
        "  reduce_prompt = # ...\n",
        "  reduce_chain = # ...\n",
        "\n",
        "  # Reduce\n",
        "  \"\"\"\n",
        "  Reducir y combinar los documentos con un m√°ximo de 4000 tokens\n",
        "  \"\"\"\n",
        "\n",
        "  # Map/Reduce\n",
        "  \"\"\"\n",
        "  Uilizar MapReduceDocumentsChain\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Text splitter\n",
        "  \"\"\"\n",
        "  Usar RecursiveCharacterTextSplitter\n",
        "  \"\"\"\n",
        "\n",
        "  result = map_reduce_chain.invoke(split_script)\n",
        "  return result[\"output_text\"]\n",
        "\n",
        "\n",
        "# Formato del perfil\n",
        "def format_profile(answer_character_profile):\n",
        "  \"\"\"\n",
        "  Crear un json con las caracteristicas y que retorne\n",
        "  (final_profile, stats) del personaje\n",
        "  \"\"\"\n",
        "  return (final_profile, stats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_wwMRm7PbXC"
      },
      "outputs": [],
      "source": [
        "# Escriba su respuesta ac√°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oduYAOZPaL_"
      },
      "outputs": [],
      "source": [
        "final_profile, stats = format_profile(answer_character_profile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOQ8yMG5PhGT"
      },
      "outputs": [],
      "source": [
        "print(final_profile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXAHPyRSP6HY"
      },
      "outputs": [],
      "source": [
        "# Funci√≥n para gr√°ficar stats. No Tocar.\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "def plot_stats(stats, character_name=\"Paul Atreides\"):\n",
        "    base_stats = [\n",
        "        \"Intelligence\", \"Charisma\", \"Strength\",\n",
        "        \"Wisdom\", \"Emotional Resilience\", \"Creativity\"\n",
        "    ]\n",
        "    for stat in base_stats:\n",
        "        if stat not in stats:\n",
        "            stats[stat] = 0\n",
        "\n",
        "    labels = list(stats.keys())\n",
        "    stats_values = list(stats.values())\n",
        "    stats_values += stats_values[:1]\n",
        "    labels += labels[:1]\n",
        "\n",
        "    # Plotly figure\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatterpolar(\n",
        "        r=stats_values,\n",
        "        theta=labels,\n",
        "        fill='toself',\n",
        "        name=character_name\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        polar=dict(\n",
        "            radialaxis=dict(\n",
        "                visible=True,\n",
        "                range=[0, max(stats_values)]\n",
        "            )\n",
        "        ),\n",
        "        showlegend=False,\n",
        "        title=character_name\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "fig = plot_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_APhHBPXQXTX"
      },
      "source": [
        "#### **Comentar (0.25 puntos)**\n",
        "Explicar metodolog√≠a y secuencia l√≥gica de cada una de las respuestas. Adem√°s responda:\n",
        "\n",
        "* ¬øQu√© otras tareas se podr√≠a realizar? De dos ejemplos con la metodolog√≠a asociada.\n",
        "\n",
        "* ¬øCual es la importancia de los prompt y como estos afectan al desempe√±o de los LLM?\n",
        "\n",
        "* ¬øAlguna de sus respuestas fue una 'alucinaci√≥n'? ¬øPor qu√© sucede esto?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hmHHQ9BuyAG"
      },
      "source": [
        "## **2. Reinforcement Learning (2.0 puntos)**\n",
        "\n",
        "En esta secci√≥n van a usar m√©todos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOcejYb6uzOO",
        "outputId": "384330f0-94ca-4d1a-b70f-079919eee1dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qqq gymnasium stable_baselines3\n",
        "!pip install -qqq swig\n",
        "!pip install -qqq gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBPet_Mq8dX9"
      },
      "source": [
        "### **2.1 Blackjack (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Joaqu√≠n es fan√°tico del Blackjack, por lo que en esta subsecci√≥n implementar√°n m√©todos de RL y as√≠ generar una estrategia para que pueda ~~ir al casino a  hacerse millonario~~ aprender a resolver problemas mediante RL.\n",
        "\n",
        "Comencemos primero preparando el ambiente. El siguiente bloque de c√≥digo transforma las observaciones del ambiente a `np.array`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpZ8bBKk9ZlU"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import MultiDiscrete\n",
        "import numpy as np\n",
        "\n",
        "class FlattenObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(FlattenObservation, self).__init__(env)\n",
        "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.array(observation).flatten()\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ6J1_-Y9nHO"
      },
      "source": [
        "#### **2.1.1 Descripci√≥n de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripci√≥n sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulaci√≥n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5i1Wt1p770x"
      },
      "source": [
        "\n",
        "El objetivo del Blackjack  es obtener una mano con un valor total lo m√°s cercano posible a 21 sin pasarse.\n",
        "\n",
        "- Un estado en el Blackjack puede representarse mediante una tupla la cual tiene la informaci√≥n de la suma total de las cartas del jugador, la carta visible del dealer y un indicador que diga que si es que el jugador tiene un As que puede contar como 11 sin pasarse de 21. Por ende, los estados son las posibles combinaciones de estas variables.\n",
        "\n",
        "- Las acciones disponibles para el jugador son hit (el jugador solicita una carta adicional) y stick (el jugador decide no pedir m√°s cartas y se planta con su mano actual).\n",
        "\n",
        "- Las recompensas en el juego est√°n definidas de la siguiente manera:\n",
        "     - `+1`: Si el jugador gana la partida.\n",
        "     - `0`: Si la partida termina en empate.\n",
        "     - `-1`: Si el jugador pierde la partida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmcX6bRC9agQ"
      },
      "source": [
        "#### **2.1.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta\n",
        "simulaci√≥n 5000 veces y reporte el promedio y desviaci√≥n de las recompensas.\n",
        "* ¬øC√≥mo calificar√≠a el performance de esta pol√≠tica?\n",
        "* ¬øC√≥mo podr√≠a interpretar las recompensas obtenidas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6toq1Exwsprs",
        "outputId": "ddb9d11a-5ecf-4fb9-b0cb-42a63085a47e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([24,  8,  0]), -1.0, True, False, {})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.step(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHCfKN7NGi1K",
        "outputId": "57512f15-3732-4168-f7d0-8f282c9dcdaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(-0.3888, 0.8986849058485404)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Simulaci√≥n ambiente con acciones random\n",
        "num_episodes = 5000\n",
        "rewards = []\n",
        "\n",
        "for _ in range(num_episodes):\n",
        "    observation, _ = env.reset()\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "    while not done:\n",
        "        action = env.action_space.sample()  # Tomar una acci√≥n aleatoria\n",
        "        observation, reward, done, truncated, info = env.step(action)\n",
        "        episode_reward += reward\n",
        "        done = done or truncated  # Considerar truncado como t√©rmino del episodio\n",
        "    rewards.append(episode_reward)\n",
        "\n",
        "# Calculo del promedio y desviaci√≥n est√°ndar\n",
        "mean_reward = np.mean(rewards)\n",
        "std_reward = np.std(rewards)\n",
        "\n",
        "mean_reward, std_reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMX69-Gzvqf0"
      },
      "source": [
        "###¬øC√≥mo calificar√≠a el performance de esta pol√≠tica?\n",
        "El valor promedio negativo indica que la pol√≠tica de acciones aleatorias resulta en p√©rdidas para el jugador. En este caso, el promedio -0.3888 implica que el jugador pierde en promedio aproximadamente 0.39 unidades de recompensa por episodio. Por otro lado, la desviaci√≥n est√°ndar de 0.8987 muestra una variabilidad considerable en las recompensas obtenidas, indicando que los resultados pueden variar significativamente de un episodio a otro (debido a la aleatoridad). En algunos episodios, el jugador podr√≠a ganar o empatar, pero en muchos otros es probable que pierda.\n",
        "\n",
        "Dado lo anterior, el rendimiento de la pol√≠tica aleatoria en Blackjack es pobre como se esperaba. Esto se debe a que este juego  tiene estrategias espec√≠ficas que pueden aumentar las probabilidades de ganar o minimizar las p√©rdidas.\n",
        "\n",
        "###¬øC√≥mo podr√≠a interpretar las recompensas obtenidas?\n",
        "Recordemos que cuanado la recompensa es -1, el jugador ha perdido la partida, una recompensa de 0 indica que la partida termin√≥ en empate y que una recompensa de +1 indica que el jugador ha ganado la partida. Dado esto, la pol√≠tica de acciones aleatorias tiene una mayor tendencia a perder, como lo muestra el promedio negativo de las recompensas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEO_dY4x_SJu"
      },
      "source": [
        "#### **2.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0sp8XWsGg4P",
        "outputId": "52a8c2e1-eeed-4ad3-9e2a-68ba67939127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mSe han truncado las √∫ltimas 5000 l√≠neas del flujo de salida.\u001b[0m\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.177    |\n",
            "|    n_updates        | 24460    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63212    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 97948    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.222    |\n",
            "|    n_updates        | 24461    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63216    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 97954    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.246    |\n",
            "|    n_updates        | 24463    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63220    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 97959    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.206    |\n",
            "|    n_updates        | 24464    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63224    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 97965    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.289    |\n",
            "|    n_updates        | 24466    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63228    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 97969    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.237    |\n",
            "|    n_updates        | 24467    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.43     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63232    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 97974    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.316    |\n",
            "|    n_updates        | 24468    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63236    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 97980    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.177    |\n",
            "|    n_updates        | 24469    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63240    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 97985    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.236    |\n",
            "|    n_updates        | 24471    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63244    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 97991    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.222    |\n",
            "|    n_updates        | 24472    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.41     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63248    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 97996    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.251    |\n",
            "|    n_updates        | 24473    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63252    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 98005    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.256    |\n",
            "|    n_updates        | 24476    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63256    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 98010    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.273    |\n",
            "|    n_updates        | 24477    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63260    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 98015    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.309    |\n",
            "|    n_updates        | 24478    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63264    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 98022    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.179    |\n",
            "|    n_updates        | 24480    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.44     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63268    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 98026    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.188    |\n",
            "|    n_updates        | 24481    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.43     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63272    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 98032    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.228    |\n",
            "|    n_updates        | 24482    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63276    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 98040    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.243    |\n",
            "|    n_updates        | 24484    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | 0.07     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63280    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 98048    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.236    |\n",
            "|    n_updates        | 24486    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | 0.05     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63284    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98056    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.275    |\n",
            "|    n_updates        | 24488    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63288    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98060    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.242    |\n",
            "|    n_updates        | 24489    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63292    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98065    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.216    |\n",
            "|    n_updates        | 24491    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | 0.07     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63296    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98070    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.176    |\n",
            "|    n_updates        | 24492    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | 0.04     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63300    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98076    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.334    |\n",
            "|    n_updates        | 24493    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.43     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63304    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98081    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.256    |\n",
            "|    n_updates        | 24495    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63308    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98088    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.238    |\n",
            "|    n_updates        | 24496    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63312    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98094    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.197    |\n",
            "|    n_updates        | 24498    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.45     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63316    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98099    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.221    |\n",
            "|    n_updates        | 24499    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63320    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98108    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.288    |\n",
            "|    n_updates        | 24501    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63324    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98114    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.203    |\n",
            "|    n_updates        | 24503    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | 0.04     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63328    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98120    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.369    |\n",
            "|    n_updates        | 24504    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | 0.09     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63332    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98126    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.192    |\n",
            "|    n_updates        | 24506    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | 0.11     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63336    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98132    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.222    |\n",
            "|    n_updates        | 24507    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | 0.14     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63340    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98137    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.246    |\n",
            "|    n_updates        | 24509    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | 0.17     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63344    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98142    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.254    |\n",
            "|    n_updates        | 24510    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | 0.16     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63348    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98148    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.215    |\n",
            "|    n_updates        | 24511    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | 0.13     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63352    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98154    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.237    |\n",
            "|    n_updates        | 24513    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | 0.09     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63356    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98160    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.178    |\n",
            "|    n_updates        | 24514    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | 0.11     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63360    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98167    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.212    |\n",
            "|    n_updates        | 24516    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | 0.11     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63364    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98178    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.217    |\n",
            "|    n_updates        | 24519    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | 0.09     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63368    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98184    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.323    |\n",
            "|    n_updates        | 24520    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | 0.08     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63372    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98189    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.115    |\n",
            "|    n_updates        | 24522    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.09     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63376    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98193    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.141    |\n",
            "|    n_updates        | 24523    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | 0.09     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63380    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98199    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.168    |\n",
            "|    n_updates        | 24524    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | 0.06     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63384    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98204    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.282    |\n",
            "|    n_updates        | 24525    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.1      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63388    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98213    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.289    |\n",
            "|    n_updates        | 24528    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | 0.08     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63392    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98217    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.288    |\n",
            "|    n_updates        | 24529    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.06     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63396    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98223    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.235    |\n",
            "|    n_updates        | 24530    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | 0.07     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63400    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98227    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.171    |\n",
            "|    n_updates        | 24531    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | 0.09     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63404    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98232    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.24     |\n",
            "|    n_updates        | 24532    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | 0.1      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63408    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98237    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.175    |\n",
            "|    n_updates        | 24534    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | 0.1      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63412    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98243    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.246    |\n",
            "|    n_updates        | 24535    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | 0.08     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63416    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98249    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.19     |\n",
            "|    n_updates        | 24537    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | 0.09     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63420    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98255    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.247    |\n",
            "|    n_updates        | 24538    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | 0.07     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63424    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98262    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.174    |\n",
            "|    n_updates        | 24540    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | 0.06     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63428    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98269    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.343    |\n",
            "|    n_updates        | 24542    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63432    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 334      |\n",
            "|    total_timesteps  | 98275    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.145    |\n",
            "|    n_updates        | 24543    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63436    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98285    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.242    |\n",
            "|    n_updates        | 24546    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63440    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98290    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.268    |\n",
            "|    n_updates        | 24547    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63444    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98297    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.165    |\n",
            "|    n_updates        | 24549    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63448    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98303    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.221    |\n",
            "|    n_updates        | 24550    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63452    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98311    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.226    |\n",
            "|    n_updates        | 24552    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | 0.05     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63456    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98318    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.36     |\n",
            "|    n_updates        | 24554    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | 0.06     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63460    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98323    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.193    |\n",
            "|    n_updates        | 24555    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63464    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98331    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.166    |\n",
            "|    n_updates        | 24557    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63468    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98336    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.292    |\n",
            "|    n_updates        | 24558    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | 0.04     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63472    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98343    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.244    |\n",
            "|    n_updates        | 24560    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63476    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98350    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.197    |\n",
            "|    n_updates        | 24562    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63480    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98358    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.212    |\n",
            "|    n_updates        | 24564    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63484    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98364    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.242    |\n",
            "|    n_updates        | 24565    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63488    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98368    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.2      |\n",
            "|    n_updates        | 24566    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63492    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98372    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.157    |\n",
            "|    n_updates        | 24567    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63496    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98378    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.31     |\n",
            "|    n_updates        | 24569    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63500    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98388    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.326    |\n",
            "|    n_updates        | 24571    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63504    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98392    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.205    |\n",
            "|    n_updates        | 24572    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63508    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98396    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.213    |\n",
            "|    n_updates        | 24573    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63512    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98403    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.167    |\n",
            "|    n_updates        | 24575    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63516    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98409    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.251    |\n",
            "|    n_updates        | 24577    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63520    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98416    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.162    |\n",
            "|    n_updates        | 24578    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63524    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98424    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.278    |\n",
            "|    n_updates        | 24580    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63528    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98430    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.225    |\n",
            "|    n_updates        | 24582    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63532    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98437    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.277    |\n",
            "|    n_updates        | 24584    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63536    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98445    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.293    |\n",
            "|    n_updates        | 24586    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63540    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98449    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.21     |\n",
            "|    n_updates        | 24587    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63544    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98455    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.191    |\n",
            "|    n_updates        | 24588    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63548    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total_timesteps  | 98461    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.232    |\n",
            "|    n_updates        | 24590    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63552    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98470    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.152    |\n",
            "|    n_updates        | 24592    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63556    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98476    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.225    |\n",
            "|    n_updates        | 24593    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63560    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98483    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.262    |\n",
            "|    n_updates        | 24595    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63564    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98489    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.321    |\n",
            "|    n_updates        | 24597    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63568    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98494    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.28     |\n",
            "|    n_updates        | 24598    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.08    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63572    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98498    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.209    |\n",
            "|    n_updates        | 24599    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63576    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98503    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.239    |\n",
            "|    n_updates        | 24600    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63580    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98511    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.208    |\n",
            "|    n_updates        | 24602    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63584    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98515    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.283    |\n",
            "|    n_updates        | 24603    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63588    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98523    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.217    |\n",
            "|    n_updates        | 24605    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63592    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98530    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.209    |\n",
            "|    n_updates        | 24607    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63596    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98536    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.201    |\n",
            "|    n_updates        | 24608    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63600    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98540    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.382    |\n",
            "|    n_updates        | 24609    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63604    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98547    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.238    |\n",
            "|    n_updates        | 24611    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63608    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98553    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.179    |\n",
            "|    n_updates        | 24613    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63612    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98558    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.173    |\n",
            "|    n_updates        | 24614    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63616    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98565    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.217    |\n",
            "|    n_updates        | 24616    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63620    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98569    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.304    |\n",
            "|    n_updates        | 24617    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63624    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98578    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.244    |\n",
            "|    n_updates        | 24619    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63628    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98584    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.191    |\n",
            "|    n_updates        | 24620    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63632    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98593    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.21     |\n",
            "|    n_updates        | 24623    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63636    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98599    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.171    |\n",
            "|    n_updates        | 24624    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63640    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98607    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.214    |\n",
            "|    n_updates        | 24626    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63644    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98611    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.281    |\n",
            "|    n_updates        | 24627    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63648    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98619    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.296    |\n",
            "|    n_updates        | 24629    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63652    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98626    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.247    |\n",
            "|    n_updates        | 24631    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63656    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98631    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.205    |\n",
            "|    n_updates        | 24632    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63660    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98638    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.182    |\n",
            "|    n_updates        | 24634    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63664    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98643    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.164    |\n",
            "|    n_updates        | 24635    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63668    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98648    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.23     |\n",
            "|    n_updates        | 24636    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63672    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98653    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.165    |\n",
            "|    n_updates        | 24638    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63676    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98660    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.239    |\n",
            "|    n_updates        | 24639    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | 0.04     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63680    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98668    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.312    |\n",
            "|    n_updates        | 24641    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | 0.04     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63684    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98673    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.213    |\n",
            "|    n_updates        | 24643    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | 0.07     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63688    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98681    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.209    |\n",
            "|    n_updates        | 24645    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | 0.06     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63692    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98685    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.188    |\n",
            "|    n_updates        | 24646    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | 0.1      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63696    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98691    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.246    |\n",
            "|    n_updates        | 24647    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | 0.05     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63700    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98696    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.173    |\n",
            "|    n_updates        | 24648    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63704    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98701    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.242    |\n",
            "|    n_updates        | 24650    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63708    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98710    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.285    |\n",
            "|    n_updates        | 24652    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63712    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98714    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.199    |\n",
            "|    n_updates        | 24653    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63716    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98719    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.19     |\n",
            "|    n_updates        | 24654    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63720    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98727    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.237    |\n",
            "|    n_updates        | 24656    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63724    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98734    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.221    |\n",
            "|    n_updates        | 24658    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63728    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98740    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.169    |\n",
            "|    n_updates        | 24659    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63732    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98748    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.228    |\n",
            "|    n_updates        | 24661    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63736    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98753    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.19     |\n",
            "|    n_updates        | 24663    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63740    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98758    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.21     |\n",
            "|    n_updates        | 24664    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63744    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98765    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.221    |\n",
            "|    n_updates        | 24666    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63748    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98772    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.23     |\n",
            "|    n_updates        | 24667    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | 0.04     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63752    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98778    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.267    |\n",
            "|    n_updates        | 24669    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.04     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63756    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98784    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.308    |\n",
            "|    n_updates        | 24670    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63760    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98790    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.242    |\n",
            "|    n_updates        | 24672    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63764    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98797    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.271    |\n",
            "|    n_updates        | 24674    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63768    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98802    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.233    |\n",
            "|    n_updates        | 24675    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63772    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98806    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.191    |\n",
            "|    n_updates        | 24676    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63776    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98812    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.276    |\n",
            "|    n_updates        | 24677    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63780    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98816    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.231    |\n",
            "|    n_updates        | 24678    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63784    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98824    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.227    |\n",
            "|    n_updates        | 24680    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63788    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98831    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.247    |\n",
            "|    n_updates        | 24682    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63792    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98835    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.305    |\n",
            "|    n_updates        | 24683    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63796    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98842    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.186    |\n",
            "|    n_updates        | 24685    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63800    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98847    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.235    |\n",
            "|    n_updates        | 24686    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63804    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98854    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.259    |\n",
            "|    n_updates        | 24688    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63808    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98861    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.211    |\n",
            "|    n_updates        | 24690    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63812    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98867    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.218    |\n",
            "|    n_updates        | 24691    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63816    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98872    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.375    |\n",
            "|    n_updates        | 24692    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63820    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98877    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.27     |\n",
            "|    n_updates        | 24694    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63824    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98882    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.218    |\n",
            "|    n_updates        | 24695    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63828    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98892    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.186    |\n",
            "|    n_updates        | 24697    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63832    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98900    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.241    |\n",
            "|    n_updates        | 24699    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63836    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98908    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.216    |\n",
            "|    n_updates        | 24701    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63840    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98912    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.174    |\n",
            "|    n_updates        | 24702    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63844    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98918    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.229    |\n",
            "|    n_updates        | 24704    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63848    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98922    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.23     |\n",
            "|    n_updates        | 24705    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63852    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98928    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.303    |\n",
            "|    n_updates        | 24706    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63856    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98934    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.21     |\n",
            "|    n_updates        | 24708    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63860    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98939    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.143    |\n",
            "|    n_updates        | 24709    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63864    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98945    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.243    |\n",
            "|    n_updates        | 24711    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63868    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98949    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.216    |\n",
            "|    n_updates        | 24712    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63872    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98959    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.216    |\n",
            "|    n_updates        | 24714    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63876    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98965    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.175    |\n",
            "|    n_updates        | 24716    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63880    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98971    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.197    |\n",
            "|    n_updates        | 24717    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63884    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98977    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.28     |\n",
            "|    n_updates        | 24719    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.08    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63888    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98987    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.116    |\n",
            "|    n_updates        | 24721    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63892    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98993    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.251    |\n",
            "|    n_updates        | 24723    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63896    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 98998    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.352    |\n",
            "|    n_updates        | 24724    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63900    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 99004    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.221    |\n",
            "|    n_updates        | 24725    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63904    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 99010    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.219    |\n",
            "|    n_updates        | 24727    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63908    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 99016    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.235    |\n",
            "|    n_updates        | 24728    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.08    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63912    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 99023    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.206    |\n",
            "|    n_updates        | 24730    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63916    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 99031    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.232    |\n",
            "|    n_updates        | 24732    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63920    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 99037    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.217    |\n",
            "|    n_updates        | 24734    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63924    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 99042    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.249    |\n",
            "|    n_updates        | 24735    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63928    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 99049    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.298    |\n",
            "|    n_updates        | 24737    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63932    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 99055    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.176    |\n",
            "|    n_updates        | 24738    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63936    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 337      |\n",
            "|    total_timesteps  | 99061    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.244    |\n",
            "|    n_updates        | 24740    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63940    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99069    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.274    |\n",
            "|    n_updates        | 24742    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63944    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99079    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.217    |\n",
            "|    n_updates        | 24744    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.63     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63948    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99085    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.152    |\n",
            "|    n_updates        | 24746    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.63     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63952    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99091    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.238    |\n",
            "|    n_updates        | 24747    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63956    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99096    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.196    |\n",
            "|    n_updates        | 24748    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.63     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63960    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99102    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.227    |\n",
            "|    n_updates        | 24750    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.64     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63964    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99109    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.196    |\n",
            "|    n_updates        | 24752    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.67     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63968    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99116    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.183    |\n",
            "|    n_updates        | 24753    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.63     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63972    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99122    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.21     |\n",
            "|    n_updates        | 24755    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.64     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63976    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99129    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.207    |\n",
            "|    n_updates        | 24757    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.64     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63980    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99135    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.28     |\n",
            "|    n_updates        | 24758    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.65     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63984    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99142    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.217    |\n",
            "|    n_updates        | 24760    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63988    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99148    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.302    |\n",
            "|    n_updates        | 24761    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.63     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63992    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99156    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.213    |\n",
            "|    n_updates        | 24763    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 63996    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99160    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.239    |\n",
            "|    n_updates        | 24764    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.64     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64000    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99168    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.265    |\n",
            "|    n_updates        | 24766    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.64     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64004    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99174    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.181    |\n",
            "|    n_updates        | 24768    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.64     |\n",
            "|    ep_rew_mean      | 0.04     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64008    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99180    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.234    |\n",
            "|    n_updates        | 24769    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.65     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64012    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99188    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.295    |\n",
            "|    n_updates        | 24771    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.64     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64016    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99195    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.298    |\n",
            "|    n_updates        | 24773    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.65     |\n",
            "|    ep_rew_mean      | -0.08    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64020    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99202    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.353    |\n",
            "|    n_updates        | 24775    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.66     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64024    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99208    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.193    |\n",
            "|    n_updates        | 24776    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.65     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64028    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99214    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.141    |\n",
            "|    n_updates        | 24778    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.64     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64032    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99219    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.176    |\n",
            "|    n_updates        | 24779    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.64     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64036    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99225    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.168    |\n",
            "|    n_updates        | 24781    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64040    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99231    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.34     |\n",
            "|    n_updates        | 24782    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | -0.08    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64044    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99240    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.144    |\n",
            "|    n_updates        | 24784    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | -0.04    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64048    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99246    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.265    |\n",
            "|    n_updates        | 24786    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | -0.08    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64052    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99253    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.32     |\n",
            "|    n_updates        | 24788    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.65     |\n",
            "|    ep_rew_mean      | -0.02    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64056    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99261    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.254    |\n",
            "|    n_updates        | 24790    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.66     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64060    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99268    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.236    |\n",
            "|    n_updates        | 24791    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.65     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64064    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99274    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.276    |\n",
            "|    n_updates        | 24793    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.66     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64068    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99282    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.314    |\n",
            "|    n_updates        | 24795    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.65     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64072    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99287    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.231    |\n",
            "|    n_updates        | 24796    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.65     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64076    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99294    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.217    |\n",
            "|    n_updates        | 24798    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.66     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64080    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99301    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.254    |\n",
            "|    n_updates        | 24800    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.63     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64084    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99305    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.302    |\n",
            "|    n_updates        | 24801    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64088    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99310    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.107    |\n",
            "|    n_updates        | 24802    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64092    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99316    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.173    |\n",
            "|    n_updates        | 24803    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.63     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64096    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99323    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.19     |\n",
            "|    n_updates        | 24805    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64100    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99329    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.233    |\n",
            "|    n_updates        | 24807    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64104    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99333    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.263    |\n",
            "|    n_updates        | 24808    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64108    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99338    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.236    |\n",
            "|    n_updates        | 24809    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64112    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99344    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.296    |\n",
            "|    n_updates        | 24810    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64116    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99351    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.218    |\n",
            "|    n_updates        | 24812    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | 0        |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64120    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99357    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.297    |\n",
            "|    n_updates        | 24814    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64124    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99361    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.23     |\n",
            "|    n_updates        | 24815    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64128    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99370    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.279    |\n",
            "|    n_updates        | 24817    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.01    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64132    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99376    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.311    |\n",
            "|    n_updates        | 24818    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64136    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 338      |\n",
            "|    total_timesteps  | 99382    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.126    |\n",
            "|    n_updates        | 24820    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64140    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99386    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.187    |\n",
            "|    n_updates        | 24821    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.05    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64144    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99391    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.265    |\n",
            "|    n_updates        | 24822    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.07    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64148    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99395    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.304    |\n",
            "|    n_updates        | 24823    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64152    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99400    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.167    |\n",
            "|    n_updates        | 24824    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.46     |\n",
            "|    ep_rew_mean      | -0.13    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64156    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99407    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.265    |\n",
            "|    n_updates        | 24826    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.43     |\n",
            "|    ep_rew_mean      | -0.17    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64160    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99411    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.317    |\n",
            "|    n_updates        | 24827    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.42     |\n",
            "|    ep_rew_mean      | -0.17    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64164    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99416    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.194    |\n",
            "|    n_updates        | 24828    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.39     |\n",
            "|    ep_rew_mean      | -0.18    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64168    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99421    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.221    |\n",
            "|    n_updates        | 24830    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.38     |\n",
            "|    ep_rew_mean      | -0.2     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64172    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99425    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.248    |\n",
            "|    n_updates        | 24831    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.35     |\n",
            "|    ep_rew_mean      | -0.23    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64176    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99429    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.201    |\n",
            "|    n_updates        | 24832    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.34     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64180    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99435    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.399    |\n",
            "|    n_updates        | 24833    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.38     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64184    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99443    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.258    |\n",
            "|    n_updates        | 24835    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.38     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64188    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99448    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.243    |\n",
            "|    n_updates        | 24836    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.37     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64192    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99453    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.221    |\n",
            "|    n_updates        | 24838    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.36     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64196    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99459    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.228    |\n",
            "|    n_updates        | 24839    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.36     |\n",
            "|    ep_rew_mean      | -0.21    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64200    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99465    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.328    |\n",
            "|    n_updates        | 24841    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.37     |\n",
            "|    ep_rew_mean      | -0.23    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64204    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99470    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.205    |\n",
            "|    n_updates        | 24842    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.38     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64208    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99476    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.292    |\n",
            "|    n_updates        | 24843    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.37     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64212    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99481    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.2      |\n",
            "|    n_updates        | 24845    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.36     |\n",
            "|    ep_rew_mean      | -0.24    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64216    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99487    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.134    |\n",
            "|    n_updates        | 24846    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.38     |\n",
            "|    ep_rew_mean      | -0.25    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64220    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99495    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.237    |\n",
            "|    n_updates        | 24848    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.42     |\n",
            "|    ep_rew_mean      | -0.28    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64224    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99503    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.32     |\n",
            "|    n_updates        | 24850    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.41     |\n",
            "|    ep_rew_mean      | -0.27    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64228    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99511    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.236    |\n",
            "|    n_updates        | 24852    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.4      |\n",
            "|    ep_rew_mean      | -0.25    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64232    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99516    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.216    |\n",
            "|    n_updates        | 24853    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.39     |\n",
            "|    ep_rew_mean      | -0.26    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64236    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99521    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.359    |\n",
            "|    n_updates        | 24855    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.43     |\n",
            "|    ep_rew_mean      | -0.23    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64240    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99529    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.192    |\n",
            "|    n_updates        | 24857    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.44     |\n",
            "|    ep_rew_mean      | -0.25    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64244    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99535    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.262    |\n",
            "|    n_updates        | 24858    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.47     |\n",
            "|    ep_rew_mean      | -0.25    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64248    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99542    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.226    |\n",
            "|    n_updates        | 24860    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.21    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64252    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99549    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.277    |\n",
            "|    n_updates        | 24862    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64256    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99555    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.166    |\n",
            "|    n_updates        | 24863    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.48     |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64260    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99559    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.286    |\n",
            "|    n_updates        | 24864    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.18    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64264    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99565    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.173    |\n",
            "|    n_updates        | 24866    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.21    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64268    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99572    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.254    |\n",
            "|    n_updates        | 24867    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64272    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99577    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.303    |\n",
            "|    n_updates        | 24869    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64276    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99585    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.286    |\n",
            "|    n_updates        | 24871    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.16    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64280    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99591    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.256    |\n",
            "|    n_updates        | 24872    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | -0.17    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64284    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99595    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.248    |\n",
            "|    n_updates        | 24873    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64288    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99601    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.198    |\n",
            "|    n_updates        | 24875    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.22    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64292    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99609    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.233    |\n",
            "|    n_updates        | 24877    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | -0.19    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64296    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99615    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.233    |\n",
            "|    n_updates        | 24878    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.2     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64300    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99622    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.29     |\n",
            "|    n_updates        | 24880    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.18    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64304    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99627    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.216    |\n",
            "|    n_updates        | 24881    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.2     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64308    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99633    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.29     |\n",
            "|    n_updates        | 24883    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.2     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64312    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99639    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.246    |\n",
            "|    n_updates        | 24884    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.2     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64316    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99645    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.304    |\n",
            "|    n_updates        | 24886    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | -0.18    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64320    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99652    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.241    |\n",
            "|    n_updates        | 24887    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.13    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64324    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99657    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.272    |\n",
            "|    n_updates        | 24889    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | -0.16    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64328    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99663    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.279    |\n",
            "|    n_updates        | 24890    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.13    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64332    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99667    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.155    |\n",
            "|    n_updates        | 24891    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64336    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99673    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.136    |\n",
            "|    n_updates        | 24893    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64340    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 339      |\n",
            "|    total_timesteps  | 99680    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.171    |\n",
            "|    n_updates        | 24894    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.5      |\n",
            "|    ep_rew_mean      | -0.12    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64344    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99685    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.25     |\n",
            "|    n_updates        | 24896    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64348    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99693    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.29     |\n",
            "|    n_updates        | 24898    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.49     |\n",
            "|    ep_rew_mean      | -0.09    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64352    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99698    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.156    |\n",
            "|    n_updates        | 24899    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.51     |\n",
            "|    ep_rew_mean      | -0.13    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64356    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99706    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.329    |\n",
            "|    n_updates        | 24901    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | -0.15    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64360    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99713    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.271    |\n",
            "|    n_updates        | 24903    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.14    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64364    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99720    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.201    |\n",
            "|    n_updates        | 24904    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | -0.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64368    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99730    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.253    |\n",
            "|    n_updates        | 24907    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | -0.11    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64372    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99739    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.169    |\n",
            "|    n_updates        | 24909    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64376    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99744    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.197    |\n",
            "|    n_updates        | 24910    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | -0.06    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64380    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99750    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.228    |\n",
            "|    n_updates        | 24912    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64384    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99755    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.205    |\n",
            "|    n_updates        | 24913    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | 0.01     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64388    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99760    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.309    |\n",
            "|    n_updates        | 24914    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | 0.03     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64392    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99765    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.225    |\n",
            "|    n_updates        | 24916    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | 0.04     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64396    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99773    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.268    |\n",
            "|    n_updates        | 24918    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64400    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99779    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.233    |\n",
            "|    n_updates        | 24919    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | 0.08     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64404    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99785    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.194    |\n",
            "|    n_updates        | 24921    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.59     |\n",
            "|    ep_rew_mean      | 0.12     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64408    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99792    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.3      |\n",
            "|    n_updates        | 24922    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | 0.13     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64412    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99799    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.295    |\n",
            "|    n_updates        | 24924    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | 0.16     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64416    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99805    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.27     |\n",
            "|    n_updates        | 24926    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | 0.14     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64420    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99810    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.146    |\n",
            "|    n_updates        | 24927    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.58     |\n",
            "|    ep_rew_mean      | 0.13     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64424    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99815    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.16     |\n",
            "|    n_updates        | 24928    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | 0.16     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64428    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99820    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.289    |\n",
            "|    n_updates        | 24929    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | 0.17     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64432    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99827    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.175    |\n",
            "|    n_updates        | 24931    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | 0.15     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64436    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99833    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.172    |\n",
            "|    n_updates        | 24933    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | 0.2      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64440    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99842    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.284    |\n",
            "|    n_updates        | 24935    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.63     |\n",
            "|    ep_rew_mean      | 0.17     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64444    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99848    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.309    |\n",
            "|    n_updates        | 24936    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.61     |\n",
            "|    ep_rew_mean      | 0.15     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64448    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99854    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.268    |\n",
            "|    n_updates        | 24938    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.63     |\n",
            "|    ep_rew_mean      | 0.12     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64452    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99861    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.211    |\n",
            "|    n_updates        | 24940    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | 0.11     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64456    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99868    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.154    |\n",
            "|    n_updates        | 24941    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.62     |\n",
            "|    ep_rew_mean      | 0.14     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64460    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99875    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.231    |\n",
            "|    n_updates        | 24943    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.6      |\n",
            "|    ep_rew_mean      | 0.17     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64464    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99880    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.206    |\n",
            "|    n_updates        | 24944    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | 0.17     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64468    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99886    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.318    |\n",
            "|    n_updates        | 24946    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.17     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64472    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99892    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.287    |\n",
            "|    n_updates        | 24947    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.16     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64476    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99897    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.177    |\n",
            "|    n_updates        | 24949    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | 0.2      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64480    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99904    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.232    |\n",
            "|    n_updates        | 24950    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | 0.19     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64484    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99910    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.256    |\n",
            "|    n_updates        | 24952    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | 0.21     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64488    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99916    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.247    |\n",
            "|    n_updates        | 24953    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | 0.19     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64492    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99922    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.203    |\n",
            "|    n_updates        | 24955    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.2      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64496    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99926    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.255    |\n",
            "|    n_updates        | 24956    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.24     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64500    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99932    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.212    |\n",
            "|    n_updates        | 24957    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.54     |\n",
            "|    ep_rew_mean      | 0.16     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64504    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99939    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.316    |\n",
            "|    n_updates        | 24959    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.52     |\n",
            "|    ep_rew_mean      | 0.12     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64508    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99944    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.245    |\n",
            "|    n_updates        | 24960    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.14     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64512    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99952    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.186    |\n",
            "|    n_updates        | 24962    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.53     |\n",
            "|    ep_rew_mean      | 0.12     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64516    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99958    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.247    |\n",
            "|    n_updates        | 24964    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | 0.1      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64520    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99965    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.335    |\n",
            "|    n_updates        | 24966    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.56     |\n",
            "|    ep_rew_mean      | 0.05     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64524    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99971    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.264    |\n",
            "|    n_updates        | 24967    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | 0.04     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64528    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 340      |\n",
            "|    total_timesteps  | 99977    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.254    |\n",
            "|    n_updates        | 24969    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.57     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64532    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 341      |\n",
            "|    total_timesteps  | 99984    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.263    |\n",
            "|    n_updates        | 24970    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | 0.02     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64536    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 341      |\n",
            "|    total_timesteps  | 99988    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.214    |\n",
            "|    n_updates        | 24971    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 1.55     |\n",
            "|    ep_rew_mean      | -0.03    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64540    |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 341      |\n",
            "|    total_timesteps  | 99997    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.221    |\n",
            "|    n_updates        | 24974    |\n",
            "----------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean reward: -0.043, Std reward: 0.9555893469477357\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Crear el modelo DQN\n",
        "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.learn(total_timesteps=100000)\n",
        "\n",
        "# Guardar el modelo\n",
        "model.save(\"dqn_blackjack\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-bpdb8wZID1"
      },
      "source": [
        "#### **2.1.4 Evaluaci√≥n de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.1.2 pero utilizando el modelo entrenado.\n",
        "* ¬øC√≥mo es el performance de su agente?\n",
        "* ¬øEs mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7jdmnTwGePD",
        "outputId": "f568d016-e63d-47fe-e328-33299bb8c351"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean reward: -0.0484, Std reward: 0.9512399486985395\n"
          ]
        }
      ],
      "source": [
        "# Evaluar la pol√≠tica entrenada\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=5000)\n",
        "\n",
        "print(f\"Mean reward: {mean_reward}, Std reward: {std_reward}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tvNuGif03He"
      },
      "source": [
        "La recompensa media del agente entrenado (-0.0484) es considerablemente mejor que la recompensa media del escenario baseline (-0.3888).\n",
        "Esto sugiere que el agente entrenado con DQN ha aprendido una pol√≠tica que resulta en menores p√©rdidas en comparaci√≥n con las acciones aleatorias. La mejora en la recompensa media indica que el agente est√° tomando decisiones m√°s informadas y efectivas durante el juego, pero no necesariamente es lo √≥ptimo (debido a su negatividad).\n",
        "\n",
        "Por otro lado, la desviaci√≥n est√°ndar de las recompensas del agente entrenado (0.9512) es ligeramente mayor que la del escenario baseline (0.8987).\n",
        "Una desviaci√≥n est√°ndar mayor implica una mayor variabilidad en las recompensas obtenidas. Aunque esto no es ideal, la mejora significativa en la recompensa media es un indicativo positivo del rendimiento del agente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO-EsAaPAYEm"
      },
      "source": [
        "#### **2.1.5 Estudio de acciones (0.2 puntos)**\n",
        "\n",
        "* Genere una funci√≥n que reciba un estado y retorne la accion del agente.\n",
        "* Luego, use esta funci√≥n para entregar la acci√≥n escogida frente a los siguientes escenarios:\n",
        "\n",
        "  * Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
        "  * Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
        "\n",
        "* ¬øSon coherentes sus acciones con las reglas del juego?\n",
        "\n",
        "Hint: ¬øA que clase de python pertenecen los estados? Pruebe a usar el m√©todo `.reset` para saberlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lssdp7AvGaRh",
        "outputId": "7b796608-9d03-47e1-aa22-b7ef931badbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Escenario: Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene un as\n",
            "Acci√≥n elegida por el agente: 1\n",
            "\n",
            "Escenario: Suma de cartas del agente es 19, dealer muestra un 3, agente tiene un as\n",
            "Acci√≥n elegida por el agente: 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Crear y envolver el entorno\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)\n",
        "\n",
        "# Definir la funci√≥n para obtener la acci√≥n del agente\n",
        "def get_action(state):\n",
        "    state = np.array(state).flatten()  # Asegurarse de que el estado est√© aplanado\n",
        "    action, _states = model.predict(state, deterministic=True)\n",
        "    return action\n",
        "\n",
        "# Escenarios proporcionados\n",
        "scenarios = [\n",
        "    ((6, 7, False), \"Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene un as\"),\n",
        "    ((19, 3, True), \"Suma de cartas del agente es 19, dealer muestra un 3, agente tiene un as\")\n",
        "]\n",
        "\n",
        "# Obtener y mostrar la acci√≥n para cada escenario\n",
        "for state, description in scenarios:\n",
        "    action = get_action(state)\n",
        "    print(f\"Escenario: {description}\\nAcci√≥n elegida por el agente: {action}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN9fHp2678nv"
      },
      "source": [
        "Para el primer escenario, la mayor√≠a de las estrategias recomendar√≠an pedir una carta porque la mano del jugador es muy d√©bil. Incluso si pedir aumenta el riesgo de pasarse de 21, es la acci√≥n correcta en este caso para intentar mejorar la mano. La acci√≥n de pedir es coherente con las reglas generales del Blackjack para una mano d√©bil contra una carta fuerte del crupier\n",
        "\n",
        "Para el esceneario 2 la estrategia √≥ptima es plantarse. Una mano de 19 es muy fuerte y no tiene sentido arriesgarse a pedir otra carta y potencialmente pasarse de 21. La acci√≥n de plantarse es coherente con las reglas del Blackjack para una mano blanda fuerte contra una carta d√©bil del crupier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEqCTqqroh03"
      },
      "source": [
        "### **2.2 LunarLander**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la secci√≥n 2.1, en esta secci√≥n usted se encargar√° de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk5VJVppXh3N"
      },
      "source": [
        "#### **2.2.1 Descripci√≥n de MDP (0.2 puntos)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvAVq1wQIjLc"
      },
      "source": [
        "Comencemos preparando el ambiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb5PmadJIngR"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "env = gym.make(\"LunarLander-v2\", render_mode = \"rgb_array\", continuous = True) # notar el par√°metro continuous = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNERH-m8JYQb"
      },
      "source": [
        "* Entregue una breve descripci√≥n sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulaci√≥n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas.\n",
        "* ¬øComo se distinguen las acciones de este ambiente en comparaci√≥n a `Blackjack`?\n",
        "* En la preparaci√≥n del ambiente se especifica el par√°metro `continuous = True`. ¬øQue implicancias tiene esto sobre el ambiente?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbpGahPcHAje"
      },
      "source": [
        "El ambiente LunarLander simula el aterrizaje de una nave lunar en la superficie de la luna. El objetivo del agente es controlar la nave para que aterrice suavemente en una zona de aterrizaje marcada, evitando colisiones con obst√°culos y minimizando el uso de combustible.\n",
        "\n",
        "El estado del MDP en LunarLander incluye la posici√≥n y velocidad de la nave lunar, as√≠ como la orientaci√≥n y la velocidad angular.\n",
        "Tambi√©n se incluyen las coordenadas de la zona de aterrizaje y la velocidad l√≠mite de contacto con el suelo.\n",
        "\n",
        "Las acciones disponibles para el agente son continuas, debido al par√°metro `continuous = True` especificado al crear el entorno.\n",
        "Estas acciones pueden incluir el empuje en dos direcciones (principal y lateral), permitiendo un control detallado y continuo sobre la nave lunar.\n",
        "\n",
        "El agente recibe recompensas basadas en varios aspectos del aterrizaje: una recompensa positiva por aterrizar suavemente en la zona de aterrizaje penalizaciones por colisiones con obst√°culos o aterrizajes bruscos y penalizaciones por el uso excesivo de combustible.\n",
        "\n",
        "En comparaci√≥n con el juego de Blackjack, donde las acciones son discretas (por ejemplo, pedir una carta, plantarse), en LunarLander las acciones son continuas. Esto significa que en cada paso de tiempo, el agente puede decidir exactamente cu√°nto empuje aplicar en la direcci√≥n principal y lateral, en lugar de tener opciones discretas predefinidas.\n",
        "\n",
        "El par√°metro `continuous = True` en el entorno LunarLander permite un control m√°s preciso y realista sobre las acciones del agente, pero al mismo tiempo introduce desaf√≠os adicionales debido a la naturaleza continua del espacio de acci√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YChodtNQwzG2"
      },
      "source": [
        "#### **2.2.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "* Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci√≥n 10 veces y reporte el promedio y desviaci√≥n de las recompensas.\n",
        "* ¬øC√≥mo calificar√≠a el performance de esta pol√≠tica?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpX6jInZ_Y3F",
        "outputId": "8ca01fcc-87dd-41bc-e5ed-1c806f22f184"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([-0.01191082,  1.4102659 , -0.40151438, -0.01819595,  0.01363343,\n",
              "         0.0904926 ,  0.        ,  0.        ], dtype=float32),\n",
              " -0.5964644918817215,\n",
              " False,\n",
              " False,\n",
              " {})"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.step(env.action_space.sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNMT_GORIreW",
        "outputId": "7ce2a159-d52c-4258-8134-f23ac98b363f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simulaci√≥n 1: Recompensa = -170.03922427701326\n",
            "Simulaci√≥n 2: Recompensa = -277.7454075857138\n",
            "Simulaci√≥n 3: Recompensa = -453.6606372759719\n",
            "Simulaci√≥n 4: Recompensa = -70.46970276221907\n",
            "Simulaci√≥n 5: Recompensa = -301.45885465932326\n",
            "Simulaci√≥n 6: Recompensa = -91.27572898012953\n",
            "Simulaci√≥n 7: Recompensa = -286.39482683941645\n",
            "Simulaci√≥n 8: Recompensa = -48.72144751554576\n",
            "Simulaci√≥n 9: Recompensa = -56.45068565896193\n",
            "Simulaci√≥n 10: Recompensa = -303.52766365369735\n",
            "\n",
            "Promedio de recompensas: -205.97441792079925\n",
            "Desviaci√≥n est√°ndar de recompensas: 130.95624926928534\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n para ejecutar una simulaci√≥n con acciones aleatorias\n",
        "def run_random_simulation():\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    state = env.reset()\n",
        "\n",
        "    while not done:\n",
        "        action = env.action_space.sample()  # Escoger una acci√≥n aleatoria\n",
        "        next_state, reward, done, _, _ = env.step(action)  # Capturar solo los primeros tres valores relevantes\n",
        "        total_reward += reward\n",
        "\n",
        "    return total_reward\n",
        "\n",
        "# Ejecutar la simulaci√≥n 10 veces\n",
        "num_simulations = 10\n",
        "rewards = []\n",
        "\n",
        "for i in range(num_simulations):\n",
        "    reward = run_random_simulation()\n",
        "    rewards.append(reward)\n",
        "    print(f\"Simulaci√≥n {i+1}: Recompensa = {reward}\")\n",
        "\n",
        "# Calcular el promedio y la desviaci√≥n est√°ndar de las recompensas\n",
        "avg_reward = np.mean(rewards)\n",
        "std_reward = np.std(rewards)\n",
        "\n",
        "print(f\"\\nPromedio de recompensas: {avg_reward}\")\n",
        "print(f\"Desviaci√≥n est√°ndar de recompensas: {std_reward}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyMoRNeXASHy"
      },
      "source": [
        "La pol√≠tica aleatoria no logra aprender o mantener una estrategia efectiva para aterrizar la nave lunar suavemente en la zona de aterrizaje. Esto se refleja en el promedio negativo de recompensas, lo cual indica que la mayor√≠a de las simulaciones terminan con un desempe√±o sub√≥ptimo o fallido.\n",
        "\n",
        "Por otro lado, la alta desviaci√≥n est√°ndar sugiere que la pol√≠tica aleatoria produce resultados inconsistentes. A veces puede obtener recompensas relativamente altas debido a la aleatoriedad de acciones que ocasionalmente pueden resultar en aterrizajes m√°s suaves o menos penalizados. Sin embargo, estos episodios de buen desempe√±o son poco frecuentes y no son consistentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQrZVQflX_5f"
      },
      "source": [
        "#### **2.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "* A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg0epSnLKfy6",
        "outputId": "625b6534-e39a-4edd-ae15-f50cfd1ac398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 121      |\n",
            "|    ep_rew_mean     | -312     |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 13       |\n",
            "|    total_timesteps | 484      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.86     |\n",
            "|    critic_loss     | 12       |\n",
            "|    ent_coef        | 0.897    |\n",
            "|    ent_coef_loss   | -0.263   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 383      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 124      |\n",
            "|    ep_rew_mean     | -318     |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 33       |\n",
            "|    time_elapsed    | 29       |\n",
            "|    total_timesteps | 993      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.2      |\n",
            "|    critic_loss     | 19       |\n",
            "|    ent_coef        | 0.784    |\n",
            "|    ent_coef_loss   | -0.585   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 892      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 128      |\n",
            "|    ep_rew_mean     | -300     |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 30       |\n",
            "|    time_elapsed    | 50       |\n",
            "|    total_timesteps | 1538     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.2      |\n",
            "|    critic_loss     | 31.5     |\n",
            "|    ent_coef        | 0.684    |\n",
            "|    ent_coef_loss   | -0.711   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1437     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 140      |\n",
            "|    ep_rew_mean     | -291     |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 30       |\n",
            "|    time_elapsed    | 73       |\n",
            "|    total_timesteps | 2244     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.9     |\n",
            "|    critic_loss     | 6.36     |\n",
            "|    ent_coef        | 0.573    |\n",
            "|    ent_coef_loss   | -0.897   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2143     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 151      |\n",
            "|    ep_rew_mean     | -287     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 30       |\n",
            "|    time_elapsed    | 99       |\n",
            "|    total_timesteps | 3022     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.82     |\n",
            "|    critic_loss     | 9.75     |\n",
            "|    ent_coef        | 0.467    |\n",
            "|    ent_coef_loss   | -1.29    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2921     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 163      |\n",
            "|    ep_rew_mean     | -275     |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 30       |\n",
            "|    time_elapsed    | 130      |\n",
            "|    total_timesteps | 3917     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 17.6     |\n",
            "|    critic_loss     | 30.1     |\n",
            "|    ent_coef        | 0.372    |\n",
            "|    ent_coef_loss   | -1.36    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3816     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -252     |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 191      |\n",
            "|    total_timesteps | 5613     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 16.3     |\n",
            "|    critic_loss     | 17.1     |\n",
            "|    ent_coef        | 0.247    |\n",
            "|    ent_coef_loss   | -1.08    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5512     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 215      |\n",
            "|    ep_rew_mean     | -229     |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 233      |\n",
            "|    total_timesteps | 6867     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 19.1     |\n",
            "|    critic_loss     | 26.5     |\n",
            "|    ent_coef        | 0.191    |\n",
            "|    ent_coef_loss   | -0.935   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6766     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 254      |\n",
            "|    ep_rew_mean     | -214     |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 311      |\n",
            "|    total_timesteps | 9153     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 17       |\n",
            "|    critic_loss     | 6.94     |\n",
            "|    ent_coef        | 0.124    |\n",
            "|    ent_coef_loss   | -0.683   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9052     |\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "env = gym.make(\"LunarLander-v2\", render_mode = \"rgb_array\", continuous = True) # notar el par√°metro continuous = True\n",
        "\n",
        "# Configurar y entrenar el modelo SAC\n",
        "model = SAC(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "# Guardar el modelo entrenado\n",
        "model.save(\"sac_lunarlander\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z-oIUSrlAsY"
      },
      "source": [
        "#### **2.2.4 Evaluaci√≥n de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita el ejercicio 2.2.2 pero utilizando el modelo entrenado.\n",
        "* ¬øC√≥mo es el performance de su agente? ¬øEs mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWVY1a39KeRs",
        "outputId": "cfb5130e-9d6e-46e5-e1f6-33abef1bf579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean reward: -30.33686969203573, Std reward: 107.65907603501222\n"
          ]
        }
      ],
      "source": [
        "# Evaluar el modelo entrenado\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
        "\n",
        "print(f\"Mean reward: {mean_reward}, Std reward: {std_reward}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daC4ybXqEGxY"
      },
      "source": [
        "El valor de -30.34 indica que, en promedio, el agente obtiene una recompensa negativa durante los episodios de evaluaci√≥n. Esto sugiere que el agente no logra realizar aterrizajes exitosos de manera consistente y, en general, no cumple con el objetivo principal de aterrizar suavemente en la zona de aterrizaje. Pero de todas formas, este valor es m√°s cercano a cero que el del baseline, por lo que es mejor (pero no √≥ptimo).\n",
        "\n",
        "Por otro lado, la alta desviaci√≥n est√°ndar de 107.66 indica una gran variabilidad en el desempe√±o del agente entre los diferentes episodios evaluados. Esto puede deberse a la naturaleza estoc√°stica del entorno LunarLander y a la complejidad de aprender una pol√≠tica efectiva para controlar la nave lunar. De todas formas, esta es menor al baseline, por lo que es relativamente mejor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6Xw4YHT3P5d"
      },
      "source": [
        "#### **2.2.5 Optimizaci√≥n de modelo (0.2 puntos)**\n",
        "\n",
        "* Repita los ejercicios 2.2.3 y 2.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente par√°metros como:\n",
        "  - `total_timesteps`\n",
        "  - `learning_rate`\n",
        "  - `batch_size`\n",
        "\n",
        "* Una vez optimizado el modelo, use la funci√≥n `export_gif` entregada para estudiar el comportamiento de su agente en la resoluci√≥n del ambiente, comente sobre sus resultados.\n",
        "\n",
        "* Adjunte el gif generado en su entrega. Si, adem√°s, adjuntan el gif en el markdown tendr√°n un bonus de 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGJLETxtPivd",
        "outputId": "45c87d71-478b-4e38-bf03-77076bbc849f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 90.2     |\n",
            "|    ep_rew_mean     | -242     |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 98       |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 361      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.3      |\n",
            "|    critic_loss     | 43.2     |\n",
            "|    ent_coef        | 0.885    |\n",
            "|    ent_coef_loss   | -0.309   |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 260      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 115      |\n",
            "|    ep_rew_mean     | -244     |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 92       |\n",
            "|    time_elapsed    | 9        |\n",
            "|    total_timesteps | 923      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.56     |\n",
            "|    critic_loss     | 41.8     |\n",
            "|    ent_coef        | 0.683    |\n",
            "|    ent_coef_loss   | -0.856   |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 822      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 145      |\n",
            "|    ep_rew_mean     | -225     |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 86       |\n",
            "|    time_elapsed    | 19       |\n",
            "|    total_timesteps | 1736     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.83     |\n",
            "|    critic_loss     | 11.6     |\n",
            "|    ent_coef        | 0.478    |\n",
            "|    ent_coef_loss   | -1.35    |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 1635     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 208      |\n",
            "|    ep_rew_mean     | -217     |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 82       |\n",
            "|    time_elapsed    | 40       |\n",
            "|    total_timesteps | 3335     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.472    |\n",
            "|    critic_loss     | 13       |\n",
            "|    ent_coef        | 0.249    |\n",
            "|    ent_coef_loss   | -1.74    |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 3234     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 329      |\n",
            "|    ep_rew_mean     | -188     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 77       |\n",
            "|    time_elapsed    | 85       |\n",
            "|    total_timesteps | 6572     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.67    |\n",
            "|    critic_loss     | 4.35     |\n",
            "|    ent_coef        | 0.109    |\n",
            "|    ent_coef_loss   | 0.246    |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 6471     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 388      |\n",
            "|    ep_rew_mean     | -172     |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 75       |\n",
            "|    time_elapsed    | 123      |\n",
            "|    total_timesteps | 9303     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.82    |\n",
            "|    critic_loss     | 95.6     |\n",
            "|    ent_coef        | 0.072    |\n",
            "|    ent_coef_loss   | -0.449   |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 9202     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 389      |\n",
            "|    ep_rew_mean     | -171     |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 75       |\n",
            "|    time_elapsed    | 143      |\n",
            "|    total_timesteps | 10884    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.93    |\n",
            "|    critic_loss     | 2.61     |\n",
            "|    ent_coef        | 0.0739   |\n",
            "|    ent_coef_loss   | 0.119    |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 10783    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 385      |\n",
            "|    ep_rew_mean     | -163     |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 76       |\n",
            "|    time_elapsed    | 161      |\n",
            "|    total_timesteps | 12305    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -4.93    |\n",
            "|    critic_loss     | 11.3     |\n",
            "|    ent_coef        | 0.073    |\n",
            "|    ent_coef_loss   | 0.383    |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 12204    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 369      |\n",
            "|    ep_rew_mean     | -156     |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 76       |\n",
            "|    time_elapsed    | 173      |\n",
            "|    total_timesteps | 13281    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.42    |\n",
            "|    critic_loss     | 2.02     |\n",
            "|    ent_coef        | 0.087    |\n",
            "|    ent_coef_loss   | 0.441    |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 13180    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 357      |\n",
            "|    ep_rew_mean     | -152     |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 77       |\n",
            "|    time_elapsed    | 185      |\n",
            "|    total_timesteps | 14276    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.66    |\n",
            "|    critic_loss     | 2.33     |\n",
            "|    ent_coef        | 0.0956   |\n",
            "|    ent_coef_loss   | 0.179    |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 14175    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 348      |\n",
            "|    ep_rew_mean     | -142     |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 77       |\n",
            "|    time_elapsed    | 198      |\n",
            "|    total_timesteps | 15330    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -10.3    |\n",
            "|    critic_loss     | 3.73     |\n",
            "|    ent_coef        | 0.0953   |\n",
            "|    ent_coef_loss   | 0.368    |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 15229    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 334      |\n",
            "|    ep_rew_mean     | -139     |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 77       |\n",
            "|    time_elapsed    | 206      |\n",
            "|    total_timesteps | 16044    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -11.4    |\n",
            "|    critic_loss     | 2.46     |\n",
            "|    ent_coef        | 0.106    |\n",
            "|    ent_coef_loss   | -0.0901  |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 15943    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 325      |\n",
            "|    ep_rew_mean     | -131     |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 77       |\n",
            "|    time_elapsed    | 217      |\n",
            "|    total_timesteps | 16913    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -11.7    |\n",
            "|    critic_loss     | 4.2      |\n",
            "|    ent_coef        | 0.113    |\n",
            "|    ent_coef_loss   | 0.245    |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 16812    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 318      |\n",
            "|    ep_rew_mean     | -124     |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 78       |\n",
            "|    time_elapsed    | 227      |\n",
            "|    total_timesteps | 17787    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -15.4    |\n",
            "|    critic_loss     | 3.61     |\n",
            "|    ent_coef        | 0.134    |\n",
            "|    ent_coef_loss   | -0.0522  |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 17686    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 317      |\n",
            "|    ep_rew_mean     | -102     |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 78       |\n",
            "|    time_elapsed    | 243      |\n",
            "|    total_timesteps | 19006    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -13.8    |\n",
            "|    critic_loss     | 6.43     |\n",
            "|    ent_coef        | 0.145    |\n",
            "|    ent_coef_loss   | 0.808    |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 18905    |\n",
            "---------------------------------\n",
            "Mean reward: 87.5341997560504, Std reward: 128.4097526409799\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "\n",
        "# Entrenamiento\n",
        "env = gym.make(\"LunarLander-v2\", render_mode = \"rgb_array\", continuous = True)\n",
        "total_timesteps = 20000\n",
        "learning_rate = 0.0005\n",
        "batch_size = 256\n",
        "model = SAC(\"MlpPolicy\", env, learning_rate=learning_rate, batch_size=batch_size, verbose=1)\n",
        "model.learn(total_timesteps=total_timesteps)\n",
        "\n",
        "# Evaluaci√≥n\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
        "print(f\"Mean reward: {mean_reward}, Std reward: {std_reward}\")\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zynpwrK3ZMmY"
      },
      "outputs": [],
      "source": [
        "model.save(\"best_sac_lunarlander\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag-QIrmhLIY_",
        "outputId": "d5e3acdc-22c2-4d6f-96c3-ee4fe5982252"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def export_gif(model, n = 5):\n",
        "  '''\n",
        "  funci√≥n que exporta a gif el comportamiento del agente en n episodios\n",
        "  '''\n",
        "  images = []\n",
        "  for episode in range(n):\n",
        "    obs = model.env.reset()\n",
        "    img = model.env.render()\n",
        "    done = False\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      action, _ = model.predict(obs)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "      img = model.env.render(mode=\"rgb_array\")\n",
        "\n",
        "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aItYF6sr6F_6"
      },
      "outputs": [],
      "source": [
        "export_gif(model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0hmHHQ9BuyAG"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
