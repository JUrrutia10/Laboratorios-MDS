{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libreria Core del lab.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Libreria para plotear (En colab esta desactualizado plotly)\n",
    "!pip install --upgrade plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Librerias utiles\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler, OneHotEncoder, FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t0 = pd.read_csv('X_t0')\n",
    "y_t0 = pd.read_csv('y_t0')\n",
    "X_t1 = pd.read_csv('X_t1')\n",
    "y_t1 = pd.read_csv('y_t1')\n",
    "X_t2 = pd.read_csv('X_t2')\n",
    "X_t3 = pd.read_csv('X_t3')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DaysSinceJob',\n",
       " 'CreditCap',\n",
       " 'Speed24h',\n",
       " 'AliveSession',\n",
       " 'BankSpots8w',\n",
       " 'HustleMinutes',\n",
       " 'RiskScore',\n",
       " 'AliasMatch',\n",
       " 'DeviceEmails8w',\n",
       " 'HustleMonth',\n",
       " 'ZipHustle',\n",
       " 'Speed4w',\n",
       " 'income',\n",
       " 'FreeMail',\n",
       " 'HomePhoneCheck',\n",
       " 'BankMonths',\n",
       " 'DOBEmails4w',\n",
       " 'ForeignHustle',\n",
       " 'DeviceScams',\n",
       " 'OldHoodMonths',\n",
       " 'intended_balcon_amount',\n",
       " 'NewCribMonths',\n",
       " 'Speed6h',\n",
       " 'CellPhoneCheck',\n",
       " 'customer_age',\n",
       " 'ExtraPlastic']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "df_num = X_t0.select_dtypes(include=numerics) # df auxiliar para imprimir columnas numéricas\n",
    "\n",
    "numerical_columns = list(df_num.columns)\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JobStatus', 'CribStatus', 'LootMethod', 'InfoSource', 'DeviceOS']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obj = X_t0.select_dtypes(include='object') # df auxiliar para imprimir columnas de objetos\n",
    "\n",
    "categorical_columns = list(df_obj.columns)\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/18 02:34:04 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: RESOURCE_DOES_NOT_EXIST: Could not find experiment with ID 414586626058799069\n",
      "2024/07/18 02:34:05 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: RESOURCE_DOES_NOT_EXIST: Could not find experiment with ID 414586626058799069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Pipelines para columnas numéricas y categóricas con VarianceThreshold\n",
    "numeric_transformations = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('variance_threshold', VarianceThreshold(threshold=0)) # Para eliminar DeviceScams\n",
    "])\n",
    "\n",
    "categoric_transformations = Pipeline([\n",
    "    ('category_one_hot', OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")),\n",
    "    ('variance_threshold', VarianceThreshold(threshold=0))\n",
    "])\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numerical', numeric_transformations, numerical_columns),\n",
    "    ('categorical', categoric_transformations, categorical_columns)\n",
    "])\n",
    "\n",
    "# Aplicar el preprocesamiento\n",
    "df_pro = preprocessor.fit_transform(X_t0)\n",
    "\n",
    "# Recuperar los nombres de las nuevas columnas\n",
    "ohe_feature_names = preprocessor.named_transformers_['categorical'].named_steps['category_one_hot'].get_feature_names_out(categorical_columns)\n",
    "final_columns = numerical_columns + list(ohe_feature_names)\n",
    "\n",
    "# Dado que VarianceThreshold puede eliminar algunas características, necesitamos actualizar los nombres de las columnas\n",
    "# Primero, debemos verificar cuántas características fueron eliminadas por VarianceThreshold\n",
    "num_features_after_numeric_threshold = preprocessor.named_transformers_['numerical'].named_steps['variance_threshold'].get_support(indices=True)\n",
    "num_features_after_categorical_threshold = preprocessor.named_transformers_['categorical'].named_steps['variance_threshold'].get_support(indices=True)\n",
    "\n",
    "# Filtrar las columnas finales\n",
    "final_columns_numeric = [numerical_columns[i] for i in num_features_after_numeric_threshold]\n",
    "final_columns_categorical = [ohe_feature_names[i] for i in num_features_after_categorical_threshold]\n",
    "final_columns = final_columns_numeric + final_columns_categorical\n",
    "\n",
    "# Convertir el resultado a un DataFrame\n",
    "df_pro = pd.DataFrame(df_pro, columns=final_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_hip={\n",
    "'learning_rate': 0.06802202044451305,\n",
    "'n_estimators': 667,\n",
    "'max_depth': 5,\n",
    "'max_leaves': 3,\n",
    "'min_child_weight': 2,\n",
    "'reg_alpha': 0.9031319828024397,\n",
    "'reg_lambda': 0.4494141630778533,\n",
    "'subsample': 0.5045063160719112,\n",
    "'colsample_bytree': 0.83259315165401,\n",
    "'gamma': 4.55839488003589,\n",
    "'scale_pos_weight': 1.532161973191951\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/18 02:34:14 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: RESOURCE_DOES_NOT_EXIST: Could not find experiment with ID 414586626058799069\n",
      "c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:34:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-PR del modelo inicial: 0.16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, auc\n",
    "\n",
    "XGB_pipe_final_hip = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', **best_params_hip))\n",
    "])\n",
    "\n",
    "# Datos iniciales\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_t0, y_t0.loc[:, 'is_mob'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Entrenar el modelo inicial\n",
    "XGB_pipe_final_hip.fit(X_train, y_train)\n",
    "\n",
    "# Guardar el modelo inicial\n",
    "XGB_pipe_final_hip.named_steps['classifier'].save_model('xgb_initial.model')\n",
    "\n",
    "# Evaluar el modelo inicial\n",
    "y_prob = XGB_pipe_final_hip.predict_proba(X_test)[:, 1]\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "auc_pr = average_precision_score(y_test, y_prob)\n",
    "print(f'AUC-PR del modelo inicial: {auc_pr:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/18 02:34:16 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:34:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"enable_categorical\", \"missing\", \"n_estimators\", \"use_label_encoder\" } are not used.\n",
      "\"\n",
      "2024/07/18 02:34:17 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during xgboost autologging: RESOURCE_DOES_NOT_EXIST: Could not find experiment with ID 414586626058799069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-PR del modelo reentrenado: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:34:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que ya tienes X_t1 e y_t1 como tus nuevos datos\n",
    "X_new_train, X_new_test, y_new_train, y_new_test = train_test_split(X_t1, y_t1.loc[:, 'is_mob'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Cargar el modelo inicial\n",
    "model = xgb.Booster()\n",
    "model.load_model('xgb_initial.model')\n",
    "\n",
    "# Convertir los nuevos datos usando el preprocesador del pipeline\n",
    "X_new_train_preprocessed = XGB_pipe_final_hip.named_steps['preprocessor'].transform(X_new_train)\n",
    "X_new_test_preprocessed = XGB_pipe_final_hip.named_steps['preprocessor'].transform(X_new_test)\n",
    "\n",
    "# Crear DMatrix para los nuevos datos\n",
    "dtrain_new = xgb.DMatrix(X_new_train_preprocessed, label=y_new_train)\n",
    "dtest_new = xgb.DMatrix(X_new_test_preprocessed, label=y_new_test)\n",
    "\n",
    "# Reentrenar el modelo con los nuevos datos\n",
    "params = XGB_pipe_final_hip.named_steps['classifier'].get_params()\n",
    "params['use_label_encoder'] = False\n",
    "params['eval_metric'] = 'logloss'\n",
    "num_boost_round_new = 50\n",
    "model = xgb.train(params, dtrain_new, num_boost_round=num_boost_round_new, xgb_model=model)\n",
    "\n",
    "# Guardar el modelo actualizado\n",
    "model.save_model('xgb_updated.model')\n",
    "\n",
    "# Evaluar el modelo reentrenado\n",
    "y_new_prob = model.predict(dtest_new)\n",
    "precision_new, recall_new, _ = precision_recall_curve(y_new_test, y_new_prob)\n",
    "auc_pr_new = average_precision_score(y_new_test, y_new_prob)\n",
    "print(f'AUC-PR del modelo reentrenado: {auc_pr_new:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/18 02:34:27 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: RESOURCE_DOES_NOT_EXIST: Could not find experiment with ID 414586626058799069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgb_pipeline_initial.joblib']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el pipeline completo después del entrenamiento inicial\n",
    "XGB_pipe_final_hip.fit(X_train, y_train)\n",
    "joblib.dump(XGB_pipe_final_hip, 'xgb_pipeline_initial.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/18 02:34:29 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:34:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"enable_categorical\", \"missing\", \"n_estimators\", \"use_label_encoder\" } are not used.\n",
      "\"\n",
      "2024/07/18 02:34:32 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during xgboost autologging: RESOURCE_DOES_NOT_EXIST: Could not find experiment with ID 414586626058799069\n",
      "c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [02:34:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgb_pipeline_updated.joblib']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el pipeline completo\n",
    "XGB_pipe_final_hip = joblib.load('xgb_pipeline_initial.joblib')\n",
    "\n",
    "X_combined = pd.concat([X_t0, X_t1], axis=0)\n",
    "y_combined = pd.concat([y_t0.loc[:, 'is_mob'], y_t1.loc[:, 'is_mob']], axis=0)\n",
    "\n",
    "# Preprocesar los datos combinados\n",
    "X_combined_preprocessed = XGB_pipe_final_hip.named_steps['preprocessor'].transform(X_combined)\n",
    "\n",
    "# Crear DMatrix para los datos combinados\n",
    "dtrain_combined = xgb.DMatrix(X_combined_preprocessed, label=y_combined)\n",
    "\n",
    "# Obtener los parámetros del modelo inicial\n",
    "params = XGB_pipe_final_hip.named_steps['classifier'].get_params()\n",
    "params['use_label_encoder'] = False\n",
    "params['eval_metric'] = 'logloss'\n",
    "\n",
    "# Reentrenar el modelo con los datos combinados\n",
    "num_boost_round_new = 50\n",
    "model = xgb.train(params, dtrain_combined, num_boost_round=num_boost_round_new, xgb_model=model)\n",
    "\n",
    "# Guardar el modelo actualizado en el pipeline\n",
    "XGB_pipe_final_hip.named_steps['classifier'].save_model('xgb_updated.model')\n",
    "\n",
    "# Guardar el pipeline completo nuevamente\n",
    "joblib.dump(XGB_pipe_final_hip, 'xgb_pipeline_updated.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "\n",
    "def optimize_hyperparameters_with_mlflow(X, y, preprocessor):\n",
    "    def objective2(trial: Trial):\n",
    "        # Definir los hiperparámetros a ajustar\n",
    "        xgb_params = {\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'max_leaves': trial.suggest_int('max_leaves', 0, 100),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "            'scale_pos_weight': trial.suggest_float('scale_pos_weight', 0.5, 10)\n",
    "        }\n",
    "\n",
    "        # Crear el pipeline\n",
    "        XGB_pipe = Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', **xgb_params))\n",
    "        ])\n",
    "\n",
    "        # Validación cruzada\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        y_pred = cross_val_predict(XGB_pipe, X, y, cv=cv, method='predict_proba')[:, 1]\n",
    "\n",
    "        # Calcular el AUC PR\n",
    "        precision, recall, _ = precision_recall_curve(y, y_pred)\n",
    "        auc_pr = auc(recall, precision)\n",
    "\n",
    "        # Rastrear los hiperparámetros y la métrica con MLFlow\n",
    "        mlflow.log_params(xgb_params)\n",
    "        mlflow.log_metric(\"auc_pr\", auc_pr)\n",
    "\n",
    "        return auc_pr\n",
    "\n",
    "    # Ejecutar la optimización con Optuna y MLFlow\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    with mlflow.start_run(run_name=\"optimize_hyperparameters\", nested=True):\n",
    "        study.optimize(objective2, n_trials=1)\n",
    "\n",
    "    # Obtener el AUC PR y los mejores hiperparámetros encontrados\n",
    "    best_auc = study.best_value\n",
    "    best_params = study.best_params\n",
    "    num_trials = len(study.trials)\n",
    "    best_model = study.best_trial\n",
    "\n",
    "    print(f'Número de trials: {num_trials}')\n",
    "    print(f'AUC PR: {best_auc}')\n",
    "    print('Mejores hiperparámetros encontrados:')\n",
    "    for key, value in best_params.items():\n",
    "        print(f'{key}: {value}')\n",
    "\n",
    "    return best_params,best_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset_X_old = mlflow.data.from_pandas(X_old, name=\"data train X nueva\")\n",
    "                mlflow.log_input(dataset_X_old, context=\"training\")\n",
    "                dataset_y_old = mlflow.data.from_pandas(y_old, name=\"data train y nueva\")\n",
    "                mlflow.log_input(dataset_y_old, context=\"training\")\n",
    "                dataset_X_new = mlflow.data.from_pandas(X_new, name=\"data train X nueva\")\n",
    "                mlflow.log_input(dataset_X_new, context=\"training\")\n",
    "                dataset_y_new = mlflow.data.from_pandas(y_new, name=\"data train y nueva\")\n",
    "                mlflow.log_input(dataset_y_new, context=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Obtener la fecha y hora actual\n",
    "\n",
    "\n",
    "# Crear el nombre del run\n",
    "\n",
    "\n",
    "def retrain_model(X_old, y_old, X_new, y_new, preprocessor, model_path='xgb_pipeline.joblib'):\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    run_name = f\"incremental_training_{current_time}\"\n",
    "    # Finalizar cualquier ejecución activa de MLFlow\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()\n",
    "\n",
    "    # Combinar los datos antiguos y nuevos\n",
    "    X_combined = pd.concat([X_old, X_new], axis=0)\n",
    "    y_combined = pd.concat([y_old, y_new], axis=0)\n",
    "    \n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            try:\n",
    "                # Initial training\n",
    "                params,auclog = optimize_hyperparameters_with_mlflow(X_old, y_old, preprocessor)\n",
    "                \n",
    "                #mlflow.log_params(params)\n",
    "                #mlflow.log_metric(\"aucpr\", auclog)\n",
    "                XGB_pipe = Pipeline([\n",
    "                    (\"preprocessor\", preprocessor),\n",
    "                    (\"classifier\", XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', **params))\n",
    "                ])\n",
    "                XGB_pipe.fit(X_combined, y_combined)\n",
    "                joblib.dump(XGB_pipe, model_path)\n",
    "                mlflow.autolog()\n",
    "\n",
    "            finally:\n",
    "                mlflow.end_run()\n",
    "    else:\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            try:\n",
    "                # Cargar el pipeline completo\n",
    "                XGB_pipe = joblib.load(model_path)\n",
    "                classifier = XGB_pipe.named_steps['classifier']\n",
    "                \n",
    "                # Reentrenar el modelo con los datos combinados\n",
    "                X_combined_preprocessed = XGB_pipe.named_steps['preprocessor'].transform(X_combined)\n",
    "                dtrain_combined = xgb.DMatrix(X_combined_preprocessed, label=y_combined)\n",
    "                params,auclog = optimize_hyperparameters_with_mlflow(X_combined, y_combined, preprocessor)\n",
    "                #mlflow.log_params(params)\n",
    "                #mlflow.log_metric(\"aucpr\", auclog)\n",
    "                \n",
    "                classifier = xgb.train(params, dtrain_combined, num_boost_round=50, xgb_model=classifier.get_booster())\n",
    "                XGB_pipe.named_steps['classifier'] = classifier\n",
    "                joblib.dump(XGB_pipe, model_path)\n",
    "                mlflow.autolog()\n",
    "                mlflow.sklearn.log_model(XGB_pipe, \"model_updated\")\n",
    "            finally:\n",
    "                mlflow.end_run()\n",
    "\n",
    "    return XGB_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/843434259623179817', creation_time=1721284316795, experiment_id='843434259623179817', last_update_time=1721284316795, lifecycle_stage='active', name='MLflow Quickstart2', tags={}>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "# Set our tracking server uri for logging\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"MLflow Quickstart2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 02:47:17,208] A new study created in memory with name: no-name-0608a415-c257-4358-aa8c-44a99a19566e\n",
      "[W 2024-07-18 02:48:21,293] Trial 0 failed with parameters: {'learning_rate': 0.0019937331866392493, 'n_estimators': 698, 'max_depth': 5, 'max_leaves': 39, 'min_child_weight': 4, 'reg_alpha': 0.16459254353651964, 'reg_lambda': 0.09287101134852804, 'subsample': 0.9922143928936906, 'colsample_bytree': 0.7750900785648521, 'gamma': 4.736653473479915, 'scale_pos_weight': 9.185292402030328} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jeus8\\AppData\\Local\\Temp\\ipykernel_5472\\2430157338.py\", line 39, in objective2\n",
      "    y_pred = cross_val_predict(XGB_pipe, X, y, cv=cv, method='predict_proba')[:, 1]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 580, in safe_patch_function\n",
      "    patch_function(call_original, *args, **kwargs)\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 1889, in patched_fn_with_autolog_disabled\n",
      "    return original(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 561, in call_original\n",
      "    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 496, in call_original_fn_with_event_logging\n",
      "    original_fn_result = original_fn(*og_args, **og_kwargs)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 558, in _original_fn\n",
      "    original_result = original(*_og_args, **_og_kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 1282, in cross_val_predict\n",
      "    predictions = parallel(\n",
      "                  ^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\joblib\\parallel.py\", line 1863, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\joblib\\parallel.py\", line 1792, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 1367, in _fit_and_predict\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 460, in safe_patch_function\n",
      "    return original(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 476, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 460, in safe_patch_function\n",
      "    return original(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1519, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 460, in safe_patch_function\n",
      "    return original(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\xgboost\\core.py\", line 2051, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2024-07-18 02:48:21,316] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ejemplo de uso\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m XGB_pipe_final \u001b[38;5;241m=\u001b[39m \u001b[43mretrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_t0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_t0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_mob\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_t1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_t1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_mob\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxgb_pipeline_initial.joblib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[47], line 49\u001b[0m, in \u001b[0;36mretrain_model\u001b[1;34m(X_old, y_old, X_new, y_new, preprocessor, model_path)\u001b[0m\n\u001b[0;32m     47\u001b[0m X_combined_preprocessed \u001b[38;5;241m=\u001b[39m XGB_pipe\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(X_combined)\n\u001b[0;32m     48\u001b[0m dtrain_combined \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_combined_preprocessed, label\u001b[38;5;241m=\u001b[39my_combined)\n\u001b[1;32m---> 49\u001b[0m params,auclog \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_hyperparameters_with_mlflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m#mlflow.log_params(params)\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m#mlflow.log_metric(\"aucpr\", auclog)\u001b[39;00m\n\u001b[0;32m     53\u001b[0m classifier \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mtrain(params, dtrain_combined, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, xgb_model\u001b[38;5;241m=\u001b[39mclassifier\u001b[38;5;241m.\u001b[39mget_booster())\n",
      "Cell \u001b[1;32mIn[46], line 54\u001b[0m, in \u001b[0;36moptimize_hyperparameters_with_mlflow\u001b[1;34m(X, y, preprocessor)\u001b[0m\n\u001b[0;32m     52\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimize_hyperparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m, nested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 54\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Obtener el AUC PR y los mejores hiperparámetros encontrados\u001b[39;00m\n\u001b[0;32m     57\u001b[0m best_auc \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_value\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[46], line 39\u001b[0m, in \u001b[0;36moptimize_hyperparameters_with_mlflow.<locals>.objective2\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Validación cruzada\u001b[39;00m\n\u001b[0;32m     38\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXGB_pipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredict_proba\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Calcular el AUC PR\u001b[39;00m\n\u001b[0;32m     42\u001b[0m precision, recall, _ \u001b[38;5;241m=\u001b[39m precision_recall_curve(y, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:580\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    578\u001b[0m     patch_function\u001b[38;5;241m.\u001b[39mcall(call_original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 580\u001b[0m     \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m session\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msucceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m try_log_autologging_event(\n\u001b[0;32m    585\u001b[0m     AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_patch_function_success,\n\u001b[0;32m    586\u001b[0m     session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    590\u001b[0m     kwargs,\n\u001b[0;32m    591\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py:1889\u001b[0m, in \u001b[0;36m_autolog.<locals>.patched_fn_with_autolog_disabled\u001b[1;34m(original, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpatched_fn_with_autolog_disabled\u001b[39m(original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1888\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m disable_autologging():\n\u001b[1;32m-> 1889\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:561\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[1;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m         original_result \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;241m*\u001b[39m_og_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_og_kwargs)\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[1;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_original_fn_with_event_logging\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_original_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:496\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[1;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    489\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_start,\n\u001b[0;32m    490\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m         og_kwargs,\n\u001b[0;32m    495\u001b[0m     )\n\u001b[1;32m--> 496\u001b[0m     original_fn_result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    499\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_success,\n\u001b[0;32m    500\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m         og_kwargs,\n\u001b[0;32m    505\u001b[0m     )\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:558\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[1;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[0;32m    555\u001b[0m     disable_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    556\u001b[0m     reroute_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    557\u001b[0m ):\n\u001b[1;32m--> 558\u001b[0m     original_result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_og_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_og_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1282\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m   1281\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m-> 1282\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1295\u001b[0m inv_test_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1296\u001b[0m inv_test_indices[test_indices] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1367\u001b[0m, in \u001b[0;36m_fit_and_predict\u001b[1;34m(estimator, X, y, train, test, fit_params, method)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1367\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1368\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[0;32m   1369\u001b[0m predictions \u001b[38;5;241m=\u001b[39m func(X_test)\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:460\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    442\u001b[0m     active_session_failed\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m autologging_is_disabled(autologging_integration)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# warning behavior during original function execution, since autologging is being\u001b[39;00m\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;66;03m# skipped\u001b[39;00m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[0;32m    457\u001b[0m         disable_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    458\u001b[0m         reroute_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    459\u001b[0m     ):\n\u001b[1;32m--> 460\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;66;03m# Whether or not the original / underlying function has been called during the\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# execution of patched code\u001b[39;00m\n\u001b[0;32m    464\u001b[0m original_has_been_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\sklearn\\pipeline.py:476\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    475\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 476\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:460\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    442\u001b[0m     active_session_failed\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m autologging_is_disabled(autologging_integration)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# warning behavior during original function execution, since autologging is being\u001b[39;00m\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;66;03m# skipped\u001b[39;00m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[0;32m    457\u001b[0m         disable_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    458\u001b[0m         reroute_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    459\u001b[0m     ):\n\u001b[1;32m--> 460\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;66;03m# Whether or not the original / underlying function has been called during the\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# execution of patched code\u001b[39;00m\n\u001b[0;32m    464\u001b[0m original_has_been_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1491\u001b[0m (\n\u001b[0;32m   1492\u001b[0m     model,\n\u001b[0;32m   1493\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1499\u001b[0m )\n\u001b[0;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1517\u001b[0m )\n\u001b[1;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:460\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    442\u001b[0m     active_session_failed\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m autologging_is_disabled(autologging_integration)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# warning behavior during original function execution, since autologging is being\u001b[39;00m\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;66;03m# skipped\u001b[39;00m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[0;32m    457\u001b[0m         disable_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    458\u001b[0m         reroute_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    459\u001b[0m     ):\n\u001b[1;32m--> 460\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;66;03m# Whether or not the original / underlying function has been called during the\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# execution of patched code\u001b[39;00m\n\u001b[0;32m    464\u001b[0m original_has_been_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jeus8\\Laboratorios-MDS\\0labs.venv\\Lib\\site-packages\\xgboost\\core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     _check_call(\n\u001b[1;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "XGB_pipe_final = retrain_model(X_t0, y_t0.loc[:, 'is_mob'], X_t1, y_t1.loc[:, 'is_mob'], preprocessor, model_path='xgb_pipeline_initial.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predapi(data):\n",
    "    datadf=pd.read_csv(data)\n",
    "    ypred=XGB_pipe_final.predict(datadf)\n",
    "    ypred_df = pd.DataFrame(ypred, columns=[\"Prediction\"])\n",
    "    dataypred=datadf.copy()\n",
    "    dataypred['label_predicted']=ypred\n",
    "    return ypred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(fn = predapi, # noten como estamos usando la función que generamos anteriormente\n",
    "                    inputs=gr.File(type=\"filepath\"), \n",
    "                    outputs=gr.DataFrame()) # valor de salida\n",
    "\n",
    "demo.launch(share = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "0labs.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
