{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v2D1coL7I8i"
      },
      "source": [
        "<h1><center>Laboratorio 6: La solicitud de Sergio ü§ó</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxdTmIPD7L_x"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti√°n Tinoco\n",
        "- Auxiliar: Catherine Benavides\n",
        "- Ayudante: Nicol√°s Ojeda, Eduardo Moya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2Gyrj-x7N2L"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Manuel Zamorano\n",
        "- Nombre de alumno 2: Javier Urrutia\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ9skYc57Pxi"
      },
      "source": [
        "### **Link de repositorio de GitHub:** `https://github.com/JUrrutia10/Laboratorios-MDS`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M4PoEWm7S80"
      },
      "source": [
        "## Temas a tratar\n",
        "- Aplicar Pandas para obtener caracter√≠sticas de un DataFrame.\n",
        "- Aplicar Pipelines y Column Transformers.\n",
        "- Utilizar diferentes algoritmos de cluster y ver el desempe√±o.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C√≥digo que no se pueda ejecutar, no ser√° revisado.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender c√≥mo aplicar pipelines de Scikit-Learn para generar clusters.\n",
        "- Familiarizarse con plotly.\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `numpy`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre arreglos (*o tensores*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuMbiyQZG2Cc"
      },
      "source": [
        "## Descripci√≥n del laboratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZsNO4rUrqCz"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/5a/a6/af/5aa6afde8490da403a21601adf7a7240.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o0MPuk8rqCz"
      },
      "source": [
        "En el coraz√≥n de las operaciones de Aerol√≠nea Lucero, Sergio, el gerente de an√°lisis de datos, reuni√≥ a un talentoso equipo de j√≥venes cient√≠ficos de datos para un desaf√≠o crucial: segmentar la base de datos de los clientes. ‚ÄúNuestro objetivo es descubrir patrones en el comportamiento de los pasajeros que nos permitan personalizar servicios y optimizar nuestras campa√±as de marketing,‚Äù explic√≥ Sergio, mientras desplegaba un amplio rango de datos que inclu√≠an desde h√°bitos de compra hasta opiniones sobre los vuelos.\n",
        "\n",
        "Sergio encarg√≥ a los cient√≠ficos de datos la tarea de aplicar t√©cnicas avanzadas de clustering para identificar distintos segmentos de clientes, como los viajeros frecuentes y aquellos que eligen la aerol√≠nea para celebrar ocasiones especiales. La meta principal era entender profundamente c√≥mo estos grupos perciben la calidad y satisfacci√≥n de los servicios ofrecidos por la aerol√≠nea.\n",
        "\n",
        "A trav√©s de un enfoque meticuloso y colaborativo, los cient√≠ficos de datos se abocaron a la tarea, buscando transformar los datos brutos en valiosos insights que permitir√≠an a Aerol√≠nea Lucero no solo mejorar su servicio, sino tambi√©n fortalecer las relaciones con sus clientes mediante una oferta m√°s personalizada y efectiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs4KKWF1Hdpo"
      },
      "source": [
        "## Importamos librerias utiles üò∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4YpMafirqC0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQOXod4gHhSq"
      },
      "source": [
        "## 1. Estudio de Performance üìà\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn5u5ICkrqC2"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://user-images.githubusercontent.com/57133330/188281408-c67df9ee-fd1f-4b37-833b-f02848f1ce02.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Z0jTjtrqC2"
      },
      "source": [
        "Don Sergio les ha encomendado su primera tarea: analizar diversas t√©cnicas de clustering. Su objetivo es entender detalladamente c√≥mo funcionan estos m√©todos en t√©rminos de segmentaci√≥n y eficiencia en tiempo de ejecuci√≥n.\n",
        "\n",
        "Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering (k-means, DBSCAN, Ward y GMM) aplicados a tres conjuntos de datos, incrementando progresivamente su tama√±o. Utilice Plotly para las gr√°ficas y discuta los resultados tanto cualitativa como cuantitativamente.\n",
        "\n",
        "Uno de los requisitos establecidos por Sergio es que el an√°lisis se lleve a cabo utilizando Plotly; de no ser as√≠, se considerar√° incorrecto. Para facilitar este proceso, se ha proporcionado un c√≥digo de Plotly que puede servir como base para realizar las gr√°ficas. Ap√≥yese en el c√≥digo entregado para efectuar el an√°lisis y tome como referencia la siguiente imagen para realizar los gr√°ficos:\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-04-26_at_9.10.44_AM.png' width=300 />\n",
        "\n",
        "En el gr√°fico se visualizan en dos dimensiones los diferentes tipos de datos proporcionados en `datasets`. Cada columna corresponde a un modelo de clustering diferente, mientras que cada fila representa un conjunto de datos distinto. Cada uno de los gr√°ficos incluye el tiempo en segundos que tarda el an√°lisis y la m√©trica Silhouette obtenida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maCUNAvZrqC2"
      },
      "source": [
        "Para ser m√°s espec√≠ficos, usted debe cumplir los siguientes objetivos:\n",
        "1. Generar una funci√≥n que permita replicar el gr√°fico expuesto en la imagen (no importa que los colores calcen). [4 puntos]\n",
        "2. Ejecuta la funci√≥n para un `n_samples` igual a 1000, 5000, 20000. [2 puntos]\n",
        "3. Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering. [4 puntos]\n",
        "\n",
        "\n",
        "> ‚ùó Tiene libertad absoluta de escoger los hiper par√°metros de los cluster, sin embargo, se recomienda verificar el dominio de las variables para realizar la segmentaci√≥n.\n",
        "> ‚ùó Recuerde que es obligatorio el uso de plotly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0IZPGPOrqC3"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "En la siguiente celda se crean los datos ficticios a usar en la secci√≥n 1 del lab.\n",
        "‚ùóNo realice cambios a esta celda\n",
        "\"\"\"\n",
        "\n",
        "# Datos a utilizar\n",
        "\n",
        "# Configuracion\n",
        "n_samples = 5000\n",
        "\n",
        "# Lunas\n",
        "moons = datasets.make_moons(n_samples=n_samples, noise=0.05, random_state=30)\n",
        "\n",
        "# Blobs\n",
        "blobs = datasets.make_blobs(n_samples=n_samples, random_state=172)\n",
        "\n",
        "# Datos desiguales\n",
        "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
        "mutated = (np.dot(blobs[0], transformation), blobs[1])\n",
        "\n",
        "# Generamos Dataset\n",
        "datasets = {\n",
        "    'moons':{\n",
        "        'x': moons[0], 'classes': moons[1], 'n_cluster': 2\n",
        "    },\n",
        "    'blobs':{\n",
        "        'x': blobs[0], 'classes': blobs[1], 'n_cluster': 3\n",
        "    },\n",
        "    'mutated':{\n",
        "        'x': mutated[0], 'classes': mutated[1], 'n_cluster': 3\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO3JFqezrqC3",
        "outputId": "3a1baeb2-217c-47a6-e908-8dc46a59de51"
      },
      "outputs": [],
      "source": [
        "# Funci√≥n scatter\n",
        "def plot_scatter(x, y, color):\n",
        "    fig = go.Figure(data=[go.Scatter(\n",
        "        x=x, y=y, mode='markers',\n",
        "        marker=dict(\n",
        "            size=8,\n",
        "            color=color,  # corresponde a una variable por el cual colorear\n",
        "            showscale=False  # esconde la escala de color\n",
        "        )\n",
        "    )])\n",
        "    return fig\n",
        "\n",
        "# Multiples plots con plotly\n",
        "fig = make_subplots(rows=3, cols=1)\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['moons']['x'][:, 0],\n",
        "        y=datasets['moons']['x'][:, 1],\n",
        "        color=datasets['moons']['classes']\n",
        "    )._data[0],\n",
        "    row=1, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['blobs']['x'][:, 0],\n",
        "        y=datasets['blobs']['x'][:, 1],\n",
        "        color=datasets['blobs']['classes']\n",
        "    )._data[0],\n",
        "    row=2, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['mutated']['x'][:, 0],\n",
        "        y=datasets['mutated']['x'][:, 1],\n",
        "        color=datasets['mutated']['classes']\n",
        "    )._data[0],\n",
        "    row=3, col=1\n",
        ")\n",
        "fig.update_layout(\n",
        "    showlegend=False, template='simple_white'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y51s6f_UtIkc"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlfDaoPqKMzg",
        "outputId": "4911309d-7774-4d37-a1d7-731a7c94b6a3"
      },
      "outputs": [],
      "source": [
        "datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlJAouH-Vu4t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from scipy.cluster.hierarchy import average, complete, dendrogram, single, ward\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import silhouette_score\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import time\n",
        "\n",
        "\n",
        "# Funci√≥n para calcular el tiempo y la m√©trica Silhouette\n",
        "def analyze_cluster(data, n_cluster):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # K-means\n",
        "    kmeans = KMeans(n_clusters=n_cluster, random_state=0)\n",
        "    kmeans.fit(data)\n",
        "    labels_kmeans = kmeans.labels_\n",
        "    silhouette_kmeans = silhouette_score(data, labels_kmeans)\n",
        "    end_time_kmeans = time.time()\n",
        "\n",
        "    # DBSCAN\n",
        "    dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "    dbscan.fit(data)\n",
        "    labels_dbscan = dbscan.labels_\n",
        "    # Check for single cluster\n",
        "    if len(np.unique(labels_dbscan)) == 1:\n",
        "        silhouette_dbscan = 0\n",
        "    else:\n",
        "        silhouette_dbscan = silhouette_score(data, labels_dbscan)\n",
        "    end_time_dbscan = time.time()\n",
        "\n",
        "    # Ward\n",
        "    Ward = AgglomerativeClustering(n_clusters=n_cluster, linkage=\"ward\")\n",
        "    labels_ward = Ward.fit_predict(data)\n",
        "    silhouette_ward = silhouette_score(data, labels_ward)\n",
        "    end_time_ward = time.time()\n",
        "\n",
        "    # GMM\n",
        "    gmm = GaussianMixture(n_components=n_cluster)\n",
        "    gmm.fit(data)\n",
        "    labels_gmm = gmm.predict(data)\n",
        "    silhouette_gmm = silhouette_score(data, labels_gmm)\n",
        "    end_time_gmm = time.time()\n",
        "\n",
        "    # Calcular tiempos\n",
        "    time_kmeans = end_time_kmeans - start_time\n",
        "    time_dbscan = end_time_dbscan - start_time\n",
        "    time_ward = end_time_ward - start_time\n",
        "    time_gmm = end_time_gmm - start_time\n",
        "\n",
        "    return {\n",
        "        'kmeans': {'labels': labels_kmeans, 'silhouette': silhouette_kmeans, 'time': time_kmeans},\n",
        "        'dbscan': {'labels': labels_dbscan, 'silhouette': silhouette_dbscan, 'time': time_dbscan},\n",
        "        'ward': {'labels': labels_ward, 'silhouette': silhouette_ward, 'time': time_ward},\n",
        "        'gmm': {'labels': labels_gmm, 'silhouette': silhouette_gmm, 'time': time_gmm}\n",
        "    }\n",
        "\n",
        "# Funci√≥n para generar la figura\n",
        "def generate_plot(datasets):\n",
        "    # Subplots with string titles\n",
        "    titles = (\n",
        "        'Moons - K-means', 'Moons - DBSCAN', 'Moons - Ward', 'Moons - GMM',\n",
        "        'Blobs - K-means', 'Blobs - DBSCAN', 'Blobs - Ward', 'Blobs - GMM',\n",
        "        'Mutated - K-means', 'Mutated - DBSCAN', 'Mutated - Ward', 'Mutated - GMM'\n",
        "    )\n",
        "    fig = make_subplots(rows=3, cols=4, subplot_titles=titles, vertical_spacing=0.2,row_heights=[0.25, 0.25, 0.25])\n",
        "\n",
        "\n",
        "    # Iterar sobre datasets y modelos\n",
        "    for row, dataset in enumerate(datasets.keys()):\n",
        "        data = datasets[dataset]['x']\n",
        "        n_cluster = datasets[dataset]['n_cluster']\n",
        "        cluster_results = analyze_cluster(data, n_cluster)\n",
        "\n",
        "        for col, model in enumerate(cluster_results.keys()):\n",
        "            labels = cluster_results[model]['labels']\n",
        "            silhouette = cluster_results[model]['silhouette']\n",
        "            time = cluster_results[model]['time']\n",
        "\n",
        "            # Generar scatter plot\n",
        "            fig.add_trace(\n",
        "                go.Scatter(\n",
        "                    x=data[:, 0],\n",
        "                    y=data[:, 1],\n",
        "                    mode='markers',\n",
        "                    marker=dict(\n",
        "                        size=8,\n",
        "                        color=labels,\n",
        "                        showscale=False\n",
        "                    ),\n",
        "                    \n",
        "                    name=f\"Silhouette: {silhouette:.3f} | Tiempo: {time:.3f} s\"  # Use label as trace name\n",
        "                ),\n",
        "                row=row + 1,\n",
        "                col=col + 1\n",
        "            )\n",
        "\n",
        "\n",
        "            fig.update_xaxes(title_text=f\"Silhouette: {silhouette:.3f} | Tiempo: {time:.3f} s\", row=row + 1, col=col + 1, title_font=dict(size=10))\n",
        "\n",
        "        \n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "    # Eliminar leyendas y t√≠tulos\n",
        "    fig.update_layout(\n",
        "        showlegend=False,\n",
        "        title_text='Resultados de Clustering para diferentes datasets y modelos'\n",
        "    )\n",
        "\n",
        "    # Mostrar la figura\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v9YP5NGWoy3",
        "outputId": "f8c08b92-a667-46c7-b0d0-fe8c553ee414"
      },
      "outputs": [],
      "source": [
        "generate_plot(datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mCbZc86rqC6"
      },
      "source": [
        "## 2. An√°lisis de Satisfacci√≥n de Vuelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI33m5jbrqC6"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.gifer.com/2Hci.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5k24znirqC7"
      },
      "source": [
        "Habiendo entendido c√≥mo funcionan los modelos de aprendizaje no supervisado, *Don Sergio* le encomienda estudiar la satisfacci√≥n de pasajeros al haber tomado un vuelo en alguna de sus aerolineas. Para esto, el magnate le dispone del dataset `aerolineas_licer.parquet`, el cual contiene el grado de satisfacci√≥n de los clientes frente a diferentes aspectos del vuelo. Las caracter√≠sticas del vuelo se definen a continuaci√≥n:\n",
        "\n",
        "- *Gender*: G√©nero de los pasajeros (Femenino, Masculino)\n",
        "- *Customer Type*: Tipo de cliente (Cliente habitual, cliente no habitual)\n",
        "- *Age*: Edad actual de los pasajeros\n",
        "- *Type of Travel*: Prop√≥sito del vuelo de los pasajeros (Viaje personal, Viaje de negocios)\n",
        "- *Class*: Clase de viaje en el avi√≥n de los pasajeros (Business, Eco, Eco Plus)\n",
        "- *Flight distance*: Distancia del vuelo de este viaje\n",
        "- *Inflight wifi service*: Nivel de satisfacci√≥n del servicio de wifi durante el vuelo (0:No Aplicable; 1-5)\n",
        "- *Departure/Arrival time convenient*: Nivel de satisfacci√≥n con la conveniencia del horario de salida/llegada\n",
        "- *Ease of Online booking*: Nivel de satisfacci√≥n con la facilidad de reserva en l√≠nea\n",
        "- *Gate location*: Nivel de satisfacci√≥n con la ubicaci√≥n de la puerta\n",
        "- *Food and drink*: Nivel de satisfacci√≥n con la comida y la bebida\n",
        "- *Online boarding*: Nivel de satisfacci√≥n con el embarque en l√≠nea\n",
        "- *Seat comfort*: Nivel de satisfacci√≥n con la comodidad del asiento\n",
        "- *Inflight entertainment*: Nivel de satisfacci√≥n con el entretenimiento durante el vuelo\n",
        "- *On-board service*: Nivel de satisfacci√≥n con el servicio a bordo\n",
        "- *Leg room service*: Nivel de satisfacci√≥n con el espacio para las piernas\n",
        "- *Baggage handling*: Nivel de satisfacci√≥n con el manejo del equipaje\n",
        "- *Check-in service*: Nivel de satisfacci√≥n con el servicio de check-in\n",
        "- *Inflight service*: Nivel de satisfacci√≥n con el servicio durante el vuelo\n",
        "- *Cleanliness*: Nivel de satisfacci√≥n con la limpieza\n",
        "- *Departure Delay in Minutes*: Minutos de retraso en la salida\n",
        "- *Arrival Delay in Minutes*: Minutos de retraso en la llegada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOoIFHpw5xCW"
      },
      "source": [
        "En consideraci√≥n de lo anterior, realice las siguientes tareas:\n",
        "\n",
        "0. Ingeste el dataset a su ambiente de trabajo.\n",
        "\n",
        "1. Seleccione **s√≥lo las variables num√©ricas del dataset**.  Explique qu√© √©fectos podr√≠a usar variables categ√≥ricas en un algoritmo no supervisado. Los datos se encuentran en el siguiente [enlace](https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/aerolineas_lucer.parquet). [2 puntos]\n",
        "\n",
        "2. Realice una visualizaci√≥n de la distribuci√≥n de cada variable y analice cada una de estas distribuciones. [2 puntos]\n",
        "\n",
        "3. Bas√°ndose en los gr√°ficos, eval√∫e la necesidad de escalar los datos y explique el motivo de su decisi√≥n. [2 puntos]\n",
        "\n",
        "4. Examine la correlaci√≥n entre las variables mediante un correlograma. [2 puntos]\n",
        "\n",
        "5. De acuerdo con los resultados obtenidos en 5, reduzca la dimensionalidad del conjunto de datos a cuatro variables, justificando su elecci√≥n respecto a las variables que decide eliminar. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO6tcVBCtxxS"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y0XFC8jsSVU"
      },
      "source": [
        "###0. Ingeste el dataset a su ambiente de trabajo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "pzHTZ17xveU_",
        "outputId": "4ada78be-c751-489d-ac15-8f59e20a30dd"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet(\"aerolineas_lucer.parquet\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ1pjtkTtYSH"
      },
      "source": [
        "###1. Seleccione s√≥lo las variables num√©ricas del dataset. Explique qu√© √©fectos podr√≠a usar variables categ√≥ricas en un algoritmo no supervisado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCtgP0b9tc70",
        "outputId": "151f8a2f-67bc-4810-bf7f-28de17736661"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_l0fkJmuAcF"
      },
      "outputs": [],
      "source": [
        "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "\n",
        "df = df.select_dtypes(include=numerics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97BFCtyWuKp6",
        "outputId": "9ca59548-4188-44b7-c08e-325c9cdc82dc"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "DfXxI8lQzc6w",
        "outputId": "e07b3756-1d6c-49dd-a943-ced6d8c8f2fd"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rHExQ_buOqh"
      },
      "source": [
        "En general, los algoritmos de clustering tradicionales est√°n dise√±ados para trabajar con datos num√©ricos y utilizan medidas de distancia, como la euclidiana, para determinar la similitud entre los puntos de datos. Sin embargo, aplicar estas t√©cnicas directamente a datos categ√≥ricos puede ser inapropiado, ya que la distancia euclidiana pierde su significado cuando se trata de atributos que no son num√©ricos. Esto puede llevar a interpretaciones err√≥neas y resultados de clustering no fiables. Es crucial seleccionar algoritmos, como k-modes, que est√©n espec√≠ficamente adaptados para manejar datos categ√≥ricos y que utilicen m√©tricas de disimilitud adecuadas para este tipo de informaci√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjKm_3Qav1F2"
      },
      "source": [
        "### 2. Realice una visualizaci√≥n de la distribuci√≥n de cada variable y analice cada una de estas distribuciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bRsEYB9l1yJC",
        "outputId": "487bc1bf-924d-41a2-fa3f-ec23fd69e681"
      },
      "outputs": [],
      "source": [
        "df = df.iloc[:, 1:]\n",
        "\n",
        "for column in df.columns:\n",
        "    fig = px.histogram(df, x=column, title=f'Distribuci√≥n de {column}')\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0S8Q6Sx2pAk"
      },
      "source": [
        "Se puede observar que gran parte de las distribuciones tienen una forma Gaussiana (Inflight entertainment', 'On-board service', 'Leg room service', 'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness'), a excepci√≥n de unas cuantas que presentan outliers ('Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes', 'Age'). Entre las primeras mencionas, hay alguna que se concentran a un lado del gr√°fico, al igual que 'Flight Distance', 'Departure Delay in Minutes' y 'Arrival Delay in Minutes'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkvCfU4N3aQl"
      },
      "source": [
        "### 3. Bas√°ndose en los gr√°ficos, eval√∫e la necesidad de escalar los datos y explique el motivo de su decisi√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZAPD9bY3gnP"
      },
      "source": [
        "Es necesario escalar los datos dada la diferencia que existe entre columnas. Por ejemplo, se debe estabdarizar los datos dada la distribuci√≥n de ciertas variables (algunas se concentran a cierto lado). Esto ayudar√° a trasformar las caracter√≠sticas para que tengan una media de 0 y una desviaci√≥n est√°ndar de 1. Por otro lado, los datos var√≠an un mon√≥n de acuerdo a sus valores: algunos toman valores del 1 al 5, y otros n√∫meros enteros mayores. Esto podr√≠a ocasionar problemas, por lo que es necesario normalizar las variables para escalar las caracter√≠sticas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbSqolLKNhup"
      },
      "source": [
        "### 4. Examine la correlaci√≥n entre las variables mediante un correlograma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51OkKfDvNgru",
        "outputId": "441cbb30-d817-40aa-fbf0-00f149395f87"
      },
      "outputs": [],
      "source": [
        "correlation_matrix = df.corr()\n",
        "\n",
        "fig = px.imshow(correlation_matrix,\n",
        "                labels=dict(color=\"Correlaci√≥n\"),\n",
        "                x=correlation_matrix.index,\n",
        "                y=correlation_matrix.columns,\n",
        "                color_continuous_scale='Viridis')\n",
        "\n",
        "fig.update_layout(title='Correlograma de las variables',\n",
        "                  width=800, height=600)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGfmxrTUP8HF"
      },
      "source": [
        "### 5. De acuerdo con los resultados obtenidos en 5, reduzca la dimensionalidad del conjunto de datos a cuatro variables, justificando su elecci√≥n respecto a las variables que decide eliminar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqrt_xIvRFJ2",
        "outputId": "1486d3f1-69b9-480b-ce5b-ad804e6ee445"
      },
      "outputs": [],
      "source": [
        "def print_correlation_sorted_abs(df):\n",
        "\n",
        "    correlation_matrix = df.corr()\n",
        "    stacked_corr = correlation_matrix.stack().reset_index()\n",
        "    stacked_corr.columns = ['Variable_1', 'Variable_2', 'Correlacion']\n",
        "    stacked_corr['Abs_Correlation'] = stacked_corr['Correlacion'].abs()\n",
        "    sorted_corr = stacked_corr.sort_values(by='Abs_Correlation', ascending=True)\n",
        "    print(sorted_corr.head(10))\n",
        "\n",
        "print_correlation_sorted_abs(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m3U-JbWSVte"
      },
      "source": [
        "Como se puede observar, se tiene una lista con las correlaciones (en valor absoluto) ordenada de menor a mayor. Se tiene que los primeros pares que tienen menos correlaci√≥n son:\n",
        "\n",
        "\n",
        "\n",
        "1.   `Arrival Delay in Minutes` con `Departure/Arrival time convenient`\n",
        "2.   `Gate location` con `Online boarding`\n",
        "3.    `Age` con `Gate location`\n",
        "4.   `Departure Delay in Minutes` con   `Departure/Arrival time convenient`\n",
        "\n",
        "Entre estos, tenemos:  `Arrival Delay in Minutes`, `Departure/Arrival time convenient`,  `Gate location`, `Online boarding`, `Age` y  `Departure Delay in Minutes`. Para elegir s√≥lo cuatro, se deber√≠a ver los que tengan menos correlaci√≥n con la mayor√≠a de estos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "XBCwXXQLWyiv",
        "outputId": "7e295943-a51c-40b8-d53c-dddfbcb33942"
      },
      "outputs": [],
      "source": [
        "columnas_elegidas = ['Arrival Delay in Minutes', 'Departure/Arrival time convenient',  'Gate location', 'Online boarding', 'Age',  'Departure Delay in Minutes']\n",
        "\n",
        "correlation_matrix = df[columnas_elegidas].corr()\n",
        "fig = px.imshow(correlation_matrix,\n",
        "                labels=dict(color=\"Correlaci√≥n\"),\n",
        "                x=correlation_matrix.index,\n",
        "                y=correlation_matrix.columns,\n",
        "                color_continuous_scale='Viridis')\n",
        "\n",
        "fig.update_layout(title='Correlograma de las variables',\n",
        "                  width=800, height=600)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QCyRxKPXe8G"
      },
      "source": [
        "Aqu√≠ podemos ver que:\n",
        "\n",
        "* `Departure Delay in Minutes` no puede ir junto a `Arrival Delay in Minutes`.\n",
        "* `Gate location` no puede ir junto a `Departure/Arrival time convenient`.\n",
        "* `Age` no puede ir junto a `Online boarding`.\n",
        "\n",
        "Se podr√≠a proceder a elegir las variables `Departure Delay in Minutes`, `Age`, `Gate location`, `Online boarding`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "GZ8d4toTYo6g",
        "outputId": "6bcbee4c-703e-495a-9cd9-d98c255cb3bc"
      },
      "outputs": [],
      "source": [
        "columnas_elegidas = ['Departure Delay in Minutes', 'Age', 'Gate location', 'Online boarding']\n",
        "\n",
        "correlation_matrix = df[columnas_elegidas].corr()\n",
        "fig = px.imshow(correlation_matrix,\n",
        "                labels=dict(color=\"Correlaci√≥n\"),\n",
        "                x=correlation_matrix.index,\n",
        "                y=correlation_matrix.columns,\n",
        "                color_continuous_scale='Viridis')\n",
        "\n",
        "fig.update_layout(title='Correlograma de las variables',\n",
        "                  width=800, height=600)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNGfTgtkrqC9"
      },
      "source": [
        "## 3. Preprocesamiento üé≠"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RZD0fMNrqC-"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/1e/a8/0e/1ea80e7cea0d429146580c7e91c5b944.gif\" width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6d4VEOTrqC-"
      },
      "source": [
        "Tras quedar satisfecho con los resultados presentados en el punto 2, el due√±o de la empresa ha solicitado que se preprocesen los datos mediante un `pipeline`. Es crucial que este proceso tenga en cuenta las observaciones derivadas de los an√°lisis anteriores. Adicionalmente, ha expresado su inter√©s en visualizar el conjunto de datos en un gr√°fico de dos o tres dimensiones.\n",
        "\n",
        "Bas√°ndose en los an√°lisis realizados anteriormente:\n",
        "1. Cree un `pipeline` que incluya PCA, utilizando las consideraciones mencionadas previamente para proyectar los datos a dos dimensiones. [4 puntos]\n",
        "2. Grafique los resultados obtenidos y comente lo visualizado. [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paDSaGoq0OUp"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBYG238wrqC-"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJM-LfhioC1M",
        "outputId": "aed7b864-3f76-47ec-8b58-7615c05c7a75"
      },
      "outputs": [],
      "source": [
        "df_4d = df.loc[:, ['Departure Delay in Minutes', 'Age', 'Gate location', 'Online boarding']]\n",
        "\n",
        "columns_to_scale = []\n",
        "for column in df_4d.columns:\n",
        "  columns_to_scale.append(column)\n",
        "print(columns_to_scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtPFOexTvO6_"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "\n",
        "\n",
        "# Funci√≥n para identificar y tratar los valores at√≠picos basados en el IQR\n",
        "def remove_outliers_IQR(X):\n",
        "    Q1 = np.percentile(X, 25, axis=0)\n",
        "    Q3 = np.percentile(X, 75, axis=0)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    X_filtered = np.clip(X, lower_bound, upper_bound)\n",
        "    return X_filtered\n",
        "\n",
        "# Agregar el paso de preprocesamiento al pipeline\n",
        "pipe_sinPCA = Pipeline([\n",
        "    ('outlier_removal', FunctionTransformer(remove_outliers_IQR)),   # Este realmente no estoy seguro, es para eliminar outliers que se dan en Departure Delay in Minutes (se supone)\n",
        "    ('scaler_1', StandardScaler()),\n",
        "    ('scaler_2', MinMaxScaler())\n",
        "])\n",
        "scaled_features = pipe_sinPCA.fit_transform(df_4d)\n",
        "\n",
        "# generamos dataframe con resultado\n",
        "scaled_features_df = pd.DataFrame(scaled_features, columns = columns_to_scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "B98bPqwet-0C",
        "outputId": "fb909fa2-3661-45a2-8c16-90e91bc8c88d"
      },
      "outputs": [],
      "source": [
        "# Esto est√° corrido sin el PCA en el pipeline!\n",
        "display(scaled_features_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BZifqXBMwOnS",
        "outputId": "2c0b3260-4bd3-4d24-995e-9e46366804ea"
      },
      "outputs": [],
      "source": [
        "# Esto est√° corrido sin el PCA en el pipeline!\n",
        "for column in scaled_features_df.columns:\n",
        "    fig = px.histogram(scaled_features_df, x=column, title=f'Distribuci√≥n de {column}')\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "VJ8PAdSZ86Vf",
        "outputId": "c0be07b1-fb6a-49b4-f914-a592cd4e5d77"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Funci√≥n para identificar y tratar los valores at√≠picos basados en el IQR\n",
        "def remove_outliers_IQR(X):\n",
        "    Q1 = np.percentile(X, 25, axis=0)\n",
        "    Q3 = np.percentile(X, 75, axis=0)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    X_filtered = np.clip(X, lower_bound, upper_bound)\n",
        "    return X_filtered\n",
        "\n",
        "# Agregar el paso de preprocesamiento al pipeline\n",
        "pipe_conPCA = Pipeline([\n",
        "    ('outlier_removal', FunctionTransformer(remove_outliers_IQR)),   # Este realmente no estoy seguro, es para eliminar outliers que se dan en Departure Delay in Minutes (se supone)\n",
        "    ('scaler_1', StandardScaler()),\n",
        "    ('scaler_2', MinMaxScaler()),\n",
        "    ('pca', PCA(n_components=2)),\n",
        "])\n",
        "scaled_features_pca = pipe_conPCA.fit_transform(df_4d)\n",
        "\n",
        "# Generamos un DataFrame con el resultado\n",
        "scaled_features_pca_df = pd.DataFrame(scaled_features_pca, columns=['Componente_1', 'Componente_2'])\n",
        "\n",
        "# Mostramos el DataFrame resultante\n",
        "display(scaled_features_pca_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "oGLnaM1A9dnv",
        "outputId": "a2b69b9b-94c7-4f29-daeb-cab46600cfa4"
      },
      "outputs": [],
      "source": [
        "# Graficar los resultados de PCA\n",
        "fig = px.scatter(scaled_features_pca_df, x='Componente_1', y='Componente_2', title='Resultados de PCA')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jSwnmKg_Pqb"
      },
      "source": [
        "En el gr√°fico se pueden observar distintos clusters que se generan en forma de l√≠neas. Esto podr√≠a dar cuenta a distintas clases que se podr√≠an dar con estos datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ENoOtIIrqC_"
      },
      "source": [
        "## 4. Outliers üö´üôÖ‚Äç‚ôÄÔ∏è‚ùåüôÖ‚Äç‚ôÇÔ∏è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbGw6Sa-rqC_"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://joachim-gassen.github.io/images/ani_sim_bad_leverage.gif\" width=250>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl_ccu9brqDA"
      },
      "source": [
        "Con el objetivo de mantener la claridad en su an√°lisis, Don Sergio le ha solicitado entrenar un modelo que identifique pasajeros con comportamientos altamente at√≠picos.\n",
        "\n",
        "1. Utilice `IsolationForest` para clasificar las anomal√≠as del dataset, configurando el modelo para que s√≥lo el 1% de los datos sean considerados an√≥malos. Aseg√∫rese de integrar esta tarea dentro de un `pipeline`. [3 puntos]\n",
        "\n",
        "2. Visualice los resultados en el gr√°fico de dos dimensiones previamente creado. [3 puntos]\n",
        "\n",
        "3. ¬øC√≥mo evaluar√≠a el rendimiento de su modelo en la detecci√≥n de anomal√≠as? [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5cS1FR00NlF"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "iaPZFmjyrqDA",
        "outputId": "848d61dd-6999-4a85-c2de-8cf518bf929d"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Definimos el pipeline con IsolationForest\n",
        "pipe_with_isolation_forest = Pipeline([\n",
        "    ('outlier_removal', FunctionTransformer(remove_outliers_IQR)),   # Eliminaci√≥n de outliers si lo deseas\n",
        "    ('scaler_1', StandardScaler()),\n",
        "    ('scaler_2', MinMaxScaler()),\n",
        "    ('pca', PCA(n_components=2)),\n",
        "    ('isolation_forest', IsolationForest(contamination=0.01))  # Solo el 1% de los datos ser√°n considerados an√≥malos\n",
        "])\n",
        "\n",
        "# Entrenamos el modelo\n",
        "pipe_with_isolation_forest.fit(df_4d)\n",
        "\n",
        "# Predicci√≥n de anomal√≠as\n",
        "anomaly_prediction = pipe_with_isolation_forest.predict(df_4d)\n",
        "\n",
        "scaled_features_pca_df_2 = scaled_features_pca_df.copy()\n",
        "\n",
        "# Visualizamos los resultados en el gr√°fico de dispersi√≥n\n",
        "scaled_features_pca_df_2['Anomaly'] = anomaly_prediction\n",
        "fig = px.scatter(scaled_features_pca_df_2, x='Componente_1', y='Componente_2', color='Anomaly',\n",
        "                 title='Resultados de PCA con Anomal√≠as Detectadas por IsolationForest')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvVUx4xkBRGc"
      },
      "source": [
        "Los puntos amarillos son considerados normales, mientras que los puntos azules son an√≥malos.\n",
        "\n",
        "Evaluar el rendimiento del modelo puede ser dif√≠cil, ya que no tenemos etiquetas de clase para los datos an√≥malos en el conjunto de datos no supervisado. Sin embargo, hay algunas m√©tricas y t√©cnicas que se pueden utilizar para evaluar la calidad de las predicciones de anomal√≠as.\n",
        "\n",
        "*   Como ya hemos hecho, visualizar los resultados es una forma √∫til de evaluar el rendimiento del modelo. En el gr√°fico de dispersi√≥n, los puntos etiquetados como an√≥malos (Anomaly = -1) deber√≠an destacarse y ser claramente distinguibles de los puntos normales.\n",
        "\n",
        "*   Aunque no tenemos etiquetas de clase para los datos an√≥malos, podemos utilizar t√©cnicas de validaci√≥n cruzada para evaluar la estabilidad y la consistencia de las predicciones del modelo.\n",
        "\n",
        "*   Si tenemos conocimiento de dominio sobre los datos, podemos realizar un an√°lisis manual de las observaciones etiquetadas como an√≥malas para determinar su validez. Esto puede ser √∫til para comprender mejor qu√© tipo de anomal√≠as est√° detectando el modelo y si estas anomal√≠as son relevantes o importantes en el contexto del problema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQFTklmVrqDB"
      },
      "source": [
        "## 5. M√©tricas de Desempe√±o üöÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpNj4wbPrqDB"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://giffiles.alphacoders.com/219/219081.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR3hzRxrrqDB"
      },
      "source": [
        "Motivado por incrementar su fortuna, Don Sergio le solicita entrenar un modelo que le permita segmentar a los pasajeros en grupos distintos, con el objetivo de optimizar las diversas campa√±as de marketing dise√±adas por su equipo. Para ello, le se pide realizar las siguientes tareas:\n",
        "\n",
        "1. Utilizar el modelo **Gaussian Mixture** y explore diferentes configuraciones de n√∫mero de cl√∫sters, espec√≠ficamente entre 3 y 8. Aseg√∫rese de integrar esta operaci√≥n dentro de un `pipeline`. [4 puntos]\n",
        "2. Explique cu√°l ser√≠a el criterio adecuado para seleccionar el n√∫mero √≥ptimo de cl√∫sters. **Justifique de forma estadistica y a traves de gr√°ficos.** [6 puntos]\n",
        "\n",
        "> **HINT:** Se recomienda investigar sobre los criterios AIC y BIC para esta tarea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwRSn4cdZsUv",
        "outputId": "02500617-ff3f-4d10-d47d-3cfa3270afe5"
      },
      "outputs": [],
      "source": [
        "print(scaled_features_pca_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_T_zTg0MXB"
      },
      "source": [
        "**Respuestas:**\n",
        "\n",
        "Como no queda muy claro si se debe hacer con el dataset original, el dataset filtrado por columnas o el dataset filtrado sin outliers, se hara para los tres casos el analisis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### con dataframe General"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5GeUb9J3rqDB",
        "outputId": "b94b0b8f-5360-4cdd-d410-2e7b9d210573"
      },
      "outputs": [],
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# Creamos un pipeline con el modelo Gaussian Mixture\n",
        "pipe_gmm = Pipeline([\n",
        "\n",
        "    ('scaler', StandardScaler()),  # Escalado de caracter√≠sticas\n",
        "    ('gmm', GaussianMixture(random_state=44))  # Modelo Gaussian Mixture\n",
        "])\n",
        "\n",
        "# Creamos una lista de n√∫mero de cl√∫sters para explorar\n",
        "num_clusters = list(range(3, 9))\n",
        "\n",
        "# Creamos listas vac√≠as para almacenar los criterios AIC y BIC\n",
        "aic_scores = []\n",
        "bic_scores = []\n",
        "\n",
        "# Iteramos sobre diferentes n√∫meros de cl√∫sters\n",
        "for n in num_clusters:\n",
        "    # Configuramos el n√∫mero de componentes en el modelo Gaussian Mixture\n",
        "    pipe_gmm.set_params(gmm__n_components=n)\n",
        "\n",
        "    # Entrenamos el modelo\n",
        "    pipe_gmm.fit(df)\n",
        "\n",
        "    # Calculamos el AIC y BIC para el modelo entrenado\n",
        "    aic_scores.append(pipe_gmm.named_steps['gmm'].aic(df))\n",
        "    bic_scores.append(pipe_gmm.named_steps['gmm'].bic(df))\n",
        "\n",
        "# Creamos un DataFrame con los resultados\n",
        "results_df = pd.DataFrame({'N√∫mero de Cl√∫sters': num_clusters, 'AIC': aic_scores, 'BIC': bic_scores})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graficamos los resultados con Plotly Express\n",
        "fig = px.line(results_df, x='N√∫mero de Cl√∫sters', y='AIC', title='Criterios AIC  para selecci√≥n de n√∫mero de cl√∫sters')\n",
        "fig.show()\n",
        "\n",
        "fig = px.line(results_df, x='N√∫mero de Cl√∫sters', y='BIC', title='Criterios BIC  para selecci√≥n de n√∫mero de cl√∫sters')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDKA_cstSJfc"
      },
      "source": [
        "Para seleccionar el n√∫mero √≥ptimo de cl√∫sters, podemos buscar el punto en el gr√°fico donde los valores de AIC y BIC son m√≠nimos. Este punto indicar√° el n√∫mero de cl√∫sters que mejor describe los datos, minimizando la complejidad del modelo. Por lo tanto, seleccionar√≠amos el n√∫mero de cl√∫sters correspondiente a este punto como el n√∫mero √≥ptimo de cl√∫sters para nuestro modelo Gaussian Mixture. En este caso, el punto m√≠nimo es 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "9tzbZoRVTmAI",
        "outputId": "16d8d220-a9d8-4612-c5bd-6ac9228be716"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento del modelo Gaussian Mixture con el n√∫mero √≥ptimo de cl√∫sters\n",
        "optimal_num_clusters = 5  # N√∫mero √≥ptimo de cl√∫sters que has seleccionado\n",
        "gmm = GaussianMixture(n_components=optimal_num_clusters)\n",
        "gmm.fit(df)\n",
        "\n",
        "# Predicci√≥n de los cl√∫sters\n",
        "cluster_labels_df = gmm.predict(df)\n",
        "\n",
        "\n",
        "\n",
        "df_with_clustersgmm=df.copy()\n",
        "df_with_clustersgmm['Cluster'] = cluster_labels_df\n",
        "\n",
        "# Crear un objeto PCA con el n√∫mero deseado de componentes\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Ajustar el PCA al conjunto de caracter√≠sticas seleccionado\n",
        "pca.fit(df)\n",
        "# Transformar el DataFrame con las caracter√≠sticas seleccionadas\n",
        "scaled_features_pca = pca.transform(df)\n",
        "\n",
        "\n",
        "\n",
        "# Generar un DataFrame con el resultado\n",
        "scaled_features_pca_df = pd.DataFrame(scaled_features_pca, columns=['Componente_1', 'Componente_2'])\n",
        "\n",
        "# Mostrar el DataFrame resultante\n",
        "display(scaled_features_pca_df)\n",
        "\n",
        "scaled_features_pca_df['Cluster'] = cluster_labels_df\n",
        "\n",
        "# Graficar los cl√∫sters con Plotly Express\n",
        "fig = px.scatter(scaled_features_pca_df, x='Componente_1', y='Componente_2', color='Cluster',\n",
        "                 title='Cl√∫sters encontrados por Gaussian Mixture despu√©s de PCA')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "NF7RsAcDRFGs",
        "outputId": "6ae95e87-e016-46bb-b7e6-a509b321c311"
      },
      "outputs": [],
      "source": [
        "display(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### con dataframe de 4dimensiones\n",
        "\n",
        "Con las dimensiones obtenidas en los puntos anteriores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# Creamos un pipeline con el modelo Gaussian Mixture\n",
        "pipe_gmm = Pipeline([\n",
        "\n",
        "    ('scaler', StandardScaler()),  # Escalado de caracter√≠sticas\n",
        "    ('gmm', GaussianMixture(random_state=44))  # Modelo Gaussian Mixture\n",
        "])\n",
        "\n",
        "# Creamos una lista de n√∫mero de cl√∫sters para explorar\n",
        "num_clusters = list(range(3, 9))\n",
        "\n",
        "# Creamos listas vac√≠as para almacenar los criterios AIC y BIC\n",
        "aic_scores = []\n",
        "bic_scores = []\n",
        "\n",
        "# Iteramos sobre diferentes n√∫meros de cl√∫sters\n",
        "for n in num_clusters:\n",
        "    # Configuramos el n√∫mero de componentes en el modelo Gaussian Mixture\n",
        "    pipe_gmm.set_params(gmm__n_components=n)\n",
        "\n",
        "    # Entrenamos el modelo\n",
        "    pipe_gmm.fit(df_4d)\n",
        "\n",
        "    # Calculamos el AIC y BIC para el modelo entrenado\n",
        "    aic_scores.append(pipe_gmm.named_steps['gmm'].aic(df_4d))\n",
        "    bic_scores.append(pipe_gmm.named_steps['gmm'].bic(df_4d))\n",
        "\n",
        "# Creamos un DataFrame con los resultados\n",
        "results_df_4d = pd.DataFrame({'N√∫mero de Cl√∫sters': num_clusters, 'AIC': aic_scores, 'BIC': bic_scores})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graficamos los resultados con Plotly Express\n",
        "fig = px.line(results_df_4d, x='N√∫mero de Cl√∫sters', y='AIC', title='Criterios AIC  para selecci√≥n de n√∫mero de cl√∫sters')\n",
        "fig.show()\n",
        "\n",
        "fig = px.line(results_df_4d, x='N√∫mero de Cl√∫sters', y='BIC', title='Criterios BIC  para selecci√≥n de n√∫mero de cl√∫sters')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este caso se puede observa que es mejor optar por 6 clusters para el dataset filtrado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenamiento del modelo Gaussian Mixture con el n√∫mero √≥ptimo de cl√∫sters\n",
        "optimal_num_clusters = 6  # N√∫mero √≥ptimo de cl√∫sters que has seleccionado\n",
        "\n",
        "\n",
        "gmm = GaussianMixture(n_components=optimal_num_clusters)\n",
        "gmm.fit(df_4d)\n",
        "\n",
        "# Predicci√≥n de los cl√∫sters\n",
        "cluster_labels_4d = gmm.predict(df_4d)\n",
        "\n",
        "df_4d_with_clustersgmm=df_4d.copy()\n",
        "df_4d_with_clustersgmm['Cluster'] = cluster_labels_4d\n",
        "\n",
        "\n",
        "\n",
        "# Crear un objeto PCA con el n√∫mero deseado de componentes\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Ajustar el PCA al conjunto de caracter√≠sticas seleccionado\n",
        "pca.fit(df_4d)\n",
        "\n",
        "# Transformar el DataFrame con las caracter√≠sticas seleccionadas\n",
        "scaled_features_pca_df_4d = pca.transform(df_4d)\n",
        "\n",
        "# Generar un DataFrame con el resultado\n",
        "scaled_features_pca_df_4d = pd.DataFrame(scaled_features_pca_df_4d, columns=['Componente_1', 'Componente_2'])\n",
        "\n",
        "# Mostrar el DataFrame resultante\n",
        "display(scaled_features_pca_df_4d)\n",
        "\n",
        "scaled_features_pca_df_4d['Cluster'] = cluster_labels_4d\n",
        "\n",
        "# Graficar los cl√∫sters con Plotly Express\n",
        "fig = px.scatter(scaled_features_pca_df_4d, x='Componente_1', y='Componente_2', color='Cluster',color_continuous_scale=px.colors.sequential.Viridis,\n",
        "                 title='Cl√∫sters encontrados por Gaussian Mixture despu√©s de PCA')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DAtaframe con Pipeline de parte 3\n",
        "para comparacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe_sinPCA = Pipeline([\n",
        "    ('outlier_removal', FunctionTransformer(remove_outliers_IQR)),   # Este realmente no estoy seguro, es para eliminar outliers que se dan en Departure Delay in Minutes (se supone)\n",
        "    ('scaler_1', StandardScaler()),\n",
        "    ('scaler_2', MinMaxScaler()),  # Escalado de caracter√≠sticas\n",
        "    ('gmm', GaussianMixture(random_state=44))  # Modelo Gaussian Mixture\n",
        "])\n",
        "\n",
        "# Creamos una lista de n√∫mero de cl√∫sters para explorar\n",
        "num_clusters = list(range(3, 9))\n",
        "\n",
        "# Creamos listas vac√≠as para almacenar los criterios AIC y BIC\n",
        "aic_scores = []\n",
        "bic_scores = []\n",
        "\n",
        "# Iteramos sobre diferentes n√∫meros de cl√∫sters\n",
        "for n in num_clusters:\n",
        "    # Configuramos el n√∫mero de componentes en el modelo Gaussian Mixture\n",
        "    pipe_gmm.set_params(gmm__n_components=n)\n",
        "\n",
        "    # Entrenamos el modelo\n",
        "    pipe_gmm.fit(df_4d)\n",
        "\n",
        "    # Calculamos el AIC y BIC para el modelo entrenado\n",
        "    aic_scores.append(pipe_gmm.named_steps['gmm'].aic(df_4d))\n",
        "    bic_scores.append(pipe_gmm.named_steps['gmm'].bic(df_4d))\n",
        "\n",
        "# Creamos un DataFrame con los resultados\n",
        "results_df_4d = pd.DataFrame({'N√∫mero de Cl√∫sters': num_clusters, 'AIC': aic_scores, 'BIC': bic_scores})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.line(results_df_4d, x='N√∫mero de Cl√∫sters', y='AIC', title='Criterios AIC  para selecci√≥n de n√∫mero de cl√∫sters')\n",
        "fig.show()\n",
        "\n",
        "fig = px.line(results_df_4d, x='N√∫mero de Cl√∫sters', y='BIC', title='Criterios BIC  para selecci√≥n de n√∫mero de cl√∫sters')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenamiento del modelo Gaussian Mixture con el n√∫mero √≥ptimo de cl√∫sters\n",
        "optimal_num_clusters = 6  # N√∫mero √≥ptimo de cl√∫sters que has seleccionado\n",
        "\n",
        "\n",
        "pipe_sinPCA = Pipeline([\n",
        "    ('outlier_removal', FunctionTransformer(remove_outliers_IQR)),   # Este realmente no estoy seguro, es para eliminar outliers que se dan en Departure Delay in Minutes (se supone)\n",
        "    ('scaler_1', StandardScaler()),\n",
        "    ('scaler_2', MinMaxScaler()) # Modelo Gaussian Mixture\n",
        "])\n",
        "\n",
        "\n",
        "scaled_features_pipe = pipe_sinPCA.fit_transform(df_4d)\n",
        "scaled_features_df_pipe = pd.DataFrame(scaled_features_pipe)\n",
        "\n",
        "\n",
        "gmm = GaussianMixture(n_components=optimal_num_clusters)\n",
        "\n",
        "\n",
        "gmm.fit(scaled_features_df_pipe)\n",
        "# Predicci√≥n de los cl√∫sters\n",
        "cluster_labels_4d_pipe = gmm.predict(scaled_features_df_pipe)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Crear un objeto PCA con el n√∫mero deseado de componentes\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Ajustar el PCA al conjunto de caracter√≠sticas seleccionado\n",
        "pca.fit(scaled_features_df_pipe)\n",
        "\n",
        "# Transformar el DataFrame con las caracter√≠sticas seleccionadas\n",
        "scaled_features_pca_df_4d_pipe = pca.transform(scaled_features_df_pipe)\n",
        "\n",
        "# Generar un DataFrame con el resultado\n",
        "scaled_features_pca_df_4d_pipe = pd.DataFrame(scaled_features_pca_df_4d_pipe, columns=['Componente_1', 'Componente_2'])\n",
        "\n",
        "# Mostrar el DataFrame resultante\n",
        "display(scaled_features_pca_df_4d_pipe)\n",
        "\n",
        "scaled_features_pca_df_4d_pipe['Cluster'] = cluster_labels_4d_pipe\n",
        "\n",
        "# Graficar los cl√∫sters con Plotly Express\n",
        "fig = px.scatter(scaled_features_pca_df_4d_pipe, x='Componente_1', y='Componente_2', color='Cluster',\n",
        "                 title='Cl√∫sters encontrados por Gaussian Mixture despu√©s de PCA')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9CERnaerqDC"
      },
      "source": [
        "## 6. An√°lisis de resultados üìä"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1yNa111rqDC"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.gifer.com/7wTk.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg0Qx4RZrqDC"
      },
      "source": [
        "Una vez identificado el n√∫mero √≥ptimo de cl√∫sters, se le pide realizar lo siguiente:\n",
        "\n",
        "1. Utilizar la proyecci√≥n en dos dimensiones para visualizar cada cl√∫ster claramente. [2 puntos]\n",
        "\n",
        "2. ¬øEs posible distinguir claramente entre los cl√∫sters generados? [2 puntos]\n",
        "\n",
        "3. Proporcionar una descripci√≥n breve de cada cl√∫ster utilizando estad√≠sticas descriptivas b√°sicas, como la media y la desviaci√≥n est√°ndar, para resumir las caracter√≠sticas de las variables utilizadas en estos algoritmos. [2 puntos]\n",
        "\n",
        "4. Proceda a visualizar los cl√∫sters en tres dimensiones para una perspectiva m√°s detallada. [2 puntos]\n",
        "\n",
        "5. ¬øC√≥mo afecta esto a sus conclusiones anteriores? [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRN0zZip0IMB"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Utilizar la proyecci√≥n en dos dimensiones para visualizar cada cl√∫ster claramente. [2 puntos]\n",
        "\n",
        "\n",
        "### 2. ¬øEs posible distinguir claramente entre los cl√∫sters generados? [2 puntos]\n",
        "Para el caso original con el dataset completo es muy dif√≠cil poder identificar cada cluster al hacer el PCA con dos componentes, es por esto que se intent√≥ realizar con el dataset filtrado de los puntos anteriores, primero solo con las columnas y luego con el filtro completo(pipeline), en el primer caso se obtuvo un resultado similar en que es casi imposible poder identificar cada cluster, en cambio en el √∫ltimo si se logra identificar los clusters aunque no siguen los conjuntos que podr√≠an ser intuitivos por el PCA.\n",
        "\n",
        "\n",
        "### 3. Proporcionar una descripci√≥n breve de cada cl√∫ster utilizando estad√≠sticas descriptivas b√°sicas, como la media y la desviaci√≥n est√°ndar, para resumir las caracter√≠sticas de las variables utilizadas en estos algoritmos. [2 puntos] \n",
        "Como el resultado fue similar se seguir√° trabajando con el que se solicita dataset solo con 4 variables, sin pipeline, ya que seg√∫n la pregunta se puede inferir que hab√≠a que seleccionar caracter√≠sticas y por lo tanto, filtrar el dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmZrz15GrqDC"
      },
      "outputs": [],
      "source": [
        "# Escriba su c√≥digo aqu√≠\n",
        "\n",
        "for i in range(5):\n",
        "    cluster_i = df_4d_with_clustersgmm[df_4d_with_clustersgmm['Cluster'] == i]\n",
        "    print(f\"Cluster {i}:\\nMedia:\\n{cluster_i.mean()}\\nDesviaci√≥n est√°ndar:\\n{cluster_i.std()}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Proceda a visualizar los cl√∫sters en tres dimensiones para una perspectiva m√°s detallada. [2 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear un objeto PCA con el n√∫mero deseado de componentes\n",
        "pca = PCA(n_components=3)\n",
        "\n",
        "# Ajustar el PCA al conjunto de caracter√≠sticas seleccionado\n",
        "pca.fit(df_4d)\n",
        "\n",
        "# Transformar el DataFrame con las caracter√≠sticas seleccionadas\n",
        "scaled_features_pca_df_4d = pca.transform(df_4d)\n",
        "\n",
        "# Generar un DataFrame con el resultado\n",
        "scaled_features_pca_df_4d = pd.DataFrame(scaled_features_pca_df_4d, columns=['Componente_1', 'Componente_2', 'Componente_3'])\n",
        "\n",
        "# Mostrar el DataFrame resultante\n",
        "display(scaled_features_pca_df_4d)\n",
        "\n",
        "scaled_features_pca_df_4d['Cluster'] = cluster_labels_4d\n",
        "\n",
        "# Graficar los cl√∫sters con Plotly Express\n",
        "fig = px.scatter_3d(scaled_features_pca_df_4d, x='Componente_1', y='Componente_2',z='Componente_3', color='Cluster',color_continuous_scale=px.colors.sequential.Viridis,\n",
        "                 title='Cl√∫sters encontrados por Gaussian Mixture despu√©s de PCA')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. ¬øC√≥mo afecta esto a sus conclusiones anteriores? [2 puntos]\n",
        "Si bien en el gr√°fico de tres dimensiones es un poco m√°s f√°cil visualizar los clusters, es solo por la capacidad de rotar, justo por esto mismo se puede observar una separaci√≥n justo en 6 grupos de los datos que es mismo n√∫mero de clusters que recomendaba el an√°lisis por BIC y AIC, pero este tipo de algoritmo  de clustering (Gaussian Mixture) no los separ√≥ de esa forma, lo cual habr√≠a sido muy conveniente para la visualizaci√≥n si hubiera pasado.\n",
        "\n",
        "\n",
        "En conclusi√≥n, se podr√≠a considerar un algoritmo diferente de clustering para poder encontrar este tipo de separaci√≥n o bien encontrar otro tipo de transformaci√≥n de componentes para poder visualizar los clusters obtenidos.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "UQOXod4gHhSq",
        "LkvCfU4N3aQl",
        "BbSqolLKNhup"
      ],
      "provenance": []
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "7cb425aec99b4079954fd707109c42c3",
    "deepnote_persisted_session": {
      "createdAt": "2024-04-26T06:15:51.197Z"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
