{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tgm8mCA9Dp3"
      },
      "source": [
        "# Laboratorio 7: Clasificaci√≥n ü§ó\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos</strong></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Kc_ibM9GXH"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti√°n Tinoco\n",
        "- Auxiliares: Catherine Benavides y Consuelo Rojas\n",
        "- Ayudante: Nicol√°s Ojeda, Eduardo Moya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9dUSltr9JrN"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Manuel Zamorano   \n",
        "- Nombre de alumno 2: Javier Urrutia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBa48PDF9OHw"
      },
      "source": [
        "### Temas a tratar\n",
        "- Clasificaci√≥n en problemas desbalanceados\n",
        "- Lightgbm y xgboost\n",
        "- Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkhnnMx49Qrh"
      },
      "source": [
        "### Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C√≥digo que no se pueda ejecutar, no ser√° revisado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxzJ48Vv8quO"
      },
      "source": [
        "\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender c√≥mo trabajar con problemas de clasificaci√≥n con clases desbalanceadas.\n",
        "- Aplicar los modelos lightgbm y xgboost.\n",
        "- Practicar Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ao0mOU64Ru"
      },
      "source": [
        "# Parte Te√≥rica [12 puntos]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApXKwPDmxcEV"
      },
      "source": [
        "1. Explique cu√°l es la diferencia entre los datos de entrenamiento y validaci√≥n. [1 punto]\n",
        "\n",
        "2. Explique cu√°l es el principal desaf√≠o al trabajar problemas de clasificaci√≥n con data no supervisada. [1 punto]\n",
        "\n",
        "3. Explique en **sus palabras** qu√© es la matriz de confusi√≥n y para qu√© se utiliza. [1 puntos]\n",
        "\n",
        "4. Escriba la f√≥rmula de las siguientes m√©tricas y explique con **sus palabras** c√≥mo se interpretan. [1 punto cada uno]\n",
        "\n",
        "  * Accuracy\n",
        "  * Precision\n",
        "  * Recall\n",
        "  * F1 score\n",
        "\n",
        "5. Explique qu√© m√©trica recomendar√≠a para los siguientes contextos de clasificaci√≥n. [1 punto cada uno]\n",
        "\n",
        "  * Mantenimiento predictivo de fallas de maquinaria pesada en la industria minera.  \n",
        "  * Detecci√≥n de enfermedades altamente contagiosas.\n",
        "  * Aprobaci√≥n de cr√©ditos de alto riesgo.\n",
        "  * Detecci√≥n de cr√≠menes.\n",
        "\n",
        "6. Explique qu√© es la calibraci√≥n de modelos y para qu√© se usa. [1 punto]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy4QMWD8-FPk"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYFdD1aK-ICa"
      },
      "source": [
        "1. Los datos de entrenamiento son una fracci√≥n del dataset general que sirve para poder ajustar el modelo de Machine Learning, por otra parte el conjunto de validaci√≥n se utiliza para poder evaluar el modelo de manera preliminar y as√≠ hacer mejoras al modelo, estos conjuntos generalmente son disjuntos a menos que se utilice validaci√≥n cruzada, lo que hace varias iteraciones de entrenamiento y validaci√≥n rotando los datos por los conjuntos, de todas formas en cada iteraci√≥n estos datos son disjuntos con este m√©todo.\n",
        "\n",
        "\n",
        "2. El principal problema al trabajar con modelos de clasificaci√≥n de data no supervisada es la incertidumbre de las clases a las que se llega, ya que no se tiene claridad de cu√°ntas clases se debe obtener o que tan fino se debe discriminar para determinar si corresponde a una clase y la otra.\n",
        "\n",
        "\n",
        "3. La matriz de confusi√≥n es una matriz que muestra la comparaci√≥n de etiquetas de testeo de los datos y las predichas por el modelo de clasificaci√≥n entrenado sobre los datos de testeo, esta matriz muestra los siguientes valores(para caso binario):\n",
        "En la matriz se muestra la suma de las etiquetas separadas por las siguientes categor√≠as\n",
        "    * True Positive(TP), es cuando una etiqueta es predicha positiva y efectivamente lo es.\n",
        "    * False Positive(FP), es cuando una etiqueta es predicha positiva pero en realidad es negativa\n",
        "    * True Negative(TN), es cuando una etiqueta es predicha negativa y efectivamente lo es.\n",
        "    * False Negative(FN), es cuando una etiqueta es predicha negativa pero en realidad es positiva.\n",
        "   \n",
        "Estos valores sirven para calcular diversas m√©tricas de desempe√±o del modelo.\n",
        "\n",
        "\n",
        "4.\n",
        "  * Accuracy: $ \\frac{TP+TN}{TP+TN+FP+FN} $ \\\n",
        "  -Esta m√©trica muestra que tan bien puede predecir las etiquetas. Sirve mucho cuando son clases balanceadas.\n",
        "\n",
        "\n",
        "  * Precision: $\\frac{TP}{TP+FP}$  \\\n",
        "  -Esta m√©trica muestra la proporci√≥n de las etiquetas predichas correctamente positivas de todas las etiquetas predichas positivas. Sirve para las clases desbalanceadas donde el accuracy no tiene el mejor resultado y se busca minimizar los falsos positivos.\n",
        "\n",
        "\n",
        "  * Recall: $\\frac{TP}{TP+FN}$ \\\n",
        "  -Esta m√©trica muestra la proporci√≥n de etiquetas predichas correctamente positivas de todas las etiquetas efectivamente positivas. Nuevamente sirve para las clases desbalanceadas y busca minimizar los falsos negativos.\n",
        "\n",
        "\n",
        "  * F1 score: $2 \\times \\frac {Precision \\times Recall}{Precision + Recall}$ \\\n",
        "  -Esta m√©trica es una media arm√≥nica de Recall y Precision, en particular para el F1 tienen la misma proporci√≥n ambas m√©tricas, por lo que se busca un balance entre ambas.\n",
        "\n",
        "\n",
        "5.\n",
        "* Mantenimiento predictivo de fallas de maquinaria pesada en la industria minera.  \\\n",
        "  -Para esta situaci√≥n la m√©trica a enfocarse es Recall, ya que es muy importante minimizar los falsos negativos, poder identificar todas las fallas aunque hayan algunas que no correspondan y pasen por falla, ya que si se pasa una falla es peor.\n",
        "* Detecci√≥n de enfermedades altamente contagiosas. \\\n",
        "  -Para este caso es Recall la m√©trica ya que se busca minimizar los falsos negativos, es m√°s importante captar la mayor cantidad de positivos aunque haya una cantidad de falsos positivos, lo importante es no tener falsos negativos ya que esto implicar√≠a no diagnosticar a alguien que s√≠ tiene la enfermedad.\n",
        "\n",
        "\n",
        "* Aprobaci√≥n de cr√©ditos de alto riesgo. \\\n",
        "  -En esta situaci√≥n es importante la m√©trica Precision ya que se busca minimizar los falsos positivos, para el banco es mas importante identificar correctamente los que si son clientes correctos para los cr√©ditos aunque no se reconozcan todos (que hayan falsos negativos), pero los que si se etiquetan sean correctos.\n",
        "\n",
        "\n",
        "* Detecci√≥n de cr√≠menes. \\\n",
        "  -Para este caso es la Precision es la m√©trica m√°s importante, porque es muy importante minimizar a 0 los falsos positivos que en este caso ser√≠an los inocentes predichos como culpables, es mejor asegurarse que los que son detectados como criminales efectivamente lo sean, aunque se pasen algunos como falsos negativos.\n",
        "\n",
        "\n",
        "6.\n",
        "La calibraci√≥n es una probabilidad que muestra el modelo en que la clasificaci√≥n de etiquetas est√© en proporci√≥n con las etiquetas observadas, por eso si las etiquetas observadas es del 70% se esperar√≠a que s√≠ est√° perfectamente calibrado, se obtenga una predicci√≥n del 70%, en caso que no lo est√© este valor ser√≠a diferente(mayor o menor a 70%), es importante mencionar que esta m√©trica es diferente al accuracy, se puede tener perfecta calibraci√≥n pero bajo accuracy.\n",
        "Esta m√©trica se utiliza para analizar las probabilidades asociadas a las predicciones, no es muy √∫til cuando solo se busca el accuracy final del modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg_9jBqtgRDO"
      },
      "source": [
        "# Parte pr√°ctica [48 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slm6yRfdfZwS"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1BnO4tyh3vM2P199Ec9s3JjngQ4qQ9seP\"\n",
        "\" width=\"300\">\n",
        "</p>\n",
        "\n",
        "\n",
        "Tras el tr√°gico despido de la m√≠tica mascota de Maip√∫, Renac√≠n decide adentrarse como consultor en el mercado futbolero, el cu√°l (para variar...) est√° cargado en especulaciones.\n",
        "\n",
        "Como su principal tarea ser√° asesorar a los directivos de los clubes sobre cu√°l jugador comprar y cu√°l no, Renac√≠n desea generar modelos predictivos que evalu√©n distintas caracter√≠sticas de los jugadores; todo con el fin de tomar decisiones concretas basadas en los datos.\n",
        "\n",
        "Sin embargo, su condici√≥n de corporeo le impidi√≥ tomar la versi√≥n anterior de MDS7202, por lo que este motivo Renac√≠n contrata a su equipo para lograr su objetivo final. Dado que a√∫n tiene fuertes v√≠nculos con la direcci√≥n de deportes de la municipalidad, el corporeo le entrega base de datos con las estad√≠sticas de cada jugador para que su equipo empieze a trabajar ya con un dataset listo para ser usado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnbx7RwHfkue"
      },
      "source": [
        "**Los Datos**\n",
        "\n",
        "Para este laboratorio deber√°n trabajar con el csv `statsplayers.csv`, donde deber√°n aplicar algoritmos de aprendizaje supervisado de clasificaci√≥n en base a caracter√≠sticas que describen de jugadores de f√∫tbol.\n",
        "\n",
        "Para comenzar cargue el dataset se√±alado y a continuaci√≥n vea el reporte **`Player_Stats_Report.html`** (adjunto en la carpeta del enunciado) que describe las caracter√≠sticas principales del `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "# Librerias utiles\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX6iwOWUfrp_"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"stats_players.csv\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdcucZhp-M_0"
      },
      "source": [
        "## 1. Predicci√≥n de Seleccionados Nacionales [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXrewqxjjzvA"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://www.futuro.cl/wp-content/uploads/2016/06/chile-argentina-meme-12.jpg\" width=\"300\">\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfre1YsSDqla"
      },
      "source": [
        "### 1.1 Preprocesamiento [5 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR00u4HTDtxv"
      },
      "source": [
        "Tareas:\n",
        "\n",
        "1. Genere los labels para la clasificaci√≥n binaria en una variable llamada `label`. Para esto, trabaje sobre el atributo `National_Position` suponiendo que los valores nulos son jugadores no seleccionados para representar a su pa√≠s. [Sin puntaje]\n",
        "\n",
        "2. Hecho esto, ¬øcu√°ntos se tienen ejemplos por cada clase? Comente lo que observa. [1 punto]\n",
        "\n",
        "3. Genere un `ColumnTransformer` en donde especifique las transformaciones que hay que realizar para cada columna (por ejemplo StandarScaler, MinMaxScaler, OneHotEncoder, etc...) para que puedan ser utilizadas correctamente por el modelo predictivo y gu√°rdelo una variable llamada `col_transformer`. [2 puntos]\n",
        "\n",
        "4. Comente y justifique las transformaciones elegidas sobre cada una de las variables (para esto utilice el material `Player_Stats_Report.html` que viene en el zip del lab), al igual que las transformaciones aplicadas. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgAk0kbPjEsx"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Genere los labels para la clasificaci√≥n binaria en una variable llamada `label`. Para esto, trabaje sobre el atributo `National_Position` suponiendo que los valores nulos son jugadores no seleccionados para representar a su pa√≠s. [Sin puntaje]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label=df['National_Position'].notna()#de esta forma quedan en 0 los NA y 1 los que no\n",
        "label=label.astype(int)\n",
        "df_model1=df.copy()\n",
        "df_model1['label']=label\n",
        "df_model1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Hecho esto, ¬øcu√°ntos se tienen ejemplos por cada clase? Comente lo que observa. [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhC2sZj9dSI1"
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(df_model1, x='label', title='Distribuci√≥n de label')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Respuesta:\n",
        "Se puede observar con el grafico que hay un total de 1075 registros de la clase positiva(seleccionados), por lo que quedarian 16513 de la otra clase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Genere un `ColumnTransformer` en donde especifique las transformaciones que hay que realizar para cada columna (por ejemplo StandarScaler, MinMaxScaler, OneHotEncoder, etc...) para que puedan ser utilizadas correctamente por el modelo predictivo y gu√°rdelo una variable llamada `col_transformer`. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para las columnas que van de 0-100 los valores, se puede interpretar como un porcentaje para esa variable por lo que no es necesario estandarizar, quiz√°s solo se deber√≠an dividir por 100 para que los valores vayan de 0 a 1, para dejar todas las variables num√©ricas de esta forma esto √∫ltimo se aplicar√°.\n",
        "\n",
        "\n",
        "No se aplicar√° nada a National Position ya que a partir de esta variable se construye el label, por lo que no puede ser utilizada para los modelos posteriores, ya que el simple hecho que no tenga valor ya se sabe la etiqueta.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_scale=[ 'Height', 'Weight','Age', 'Weak_foot', 'Skill_Moves']#a estandarizar\n",
        "\n",
        "cols_to_div=['Ball_Control', 'Dribbling', 'Marking', 'Sliding_Tackle',\n",
        "       'Standing_Tackle', 'Aggression', 'Reactions', 'Interceptions', 'Vision',\n",
        "       'Composure', 'Crossing', 'Short_Pass', 'Long_Pass', 'Acceleration',\n",
        "       'Speed', 'Stamina', 'Strength', 'Balance', 'Agility', 'Jumping',\n",
        "       'Heading', 'Shot_Power', 'Finishing', 'Long_Shots', 'Curve',\n",
        "       'Freekick_Accuracy', 'Penalties', 'Volleys']# a dividir por 100\n",
        "cols_to_OHE=[ 'Club_Position','Preffered_Foot', 'Work_Rate']#onehot encoding\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def to_cent(x):\n",
        "    return x*0.01\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "to_cent_transformer = FunctionTransformer(to_cent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "def get_cat(df,var):\n",
        "    ohe_prv = OneHotEncoder() # inicializamos encoder\n",
        "\n",
        "    cod = ohe_prv.fit_transform(df.loc[:, var]) # encodeamos categorias\n",
        "    \n",
        "\n",
        "    cat=ohe_prv.categories_\n",
        "    cate=[]\n",
        "    for i in cat:\n",
        "        cate.extend(i)\n",
        "    return cate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Inicializa el transformer personalizado\n",
        "ohe = OneHotEncoder(sparse_output = False)\n",
        "# Definicion del pipeline\n",
        "\n",
        "\n",
        "scale_transformations = Pipeline([('minmax_scaler', minmax_scaler)])\n",
        "\n",
        "cent_transformations = Pipeline([('to_cent', to_cent_transformer)])\n",
        "\n",
        "OHE_transformations = Pipeline([('ohe', ohe)])\n",
        "\n",
        "# Configuracio el ColumnTransformer\n",
        "column_transformer = ColumnTransformer(transformers=[\n",
        "    ('numerical_to_scale', scale_transformations, cols_to_scale),\n",
        "    ('numerical_to_cent', cent_transformations, cols_to_div),\n",
        "    ('categorical_to_ohe', OHE_transformations, cols_to_OHE)], remainder='drop')\n",
        "\n",
        "\n",
        "\n",
        "# Aplicamos ColumnTransformer a los datos para probar\n",
        "df_pipe = column_transformer.fit_transform(df)\n",
        "\n",
        "df_pipe = pd.DataFrame(df_pipe).copy() # Al parecer no devulve un dataframe\n",
        "cate=get_cat(df,cols_to_OHE)\n",
        "df_pipe.columns = cols_to_scale+ cols_to_div+cate# Por alguna raz√≥n no devuelve los nombres de columnas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv1HOfcNEPF4"
      },
      "source": [
        "### 1.2 Entrenamiento [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPkuXTUBvB0"
      },
      "source": [
        "Ahora, vamos a entrenar los pipelines generados en los pasos anteriores. Para esto, debe realizar las siguientes tareas:\n",
        "\n",
        "1. Separe los datos de entrenamiento en un conjunto de entrenamiento y de prueba  (la proporci√≥n queda a su juicio). En este paso, seleccione los ejemplos de forma aleatoria e intente mantener la distribuci√≥n original de labels de cada clase en los conjuntos de prueba/entrenamiento. (vea la documentaci√≥n de `train_test_split`). [1 puntos]\n",
        "\n",
        "\n",
        "2. Defina un pipeline llamado `pipeline_xgboost` y otro llamado `pipeline_lightgbm`. Estos pipelines deben tener el mismo ColumnTransformer definido en la secci√≥n de preprocesamiento, pero deben variar los clasificadores de acuerdo al nombre de cada pipeline. [1 puntos]\n",
        "\n",
        "3. Entrene los pipelines. [1 punto]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbadONFtjGnE"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLtlXGTPdWAV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ya se sabe qu√© label y national position deben ser dorpeadas pero adem√°s se dropeara Nationality porque al separar los datos en el conjunto de training no quedan todas las nacionalidades y al hacer el predict no logra reconocer todas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_y=df_model1['label'].copy()\n",
        "df_x=df_model1.drop(['label','National_Position'], axis=1).copy()\n",
        "\n",
        "df_train_x,df_test_x, df_train_y,df_test_y= train_test_split(df_x,df_y, test_size=0.2, random_state=42, shuffle=True, stratify=df_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "lgb_model = lgb.LGBMClassifier()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cate=get_cat(df_train_x,cols_to_OHE)\n",
        "\n",
        "pipeline_xgboost=Pipeline([('column_transformer',column_transformer),\n",
        "                           ('to_dataframe', FunctionTransformer(func=lambda x: pd.DataFrame(x, columns=cols_to_scale+ cols_to_div+cate)))\n",
        "                           ,('xgb_model',xgb_model)\n",
        "                           ])\n",
        "\n",
        "pipeline_lightgbm=Pipeline([('column_transformer',column_transformer),\n",
        "                           ('to_dataframe', FunctionTransformer(func=lambda x: pd.DataFrame(x, columns=cols_to_scale+ cols_to_div+cate))),\n",
        "                           ('lgb_model',lgb_model)\n",
        "                           ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xgb_fitted=pipeline_xgboost.fit(df_train_x,df_train_y)\n",
        "\n",
        "lgbm_fitted=pipeline_lightgbm.fit(df_train_x,df_train_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poc9HSNBFeKO"
      },
      "source": [
        "### 1.3 Resultados [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGGCj8YtFil1"
      },
      "source": [
        "1. Calcule las m√©tricas accuracy, precisi√≥n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) para evaluar el rendimiento de los distintos modelos. Verifique sus resultados usando `classification_report`. [2 puntos]\n",
        "\n",
        "2. Explique qu√© implican los valores de accuracy, precisi√≥n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) y c√≥mo influye la cantidad de ejemplos por clase en los resultados obtenidos. [2 puntos]\n",
        "\n",
        "3. Explique qu√© m√©trica le parece m√°s adecuada y concluya qu√© modelo tiene un mejor desempe√±o. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1hkVFdujJTi"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_xgb=xgb_fitted.predict(df_test_x)\n",
        "y_pred_lgbm=lgbm_fitted.predict(df_test_x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "se hara una funcion para calcular las metricas directamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def metricas_mat(mat):\n",
        "    tn, fp, fn, tp=mat.ravel()\n",
        "    Accuracy=(tn+tp)/(tn+fp+tp+fn)\n",
        "    Precision=(tp)/(tp+fp)\n",
        "    Recall= (tp)/(tp+fn)\n",
        "    print('Accuracy:',Accuracy)\n",
        "    print('Precision:',Precision)\n",
        "    print('Recall:',Recall)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "para xbg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Supongamos que tienes tus etiquetas verdaderas y predichas\n",
        "\n",
        "# Calcular la matriz de confusi√≥n\n",
        "matriz_confusion_xbg = confusion_matrix(df_test_y, y_pred_xgb)\n",
        "\n",
        "# Visualizar la matriz de confusi√≥n utilizando seaborn\n",
        "sns.heatmap(matriz_confusion_xbg, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Etiquetas Predichas')\n",
        "plt.ylabel('Etiquetas Verdaderas')\n",
        "plt.title('Matriz de Confusi√≥n de xgboost')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metricas_mat(matriz_confusion_xbg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "se compara con classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(df_test_y, y_pred_xgb)\n",
        "print(report)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "para lgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNmI_tbbdQte"
      },
      "outputs": [],
      "source": [
        "# Supongamos que tienes tus etiquetas verdaderas y predichas\n",
        "\n",
        "# Calcular la matriz de confusi√≥n\n",
        "matriz_confusion_lgbm = confusion_matrix(df_test_y, y_pred_lgbm)\n",
        "\n",
        "# Visualizar la matriz de confusi√≥n utilizando seaborn\n",
        "sns.heatmap(matriz_confusion_lgbm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Etiquetas Predichas')\n",
        "plt.ylabel('Etiquetas Verdaderas')\n",
        "plt.title('Matriz de Confusi√≥n de lightgbm')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metricas_mat(matriz_confusion_lgbm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "report = classification_report(df_test_y, y_pred_lgbm)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Calcule las m√©tricas accuracy, precisi√≥n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) para evaluar el rendimiento de los distintos modelos. Verifique sus resultados usando `classification_report`. [2 puntos]\n",
        "\n",
        "2. Explique qu√© implican los valores de accuracy, precisi√≥n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) y c√≥mo influye la cantidad de ejemplos por clase en los resultados obtenidos. [2 puntos]\n",
        "\n",
        "3. Explique qu√© m√©trica le parece m√°s adecuada y concluya qu√© modelo tiene un mejor desempe√±o. [2 puntos]\n",
        "**Respuesta**\n",
        "1. Se puede observar para ambos casos que las m√©tricas son similares, enfoc√°ndonos en la clase positiva de lo entregado por el classification report, ya que las m√©tricas calculadas manualmente con con respecto a la clase positiva.\n",
        "2. El accuracy es que tan bien predice correctamente las etiquetas, si uno es seleccionado haya sido predicho como tal y si no lo es que haya sido predicho como que no lo es, el precision de todos los que se predijeron con la etiqueta positiva(seleccionado) que porcentaje efectivamente es seleccionado, por otra parte el recall muestra de todos los que son seleccionados qu√© porcentaje fue realmente predicho como seleccionado. Estos resultados son muy diferentes entre etiquetas porque est√°n altamente desbalanceadas, si hubieran sido m√°s los de etiqueta seleccionado habr√≠an sido mejores los resultados.\n",
        "3. En este caso importa m√°s bajar los falsos negativos, que los que son seleccionados efectivamente sean predichos como seleccionados, para esto se utiliza el recall, justamente esta es la m√©trica m√°s baja para los modelos, el que tiene mayor esta m√©trica es el lightgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy5VMU6ae_g6"
      },
      "source": [
        "## 2. Predicci√≥n de posiciones de jugadores [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0PGg_hLgr4H"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://pbs.twimg.com/media/E1rfA1aWEAYU6Ny.jpg\" width=\"300\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6rSnAesfOm3"
      },
      "source": [
        "En una nueva jornada de desmesuradas transacciones deportivas, Renac√≠n escuch√≥ a sus colegas discutir acerca de que el precio de cada jugador depende en gran medida de la posici√≥n en la cancha en la que juega. Y adem√°s, que hay bastantes jugadores nuevos que no tienen muy claro en que posici√≥n verdaderamente brillar√≠an, por lo que actualmente puede que actualmente est√©n jugando en posiciones sub-optimas.\n",
        "\n",
        "Viendo que los resultados del primer an√°lisis no son tan esperanzadores, el corporeo los comanda a cambiar su tarea: ahora, les solicita que construyan un clasificador enfocado en predecir la mejor posici√≥n de los jugadores en la cancha seg√∫n sus caracter√≠sticas.\n",
        "\n",
        "Para lograr esto, primero, les pide que etiqueten de la siguiente manera los valores que aparecen en el atributo `Club_Position`, pidiendo que agrupen los valores en los siguientes grupos:\n",
        "\n",
        "**Nota**:  Renac√≠n les recalca que **no deben utilizar los valores ```Sub``` y ```Res``` de esta columna**.\n",
        "\n",
        "```python\n",
        "ataque = ['ST', 'CF']\n",
        "central_ataque = ['RW', 'CAM', 'LW']\n",
        "central = ['RM', 'CM', 'LM']\n",
        "central_defensa = ['RWB', 'CDM', 'LWB']\n",
        "defensa = ['RB', 'CB', 'LB']\n",
        "arquero = ['GK']\n",
        "```\n",
        "\n",
        "La elecci√≥n del clasificador se justificar en base a la siguiente [gu√≠a](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) y se deben comentar los resultados obtenidos en la clasificaci√≥n.\n",
        "\n",
        "**Tareas:** [1 punto por tarea]\n",
        "\n",
        "1. Aplique las etiquetas descritas anteriormente en cada uno de los valores se√±alados en esta secci√≥n.\n",
        "2. Cuente cu√°ntos por clase quedan.\n",
        "3. Entrene el nuevo pipeline y ejecute una evaluaci√≥n de este.  \n",
        "4. Comente los resultados obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBmSaWh8i2MI"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set(df['Club_Position'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede observar que hay m√°s valores de posici√≥n que los que muestra el enunciado, estos se podr√≠an agregar pero para mantener consistencia se trabajara solo con los mencionados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir_7zMh2i1vg"
      },
      "outputs": [],
      "source": [
        "def cat_CP(dfcol):\n",
        "    label_CP=[]\n",
        "    for i in dfcol:\n",
        "        if i in ['ST', 'CF']:\n",
        "            label_CP.append('ataque')\n",
        "        elif i in ['RW', 'CAM', 'LW']:\n",
        "            label_CP.append('central_ataque')\n",
        "        elif i in ['RM', 'CM', 'LM']:\n",
        "            label_CP.append('central')\n",
        "        elif i in ['RWB', 'CDM', 'LWB']:\n",
        "            label_CP.append('central_defensa')\n",
        "        elif i in ['RB', 'CB', 'LB']:\n",
        "            label_CP.append('defensa')\n",
        "        elif i =='GK':\n",
        "            label_CP.append('arquero')\n",
        "        else:\n",
        "            label_CP.append(np.nan)\n",
        "    return label_CP\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_model2=df.copy()\n",
        "df_model2['label']=cat_CP(df['Club_Position'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_model2.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.histogram(df_model2,x='label', title='Distribuci√≥n de Label')\n",
        "fig.show()\n",
        "pd.DataFrame(df_model2['label']).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Para continuar con el modelo se dropean los que tienen el label =Nan y adem√°s se dropea la variable 'Club_Position' ya que esta es con la que se construy√≥ el label, si se mantiene seria filtrar informaci√≥n.\n",
        "Adem√°s se aplicar√° la transformaci√≥n del punto anterior para dejar todas la variables como num√©ricas(incluyendo los drops de variables como Nationality, Name, National Position)\n",
        "\n",
        "\n",
        "Segun la guia se deber√≠a usar Linear SVC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_model2.dropna(subset=['label'], inplace=True)\n",
        "df_y2=df_model2['label'].copy()\n",
        "df_x2=df_model2.drop(['label','Club_Position'], axis=1).copy()\n",
        "\n",
        "df_train_x2,df_test_x2, df_train_y2,df_test_y2= train_test_split(df_x2,df_y2, test_size=0.2, random_state=42, shuffle=True, stratify=df_y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "cate=get_cat(df_train_x,['Preffered_Foot', 'Work_Rate'])\n",
        "\n",
        "clf = svm.SVC()\n",
        "\n",
        "column_transformer2 = ColumnTransformer(transformers=[\n",
        "    ('numerical_to_scale', scale_transformations, cols_to_scale),\n",
        "    ('numerical_to_cent', cent_transformations, cols_to_div),\n",
        "    ('categorical_to_ohe', OHE_transformations, ['Preffered_Foot', 'Work_Rate'])], remainder='drop')\n",
        "\n",
        "\n",
        "pipeline_svm=Pipeline([('column_transformer2',column_transformer2),\n",
        "                           ('to_dataframe', FunctionTransformer(func=lambda x: pd.DataFrame(x, columns=cols_to_scale+ cols_to_div+cate))),\n",
        "                            ('classifier', clf)\n",
        "                           ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_svm.fit(df_train_x2,df_train_y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_svm=pipeline_svm.predict(df_test_x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "report = classification_report(df_test_y2, y_pred_svm)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede observar que las m√©tricas de manera general son cercanas al 70%, pero algo muy importante a notar es el resultado para la clase arquero, todas la m√©tricas son 100%, esto puede ser producto de data leakage, o quiz√°s hay una variable que tiene mucha relaci√≥n con ser arquero, por lo que se puede deducir la clase por esta variable,\n",
        "En cuanto a las otras clases los resultados son los esperados, aunque para las clases central... el rendimiento es bastante menor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bL2m8nNojXM"
      },
      "source": [
        "## 3. Predicciones de Seleccionados Nacionales para el Jere Klein [30 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2XmRsJdsEh_"
      },
      "source": [
        "<center>\n",
        "<img src='https://www.radioactiva.cl/wp-content/uploads/2024/04/Jere-Klein-1-768x432.webp' width=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgmUoVDsqUPu"
      },
      "source": [
        "Despu√©s de alcanzar la fama como cantante urbano, Jere Klein decide explorar una nueva faceta. Con su amor por el f√∫tbol y convencido de que los artistas urbanos poseen un talento y versatilidad excepcionales, Jere se embarca en un proyecto innovador: desarrollar un sistema de inteligencia artificial capaz de identificar a jugadores que tienen potencial para convertirse en futbolistas profesionales. Su teor√≠a es que muchos artistas del g√©nero urbano chileno, con sus habilidades √∫nicas y su disciplina, podr√≠an destacarse tambi√©n en el deporte. Con este sistema, Jere espera no solo abrir nuevas oportunidades para sus colegas artistas, sino tambi√©n demostrar la amplia gama de talentos que pueden ofrecer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD8pQ5Zfq8dE"
      },
      "source": [
        "### 2.1 ¬øQu√© modelo de √°rbol es m√°s de \"pana\"? [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-KUA4g99eo"
      },
      "source": [
        "<center>\n",
        "<img src='https://64.media.tumblr.com/39189215a7d3d96823cb359f35b44e05/tumblr_psmrhrR3Xw1qf5hjqo4_540.gif' width=300 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL-moVhB9vPH"
      },
      "source": [
        "\n",
        "**Tareas**\n",
        "\n",
        "\n",
        "1. Considerando el la variable llamada `label` creada en la secci√≥n 1.1. Para determinar cu√°l modelo de √°rbol ser√≠a m√°s adecuado para la tarea en cuesti√≥n, utilice PyCaret. Este deber√° centrarse exclusivamente en modelos de tipo √°rbol. Jere ha especificado que busca un modelo que tome decisiones r√°pidamente y que tenga una baja tasa de falsos positivos, ya que planea invertir en estos jugadores. [3 puntos] Para la comparaci√≥n, utilice los siguientes modelos:\n",
        "\n",
        "```python\n",
        "['et', 'rf', 'dt', 'xgboost', 'lightgbm', 'catboost']\n",
        "```\n",
        "\n",
        "3. Explique en brevemente que son los modelos de la siguiente lista `['et', 'rf', 'dt']` y como funcionan. [3 punto]\n",
        "\n",
        "4. Tras realizar la comparaci√≥n de modelos, seleccione aquel que muestre el mejor rendimiento en t√©rminos de velocidad y precisi√≥n, especialmente en la reducci√≥n de falsos positivos. Utilice la funci√≥n `evaluate_model` de PyCaret para revisar y analizar los resultados obtenidos en los siguientes aspectos:\n",
        "\n",
        "  - **Confusi√≥n Matrix**: ¬øC√≥mo se encuentran la tasa de verdaderos positivos y verdaderos negativos?\n",
        "  - **Threshold**: ¬øEs acaso el umbral por defecto del modelo el mejor para las predicciones?\n",
        "  - **Feature Importance**: ¬øCu√°les son las variables con mejor desempe√±o? ¬øA qu√© podr√≠a deberse esto?\n",
        "  - **Learning Curve**: ¬øEl modelo presenta alg√∫n problema?\n",
        "\n",
        "  [4 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#preprocesamiento\n",
        "\n",
        "df_model3=df_model1.copy()\n",
        "\n",
        "df_model3=df_model3.drop(['National_Position','Name',\t'Nationality'],axis=1)\n",
        "\n",
        "df_model3.dropna(subset=['Club_Position'], inplace=True)\n",
        "\n",
        "column_transformer3 = ColumnTransformer(transformers=[\n",
        "    ('numerical_to_scale', scale_transformations, cols_to_scale),\n",
        "    ('numerical_to_cent', cent_transformations, cols_to_div),\n",
        "    ('categorical_to_ohe', OHE_transformations, cols_to_OHE)], remainder='passthrough')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como se busca minimizar los falsos positivos, se ordenar√°n los modelos por precision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importar PyCaret\n",
        "import catboost\n",
        "from pycaret.classification import *\n",
        "df_y3=df_model3['label'].copy()\n",
        "\n",
        "df_x3=df_model3.drop(['label'], axis=1).copy()\n",
        "\n",
        "\n",
        "X3_train, X3_test,y3_train, y3_test= train_test_split(df_x3,df_y3, test_size=0.2, random_state=2024)\n",
        "\n",
        "y3_train.reset_index(drop=True, inplace=True)\n",
        "y3_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "cate=get_cat(df_model3,cols_to_OHE)\n",
        "\n",
        "Modelos3_proce=Pipeline([('column_transformer3',column_transformer3)\n",
        "                   ,('to_dataframe', FunctionTransformer(func=lambda x: pd.DataFrame(x, columns=cols_to_scale+ cols_to_div+cate)))                  \n",
        "                   ])\n",
        "\n",
        "X3_train_proce=Modelos3_proce.fit_transform(X3_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Configurar el entorno de PyCaret\n",
        "clf1 = setup(data=X3_train_proce, target=y3_train, session_id=123, verbose=False)\n",
        "\n",
        "# Comparar solo modelos de tipo √°rbol\n",
        "modelos = ['et', 'rf', 'dt', 'xgboost', 'lightgbm', 'catboost']\n",
        "mejor_modelo = compare_models(include=modelos, sort='Precision')\n",
        "\n",
        "# Ver la comparaci√≥n de modelos\n",
        "comparacion_modelos = pull()\n",
        "\n",
        "\n",
        "evaluate_model(mejor_modelo)\n",
        "\n",
        "\n",
        "# Evaluar el mejor modelo seleccionado\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "metricas de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X3_test_proce=Modelos3_proce.fit_transform(X3_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelo_seleccion = finalize_model(mejor_modelo)\n",
        "\n",
        "\n",
        "# Hacer predicciones en datos de prueba\n",
        "predicciones = predict_model(modelo_seleccion, data=X3_test_proce)\n",
        "\n",
        "# Evaluar el modelo final\n",
        "evaluacion = classification_report(predicciones['prediction_label'], y3_test)\n",
        "print(evaluacion)\n",
        "\n",
        "# Calcular la matriz de confusi√≥n\n",
        "matriz_confusion_et = confusion_matrix( y3_test,predicciones['prediction_label'])\n",
        "\n",
        "# Visualizar la matriz de confusi√≥n utilizando seaborn\n",
        "sns.heatmap(matriz_confusion_et, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Etiquetas Predichas')\n",
        "plt.ylabel('Etiquetas Verdaderas')\n",
        "plt.title('Matriz de Confusi√≥n de Extra Trees Classifier')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY85nrViYROF"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Modelos:\n",
        "* dt= Decision Tree Classifier: es el modelo base de clasificaci√≥n por √°rboles, este va dividiendo los features para encontrar una forma de caracterizar las diferentes clases, este puede tener diferentes criterios para la divisi√≥n, cada nodo es un feature para esta separaci√≥n.\n",
        "* rf=Random Forest Classifier: Este modelo es una versi√≥n m√°s compleja que el anterior ya que es del tipo ensemble, consta de muchos √°rboles que se entrenan con subconjuntos de las caracter√≠sticas de manera aleatoria, este modelo toma m√°s tiempo en ser entrenado pero a su vez obtiene mejores resultados que un solo √°rbol.\n",
        "* et=Extra Trees Classifier: Este modelo es similar al random forest pero va un paso m√°s all√°, porque tambi√©n selecciona de manera aleatoria el umbral de cada √°rbol, este modelo tiene menor varianza que el rf y toma menos tiempo en entrenarse, aunque no siempre tiene mejor resultado.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "4.  \n",
        "\n",
        "\n",
        "  - **Confusi√≥n Matrix**: ¬øC√≥mo se encuentran la tasa de verdaderos positivos y verdaderos negativos?\n",
        "    - Como se enfoc√≥ principalmente en la m√©trica precisi√≥n, se minimiz√≥ los falsos positivos, teniendo en cuenta las medidas obtenidas en el test, las tasas son:\\\n",
        "        $FPR=\\frac{1}{(3295+1)}=0.0003$\\\n",
        "        $FNR=\\frac{210}{(210+12)}=0.9459$\n",
        "     \n",
        "  - **Threshold**: ¬øEs acaso el umbral por defecto del modelo el mejor para las predicciones?\n",
        "    - el umbral por defecto seg√∫n el gr√°fico ser√≠a 0.19, este ser√≠a el mejor para tener las m√©tricas f1, recall y precisi√≥n con valores parecidos, pero en particular para este modelo se buscaba minimizar los falsos positivos, es decir maximizar la precisi√≥n, por lo que el threshold es mayor que el que muestra por defecto.\n",
        "  - **Feature Importance**: ¬øCu√°les son las variables con mejor desempe√±o? ¬øA qu√© podr√≠a deberse esto?\n",
        "    - Las variables con mejor desempe√±o son reactions, composure, stamina, vision, etc. esto se puede deber a que son las que m√°s correlaci√≥n tengan con el label del modelo.\n",
        "  - **Learning Curve**: ¬øEl modelo presenta alg√∫n problema?\n",
        "    -En particular para este caso no se ve alg√∫n problema, se consigui√≥ valores altos para el cv y casi constantes en funci√≥n de las instancias.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8DSS3u1xMpB"
      },
      "source": [
        "### 2.2 Reducci√≥n de dimensionalidad [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLu0543p876P"
      },
      "source": [
        "<center>\n",
        "<img src='https://i.kym-cdn.com/photos/images/original/002/258/560/668.gif' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT-bxJ0txwNF"
      },
      "source": [
        "A pesar de los resultados obtenidos previamente, el manager de Jere ha solicitado el entrenamiento de un modelo de XGBoost utilizando los datos disponibles. Adem√°s, se debe proceder a realizar una reducci√≥n de dimensionalidad basada en la importancia de las caracter√≠sticas.\n",
        "\n",
        "Para llevar a cabo esta tarea:\n",
        "\n",
        "1. Inicie entrenando un modelo XGBoost con todas las caracter√≠sticas disponibles. [2 puntos]\n",
        "\n",
        "2. Una vez el modelo est√© entrenado, eval√∫e y clasifique las caracter√≠sticas seg√∫n su importancia de forma descendente. [2 puntos]\n",
        "\n",
        "3. Utilice esta clasificaci√≥n para ejecutar una b√∫squeda recursiva de eliminaci√≥n de caracter√≠sticas, eliminando progresivamente las menos importantes y evaluando el impacto en el desempe√±o del modelo hasta identificar las N caracter√≠sticas m√°s cr√≠ticas. [2 puntos]\n",
        "\n",
        "4. Con este conjunto reducido de caracter√≠sticas, entrene un nuevo modelo y eval√∫e su rendimiento. [2 puntos]\n",
        "\n",
        "5. Posteriormente, responda a las siguientes preguntas para una comprensi√≥n m√°s profunda de los cambios y beneficios:\n",
        "\n",
        "  - ¬øEl rendimiento del modelo con las caracter√≠sticas seleccionadas es similar al del modelo original? ¬øC√≥mo se comparan en t√©rminos de precisi√≥n y robustez? [2 puntos]\n",
        "  - ¬øCu√°les son los beneficios potenciales de eliminar variables del modelo? Considere factores como la simplificaci√≥n del modelo, reducci√≥n del tiempo de entrenamiento, y mejora en la capacidad de generalizaci√≥n. [2 puntos]\n",
        "  - Comente si el modelo con menor dimensionalidad es m√°s sencillo de explicar. Explique brevemente por qu√© la eliminaci√≥n de ciertas caracter√≠sticas puede facilitar la comprensi√≥n y la explicaci√≥n del comportamiento del modelo. [2 puntos]\n",
        "\n",
        "Notar que con esta metodologia buscamos encontrar un punto entermedio entre n√∫mero de festures y desempe√±o. por esto, si observa que al aumentar festires el aumento es despreciable, puede no considerar agregar m√°s features a su modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHfmK63TuDOS"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQwUd_nsuDOe"
      },
      "outputs": [],
      "source": [
        "xgb_model4 = xgb.XGBClassifier()\n",
        "\n",
        "pipeline_xgboost4=Pipeline([('column_transformer3',column_transformer),\n",
        "                           ('to_dataframe', FunctionTransformer(func=lambda x: pd.DataFrame(x, columns=cols_to_scale+ cols_to_div+cate)))\n",
        "                           ,('xgb_model',xgb_model4)\n",
        "                           ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model4=pipeline_xgboost4.fit(X3_train,y3_train)\n",
        "\n",
        "model4pred=model4.predict(X3_test)\n",
        "\n",
        "evaluacion = classification_report(model4pred, y3_test)\n",
        "print(evaluacion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "columns_names = cols_to_scale+ cols_to_div+cate\n",
        "\n",
        "\n",
        "feat_importances = pd.DataFrame(\n",
        "    model4['xgb_model'].feature_importances_,\n",
        "    index=columns_names, \n",
        "    columns=[\"Importance\"]\n",
        ")\n",
        "feat_importances.sort_values(by='Importance', ascending=True, inplace=True)\n",
        "feat_importances.plot(kind='barh', figsize=(10,12), legend=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "def plot_line(x, y):\n",
        "    # Crear una figura\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # A√±adir la l√≠nea principal\n",
        "    fig.add_trace(go.Scatter(x=x, y=y, mode='lines', name='Main Line'))\n",
        "\n",
        "\n",
        "    # Establecer el dise√±o del gr√°fico\n",
        "    fig.update_layout(title='Precisi√≥n del modelo con el n√∫mero de features',\n",
        "                      template='simple_white',\n",
        "                      showlegend=False,\n",
        "                      xaxis_title='N√∫mero de features eliminadas',\n",
        "                      yaxis_title='Score')\n",
        "\n",
        "    # Mostrar el gr√°fico\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Obtenemos X para el train para el ejemplo\n",
        "array_X = model4['column_transformer3'].fit_transform(X3_train)\n",
        "cols_trans_name = cols_to_scale+ cols_to_div+cate\n",
        "new_X_train = pd.DataFrame(array_X, columns=cols_trans_name)\n",
        "\n",
        "# Lista para almacenar la precisi√≥n del modelo con cada n√∫mero de caracter√≠sticas\n",
        "precision_scores = []\n",
        "\n",
        "# Crear un selector de caracter√≠sticas recursivo con validaci√≥n cruzada\n",
        "clf = model4['xgb_model']\n",
        "\n",
        "# Iterar sobre las caracter√≠sticas y evaluar el modelo con cada adici√≥n\n",
        "for i in range(0, len(cols_trans_name) + 1):\n",
        "    # Seleccionar las primeras i caracter√≠sticas\n",
        "    selected_features = feat_importances.index[-(len(cols_trans_name)+1 -i):]\n",
        "    scores = cross_val_score(\n",
        "        clf, new_X_train[selected_features], \n",
        "        y3_train, cv=5, scoring='precision_macro'\n",
        "    )    \n",
        "    # Almacenar la precisi√≥n del modelo con i caracter√≠sticas\n",
        "    precision_scores.append(scores)\n",
        "\n",
        "# Calcular variaci√≥n de los puntos\n",
        "x = [i for i in range(0, len(cols_trans_name) + 1)]\n",
        "y = np.array(precision_scores).mean(axis=1)\n",
        "std = np.array(precision_scores).std(axis=1)\n",
        "\n",
        "plot_line(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por el gr√°fico se puede ver que var√≠a mucho c√≥mo afecta el eliminar las diferentes variables, no se ve necesariamente una disminuci√≥n de rendimiento, es m√°s, ocurre lo contrario cuando solo quedan las variables m√°s importantes, el rendimiento crece. Llegando al m√°ximo dejando las 3 variables m√°s importantes. Es por esto que se va a entrenar el modelo y evaluar con las tres variables principales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_features_filtered = feat_importances.index[-(len(cols_trans_name)+1 -71):]\n",
        "clf2= xgb.XGBClassifier()\n",
        "clf2.fit(new_X_train[selected_features_filtered],y3_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "array_X_test = model4['column_transformer3'].fit_transform(X3_test)\n",
        "cols_trans_name = cols_to_scale+ cols_to_div+cate\n",
        "new_X_test = pd.DataFrame(array_X_test, columns=cols_trans_name)\n",
        "\n",
        "ypred_4filtered=clf2.predict(new_X_test[selected_features_filtered])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluacion = classification_report(ypred_4filtered, y3_test)\n",
        "print(evaluacion)\n",
        "\n",
        "# Calcular la matriz de confusi√≥n\n",
        "matriz_confusion_et = confusion_matrix( y3_test,ypred_4filtered)\n",
        "\n",
        "# Visualizar la matriz de confusi√≥n utilizando seaborn\n",
        "sns.heatmap(matriz_confusion_et, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Etiquetas Predichas')\n",
        "plt.ylabel('Etiquetas Verdaderas')\n",
        "plt.title('Matriz de Confusi√≥n de Extra Trees Classifier')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Posteriormente, responda a las siguientes preguntas para una comprensi√≥n m√°s profunda de los cambios y beneficios:\n",
        "\n",
        "\n",
        "  - ¬øEl rendimiento del modelo con las caracter√≠sticas seleccionadas es similar al del modelo original? ¬øC√≥mo se comparan en t√©rminos de precisi√≥n y robustez? [2 puntos]\n",
        "    - el rendimiento en accuracy es similar pero con las otras m√©tricas es menor para el modelo m√°s simplificado, o al menos enfocado en la clase positiva, por eso en precisi√≥n es similar pero en robustez al ser un modelo m√°s simple deber√≠a tender a ser m√°s generalizable y por lo tanto m√°s robusto.\n",
        "  - ¬øCu√°les son los beneficios potenciales de eliminar variables del modelo? Considere factores como la simplificaci√≥n del modelo, reducci√≥n del tiempo de entrenamiento, y mejora en la capacidad de generalizaci√≥n. [2 puntos]\n",
        "    - Eliminar variables del modelo simplifica el entrenamiento de este, esto se refleja en un menor tiempo de entrenamiento, en el caso de √°rboles, √°rboles con menos profundidad, adem√°s al tener menos variables se reduce la posibilidad de sobreajuste del modelo.\n",
        "  - Comente si el modelo con menor dimensionalidad es m√°s sencillo de explicar. Explique brevemente por qu√© la eliminaci√≥n de ciertas caracter√≠sticas puede facilitar la comprensi√≥n y la explicaci√≥n del comportamiento del modelo. [2 puntos]\n",
        "    - El modelo efectivamente es m√°s sencillo de explicar ya que hay menos variables que considerar y menos interrelaciones entre estas que puedan mostrar la influencia en las clases a predecir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTG5cH9r3M9g"
      },
      "source": [
        "### 2.3 Calibraci√≥n Probabilistica [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDL0VqjR7yvb"
      },
      "source": [
        "<center>\n",
        "<img src='https://media2.giphy.com/media/l2Je4Ku0Cx292KWv6/200w.gif?cid=6c09b952y0sihtq9tb6sz8j2023x3zxxp3qx1ocgonkpkblj&ep=v1_gifs_search&rid=200w.gif&ct=g' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmOKxhAw3sic"
      },
      "source": [
        "Para lograr modelos m√°s modulares, se recomienda realizar una calibraci√≥n del modelo entrenado anteriormente, con el objetivo de obtener salidas que reflejen mayor modularidad.\n",
        "\n",
        "1. Se solicita que utilice un m√©todo de calibraci√≥n que asegure que las probabilidades generadas incrementen de manera mon√≥tona. Una m√©trica ampliamente utilizada para evaluar la precisi√≥n de la calibraci√≥n de un modelo es el Brier Score. Calcule el Brier Score para el modelo tanto antes como despu√©s de la calibraci√≥n. Esto le permitir√° realizar una comparaci√≥n cuantitativa y determinar si la calibraci√≥n ha mejorado el rendimiento del modelo. Para m√°s informaci√≥n sobre el Brier Score, puede consultar el siguiente enlace: [Scikit-Learn - Brier Score Loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html). [3 puntos]\n",
        "\n",
        "2. Tras la calibraci√≥n, examine y comente los resultados obtenidos. A su an√°lisis a√±ada una comparaci√≥n visual de las ideales versus las salidas del modelo original (sin calibrar) y del modelo calibrado. [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIiYz_qLuD19"
      },
      "source": [
        "Para la calibraci√≥n se utilizar√° el modelo reducido que fue el √∫ltimo que se entren√≥."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0bfSuiFuD2I"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import brier_score_loss\n",
        "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
        "\n",
        "# Obtener las probabilidades predichas del modelo sin calibrar\n",
        "probabilities_uncalibrated = clf2.predict_proba(new_X_test[selected_features_filtered])[:, 1]\n",
        "\n",
        "# Calcular el Brier Score del modelo sin calibrar\n",
        "brier_score_uncalibrated = brier_score_loss(y3_test, probabilities_uncalibrated)\n",
        "print(f\"Brier Score (sin calibrar): {brier_score_uncalibrated}\")\n",
        "\n",
        "calibrated_model = CalibratedClassifierCV(clf2, method='isotonic', cv='prefit')\n",
        "calibrated_model.fit(new_X_train[selected_features_filtered],y3_train)\n",
        "\n",
        "# Obtener las probabilidades predichas del modelo calibrado\n",
        "probabilities_calibrated = calibrated_model.predict_proba(new_X_test[selected_features_filtered])[:, 1]\n",
        "\n",
        "# Calcular el Brier Score del modelo calibrado\n",
        "brier_score_calibrated = brier_score_loss(y3_test, probabilities_calibrated)\n",
        "print(f\"Brier Score (calibrado): {brier_score_calibrated}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generar el gr√°fico de calibraci√≥n\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "\n",
        "fraction_of_positives_uncalibrated, mean_predicted_value_uncalibrated = calibration_curve(y3_test, probabilities_uncalibrated, n_bins=10)\n",
        "fraction_of_positives_calibrated, mean_predicted_value_calibrated = calibration_curve(y3_test, probabilities_calibrated, n_bins=10)\n",
        "\n",
        "plt.plot(mean_predicted_value_uncalibrated, fraction_of_positives_uncalibrated, \"s-\", label=\"Sin calibrar\")\n",
        "plt.plot(mean_predicted_value_calibrated, fraction_of_positives_calibrated, \"s-\", label=\"Calibrado\")\n",
        "\n",
        "# Graficar la l√≠nea de referencia perfecta\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfectamente calibrado\")\n",
        "\n",
        "plt.xlabel(\"Probabilidad predicha\")\n",
        "plt.ylabel(\"Fracci√≥n de positivos\")\n",
        "plt.title(\"Gr√°fico de Calibraci√≥n\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta**\n",
        "Tras la calibraci√≥n se puede notar un ligero aumento en la m√©trica Brier Score, en el gr√°fico tambi√©n se puede notar una ligera diferencia en la calibraci√≥n con respecto al original, la principal diferencia se encuentra en el valor de probabilidad predicha que se obtiene el 100% de fracci√≥n de positivos, siendo el modelo calibrado donde se corresponde mejor con la calibraci√≥n perfecta."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "k-ao0mOU64Ru",
        "Jg_9jBqtgRDO",
        "JdcucZhp-M_0",
        "Qfre1YsSDqla",
        "Bv1HOfcNEPF4",
        "poc9HSNBFeKO",
        "uy5VMU6ae_g6",
        "9bL2m8nNojXM",
        "rD8pQ5Zfq8dE",
        "K8DSS3u1xMpB",
        "PTG5cH9r3M9g"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
