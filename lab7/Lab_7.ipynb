{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tgm8mCA9Dp3"
      },
      "source": [
        "# Laboratorio 7: Clasificación 🤗\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Kc_ibM9GXH"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebastián Tinoco\n",
        "- Auxiliares: Catherine Benavides y Consuelo Rojas\n",
        "- Ayudante: Nicolás Ojeda, Eduardo Moya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9dUSltr9JrN"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n",
        "\n",
        "- Nombre de alumno 1: Manuel Zamorano   \n",
        "- Nombre de alumno 2: Javier Urrutia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBa48PDF9OHw"
      },
      "source": [
        "### Temas a tratar\n",
        "- Clasificación en problemas desbalanceados\n",
        "- Lightgbm y xgboost\n",
        "- Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkhnnMx49Qrh"
      },
      "source": [
        "### Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- Código que no se pueda ejecutar, no será revisado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxzJ48Vv8quO"
      },
      "source": [
        "\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender cómo trabajar con problemas de clasificación con clases desbalanceadas.\n",
        "- Aplicar los modelos lightgbm y xgboost.\n",
        "- Practicar Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ao0mOU64Ru"
      },
      "source": [
        "# Parte Teórica [12 puntos]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApXKwPDmxcEV"
      },
      "source": [
        "1. Explique cuál es la diferencia entre los datos de entrenamiento y validación. [1 punto]\n",
        "\n",
        "2. Explique cuál es el principal desafío al trabajar problemas de clasificación con data no supervisada. [1 punto]\n",
        "\n",
        "3. Explique en **sus palabras** qué es la matriz de confusión y para qué se utiliza. [1 puntos]\n",
        "\n",
        "4. Escriba la fórmula de las siguientes métricas y explique con **sus palabras** cómo se interpretan. [1 punto cada uno]\n",
        "\n",
        "  * Accuracy\n",
        "  * Precision\n",
        "  * Recall\n",
        "  * F1 score\n",
        "\n",
        "5. Explique qué métrica recomendaría para los siguientes contextos de clasificación. [1 punto cada uno]\n",
        "\n",
        "  * Mantenimiento predictivo de fallas de maquinaria pesada en la industria minera.  \n",
        "  * Detección de enfermedades altamente contagiosas.\n",
        "  * Aprobación de créditos de alto riesgo.\n",
        "  * Detección de crímenes.\n",
        "\n",
        "6. Explique qué es la calibración de modelos y para qué se usa. [1 punto]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy4QMWD8-FPk"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYFdD1aK-ICa"
      },
      "source": [
        "1. Los datos de entrenamiento son una fracción del dataset general que sirve para poder ajustar el modelo de Machine Learning, por otra parte el conjunto de validación se utiliza para poder evaluar el modelo de manera preliminar y así hacer mejoras al modelo, estos conjuntos generalmente son disjuntos a menos que se utilice validación cruzada, lo que hace varias iteraciones de entrenamiento y validación rotando los datos por los conjuntos, de todas formas en cada iteración estos datos son disjuntos con este método.\n",
        "\n",
        "\n",
        "2. El principal problema al trabajar con modelos de clasificación de data no supervisada es la incertidumbre de las clases a las que se llega, ya que no se tiene claridad de cuántas clases se debe obtener o que tan fino se debe discriminar para determinar si corresponde a una clase y la otra.\n",
        "\n",
        "\n",
        "3. La matriz de confusión es una matriz que muestra la comparación de etiquetas de testeo de los datos y las predichas por el modelo de clasificación entrenado sobre los datos de testeo, esta matriz muestra los siguientes valores(para caso binario):\n",
        "En la matriz se muestra la suma de las etiquetas separadas por las siguientes categorías\n",
        "    * True Positive(TP), es cuando una etiqueta es predicha positiva y efectivamente lo es.\n",
        "    * False Positive(FP), es cuando una etiqueta es predicha positiva pero en realidad es negativa\n",
        "    * True Negative(TN), es cuando una etiqueta es predicha negativa y efectivamente lo es.\n",
        "    * False Negative(FN), es cuando una etiqueta es predicha negativa pero en realidad es positiva.\n",
        "   \n",
        "Estos valores sirven para calcular diversas métricas de desempeño del modelo.\n",
        "\n",
        "\n",
        "4.\n",
        "  * Accuracy: $ \\frac{TP+TN}{TP+TN+FP+FN} $ \\\n",
        "  -Esta métrica muestra que tan bien puede predecir las etiquetas. Sirve mucho cuando son clases balanceadas.\n",
        "\n",
        "\n",
        "  * Precision: $\\frac{TP}{TP+FP}$  \\\n",
        "  -Esta métrica muestra la proporción de las etiquetas predichas correctamente positivas de todas las etiquetas predichas positivas. Sirve para las clases desbalanceadas donde el accuracy no tiene el mejor resultado y se busca minimizar los falsos positivos.\n",
        "\n",
        "\n",
        "  * Recall: $\\frac{TP}{TP+FN}$ \\\n",
        "  -Esta métrica muestra la proporción de etiquetas predichas correctamente positivas de todas las etiquetas efectivamente positivas. Nuevamente sirve para las clases desbalanceadas y busca minimizar los falsos negativos.\n",
        "\n",
        "\n",
        "  * F1 score: $2 \\times \\frac {Precision \\times Recall}{Precision + Recall}$ \\\n",
        "  -Esta métrica es una media armónica de Recall y Precision, en particular para el F1 tienen la misma proporción ambas métricas, por lo que se busca un balance entre ambas.\n",
        "\n",
        "\n",
        "5.\n",
        "* Mantenimiento predictivo de fallas de maquinaria pesada en la industria minera.  \\\n",
        "  -Para esta situación la métrica a enfocarse es Recall, ya que es muy importante minimizar los falsos negativos, poder identificar todas las fallas aunque hayan algunas que no correspondan y pasen por falla, ya que si se pasa una falla es peor.\n",
        "* Detección de enfermedades altamente contagiosas. \\\n",
        "  -Para este caso es Recall la métrica ya que se busca minimizar los falsos negativos, es más importante captar la mayor cantidad de positivos aunque haya una cantidad de falsos positivos, lo importante es no tener falsos negativos ya que esto implicaría no diagnosticar a alguien que sí tiene la enfermedad.\n",
        "\n",
        "\n",
        "* Aprobación de créditos de alto riesgo. \\\n",
        "  -En esta situación es importante la métrica Precision ya que se busca minimizar los falsos positivos, para el banco es mas importante identificar correctamente los que si son clientes correctos para los créditos aunque no se reconozcan todos (que hayan falsos negativos), pero los que si se etiquetan sean correctos.\n",
        "\n",
        "\n",
        "* Detección de crímenes. \\\n",
        "  -Para este caso es la Precision es la métrica más importante, porque es muy importante minimizar a 0 los falsos positivos que en este caso serían los inocentes predichos como culpables, es mejor asegurarse que los que son detectados como criminales efectivamente lo sean, aunque se pasen algunos como falsos negativos.\n",
        "\n",
        "\n",
        "6.\n",
        "La calibración es una probabilidad que muestra el modelo en que la clasificación de etiquetas esté en proporción con las etiquetas observadas, por eso si las etiquetas observadas es del 70% se esperaría que sí está perfectamente calibrado, se obtenga una predicción del 70%, en caso que no lo esté este valor sería diferente(mayor o menor a 70%), es importante mencionar que esta métrica es diferente al accuracy, se puede tener perfecta calibración pero bajo accuracy.\n",
        "Esta métrica se utiliza para analizar las probabilidades asociadas a las predicciones, no es muy útil cuando solo se busca el accuracy final del modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg_9jBqtgRDO"
      },
      "source": [
        "# Parte práctica [48 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slm6yRfdfZwS"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1BnO4tyh3vM2P199Ec9s3JjngQ4qQ9seP\"\n",
        "\" width=\"300\">\n",
        "</p>\n",
        "\n",
        "\n",
        "Tras el trágico despido de la mítica mascota de Maipú, Renacín decide adentrarse como consultor en el mercado futbolero, el cuál (para variar...) está cargado en especulaciones.\n",
        "\n",
        "Como su principal tarea será asesorar a los directivos de los clubes sobre cuál jugador comprar y cuál no, Renacín desea generar modelos predictivos que evaluén distintas características de los jugadores; todo con el fin de tomar decisiones concretas basadas en los datos.\n",
        "\n",
        "Sin embargo, su condición de corporeo le impidió tomar la versión anterior de MDS7202, por lo que este motivo Renacín contrata a su equipo para lograr su objetivo final. Dado que aún tiene fuertes vínculos con la dirección de deportes de la municipalidad, el corporeo le entrega base de datos con las estadísticas de cada jugador para que su equipo empieze a trabajar ya con un dataset listo para ser usado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnbx7RwHfkue"
      },
      "source": [
        "**Los Datos**\n",
        "\n",
        "Para este laboratorio deberán trabajar con el csv `statsplayers.csv`, donde deberán aplicar algoritmos de aprendizaje supervisado de clasificación en base a características que describen de jugadores de fútbol.\n",
        "\n",
        "Para comenzar cargue el dataset señalado y a continuación vea el reporte **`Player_Stats_Report.html`** (adjunto en la carpeta del enunciado) que describe las características principales del `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "# Librerias utiles\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX6iwOWUfrp_"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"stats_players.csv\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdcucZhp-M_0"
      },
      "source": [
        "## 1. Predicción de Seleccionados Nacionales [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXrewqxjjzvA"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://www.futuro.cl/wp-content/uploads/2016/06/chile-argentina-meme-12.jpg\" width=\"300\">\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfre1YsSDqla"
      },
      "source": [
        "### 1.1 Preprocesamiento [5 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR00u4HTDtxv"
      },
      "source": [
        "Tareas:\n",
        "\n",
        "1. Genere los labels para la clasificación binaria en una variable llamada `label`. Para esto, trabaje sobre el atributo `National_Position` suponiendo que los valores nulos son jugadores no seleccionados para representar a su país. [Sin puntaje]\n",
        "\n",
        "2. Hecho esto, ¿cuántos se tienen ejemplos por cada clase? Comente lo que observa. [1 punto]\n",
        "\n",
        "3. Genere un `ColumnTransformer` en donde especifique las transformaciones que hay que realizar para cada columna (por ejemplo StandarScaler, MinMaxScaler, OneHotEncoder, etc...) para que puedan ser utilizadas correctamente por el modelo predictivo y guárdelo una variable llamada `col_transformer`. [2 puntos]\n",
        "\n",
        "4. Comente y justifique las transformaciones elegidas sobre cada una de las variables (para esto utilice el material `Player_Stats_Report.html` que viene en el zip del lab), al igual que las transformaciones aplicadas. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgAk0kbPjEsx"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Genere los labels para la clasificación binaria en una variable llamada `label`. Para esto, trabaje sobre el atributo `National_Position` suponiendo que los valores nulos son jugadores no seleccionados para representar a su país. [Sin puntaje]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label=df['National_Position'].notna()#de esta forma quedan en 0 los NA y 1 los que no\n",
        "label=label.astype(int)\n",
        "df_model1=df.copy()\n",
        "df_model1['label']=label\n",
        "df_model1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Hecho esto, ¿cuántos se tienen ejemplos por cada clase? Comente lo que observa. [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhC2sZj9dSI1"
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(df_model1, x='label', title='Distribución de label')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Respuesta:\n",
        "Se puede observar con el grafico que hay un total de 1075 registros de la clase positiva(seleccionados), por lo que quedarian 16513 de la otra clase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Genere un `ColumnTransformer` en donde especifique las transformaciones que hay que realizar para cada columna (por ejemplo StandarScaler, MinMaxScaler, OneHotEncoder, etc...) para que puedan ser utilizadas correctamente por el modelo predictivo y guárdelo una variable llamada `col_transformer`. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para las columnas que van de 0-100 los valores, se puede interpretar como un porcentaje para esa variable por lo que no es necesario estandarizar, quizás solo se deberían dividir por 100 para que los valores vayan de 0 a 1, para dejar todas las variables numéricas de esta forma esto último se aplicará.\n",
        "\n",
        "\n",
        "No se aplicará nada a National Position ya que a partir de esta variable se construye el label, por lo que no puede ser utilizada para los modelos posteriores, ya que el simple hecho que no tenga valor ya se sabe la etiqueta.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_scale=[ 'Height', 'Weight','Age', 'Weak_foot', 'Skill_Moves']#a estandarizar\n",
        "\n",
        "cols_to_div=['Ball_Control', 'Dribbling', 'Marking', 'Sliding_Tackle',\n",
        "       'Standing_Tackle', 'Aggression', 'Reactions', 'Interceptions', 'Vision',\n",
        "       'Composure', 'Crossing', 'Short_Pass', 'Long_Pass', 'Acceleration',\n",
        "       'Speed', 'Stamina', 'Strength', 'Balance', 'Agility', 'Jumping',\n",
        "       'Heading', 'Shot_Power', 'Finishing', 'Long_Shots', 'Curve',\n",
        "       'Freekick_Accuracy', 'Penalties', 'Volleys']# a dividir por 100\n",
        "cols_to_OHE=[ 'Club_Position','Preffered_Foot', 'Work_Rate']#onehot encoding\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def to_cent(x):\n",
        "    return x*0.01\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "to_cent_transformer = FunctionTransformer(to_cent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "def get_cat(df,var):\n",
        "    ohe_prv = OneHotEncoder() # inicializamos encoder\n",
        "\n",
        "    cod = ohe_prv.fit_transform(df.loc[:, var]) # encodeamos categorias\n",
        "    \n",
        "\n",
        "    cat=ohe_prv.categories_\n",
        "    cate=[]\n",
        "    for i in cat:\n",
        "        cate.extend(i)\n",
        "    return cate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Inicializa el transformer personalizado\n",
        "ohe = OneHotEncoder(sparse_output = False)\n",
        "# Definicion del pipeline\n",
        "\n",
        "\n",
        "scale_transformations = Pipeline([('minmax_scaler', minmax_scaler)])\n",
        "\n",
        "cent_transformations = Pipeline([('to_cent', to_cent_transformer)])\n",
        "\n",
        "OHE_transformations = Pipeline([('ohe', ohe)])\n",
        "\n",
        "# Configuracio el ColumnTransformer\n",
        "column_transformer = ColumnTransformer(transformers=[\n",
        "    ('numerical_to_scale', scale_transformations, cols_to_scale),\n",
        "    ('numerical_to_cent', cent_transformations, cols_to_div),\n",
        "    ('categorical_to_ohe', OHE_transformations, cols_to_OHE)], remainder='drop')\n",
        "\n",
        "\n",
        "\n",
        "# Aplicamos ColumnTransformer a los datos para probar\n",
        "df_pipe = column_transformer.fit_transform(df)\n",
        "\n",
        "df_pipe = pd.DataFrame(df_pipe).copy() # Al parecer no devulve un dataframe\n",
        "cate=get_cat(df,cols_to_OHE)\n",
        "df_pipe.columns = cols_to_scale+ cols_to_div+cate# Por alguna razón no devuelve los nombres de columnas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv1HOfcNEPF4"
      },
      "source": [
        "### 1.2 Entrenamiento [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPkuXTUBvB0"
      },
      "source": [
        "Ahora, vamos a entrenar los pipelines generados en los pasos anteriores. Para esto, debe realizar las siguientes tareas:\n",
        "\n",
        "1. Separe los datos de entrenamiento en un conjunto de entrenamiento y de prueba  (la proporción queda a su juicio). En este paso, seleccione los ejemplos de forma aleatoria e intente mantener la distribución original de labels de cada clase en los conjuntos de prueba/entrenamiento. (vea la documentación de `train_test_split`). [1 puntos]\n",
        "\n",
        "\n",
        "2. Defina un pipeline llamado `pipeline_xgboost` y otro llamado `pipeline_lightgbm`. Estos pipelines deben tener el mismo ColumnTransformer definido en la sección de preprocesamiento, pero deben variar los clasificadores de acuerdo al nombre de cada pipeline. [1 puntos]\n",
        "\n",
        "3. Entrene los pipelines. [1 punto]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbadONFtjGnE"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLtlXGTPdWAV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ya se sabe qué label y national position deben ser dorpeadas pero además se dropeara Nationality porque al separar los datos en el conjunto de training no quedan todas las nacionalidades y al hacer el predict no logra reconocer todas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_y=df_model1['label'].copy()\n",
        "df_x=df_model1.drop(['label','National_Position'], axis=1).copy()\n",
        "\n",
        "df_train_x,df_test_x, df_train_y,df_test_y= train_test_split(df_x,df_y, test_size=0.2, random_state=42, shuffle=True, stratify=df_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "lgb_model = lgb.LGBMClassifier()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cate=get_cat(df_train_x,cols_to_OHE)\n",
        "\n",
        "pipeline_xgboost=Pipeline([('column_transformer',column_transformer),\n",
        "                           ('to_dataframe', FunctionTransformer(func=lambda x: pd.DataFrame(x, columns=cols_to_scale+ cols_to_div+cate)))\n",
        "                           ,('xgb_model',xgb_model)\n",
        "                           ])\n",
        "\n",
        "pipeline_lightgbm=Pipeline([('column_transformer',column_transformer),\n",
        "                           ('to_dataframe', FunctionTransformer(func=lambda x: pd.DataFrame(x, columns=cols_to_scale+ cols_to_div+cate))),\n",
        "                           ('lgb_model',lgb_model)\n",
        "                           ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xgb_fitted=pipeline_xgboost.fit(df_train_x,df_train_y)\n",
        "\n",
        "lgbm_fitted=pipeline_lightgbm.fit(df_train_x,df_train_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poc9HSNBFeKO"
      },
      "source": [
        "### 1.3 Resultados [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGGCj8YtFil1"
      },
      "source": [
        "1. Calcule las métricas accuracy, precisión y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) para evaluar el rendimiento de los distintos modelos. Verifique sus resultados usando `classification_report`. [2 puntos]\n",
        "\n",
        "2. Explique qué implican los valores de accuracy, precisión y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) y cómo influye la cantidad de ejemplos por clase en los resultados obtenidos. [2 puntos]\n",
        "\n",
        "3. Explique qué métrica le parece más adecuada y concluya qué modelo tiene un mejor desempeño. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1hkVFdujJTi"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_xgb=xgb_fitted.predict(df_test_x)\n",
        "y_pred_lgbm=lgbm_fitted.predict(df_test_x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "se hara una funcion para calcular las metricas directamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def metricas_mat(mat):\n",
        "    tn, fp, fn, tp=mat.ravel()\n",
        "    Accuracy=(tn+tp)/(tn+fp+tp+fn)\n",
        "    Precision=(tp)/(tp+fp)\n",
        "    Recall= (tp)/(tp+fn)\n",
        "    print('Accuracy:',Accuracy)\n",
        "    print('Precision:',Precision)\n",
        "    print('Recall:',Recall)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "para xbg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Supongamos que tienes tus etiquetas verdaderas y predichas\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "matriz_confusion_xbg = confusion_matrix(df_test_y, y_pred_xgb)\n",
        "\n",
        "# Visualizar la matriz de confusión utilizando seaborn\n",
        "sns.heatmap(matriz_confusion_xbg, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Etiquetas Predichas')\n",
        "plt.ylabel('Etiquetas Verdaderas')\n",
        "plt.title('Matriz de Confusión de xgboost')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metricas_mat(matriz_confusion_xbg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "se compara con classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(df_test_y, y_pred_xgb)\n",
        "print(report)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "para lgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNmI_tbbdQte"
      },
      "outputs": [],
      "source": [
        "# Supongamos que tienes tus etiquetas verdaderas y predichas\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "matriz_confusion_lgbm = confusion_matrix(df_test_y, y_pred_lgbm)\n",
        "\n",
        "# Visualizar la matriz de confusión utilizando seaborn\n",
        "sns.heatmap(matriz_confusion_lgbm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Etiquetas Predichas')\n",
        "plt.ylabel('Etiquetas Verdaderas')\n",
        "plt.title('Matriz de Confusión de lightgbm')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metricas_mat(matriz_confusion_lgbm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "report = classification_report(df_test_y, y_pred_lgbm)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Calcule las métricas accuracy, precisión y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) para evaluar el rendimiento de los distintos modelos. Verifique sus resultados usando `classification_report`. [2 puntos]\n",
        "\n",
        "2. Explique qué implican los valores de accuracy, precisión y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) y cómo influye la cantidad de ejemplos por clase en los resultados obtenidos. [2 puntos]\n",
        "\n",
        "3. Explique qué métrica le parece más adecuada y concluya qué modelo tiene un mejor desempeño. [2 puntos]\n",
        "**Respuesta**\n",
        "1. Se puede observar para ambos casos que las métricas son similares, enfocándonos en la clase positiva de lo entregado por el classification report, ya que las métricas calculadas manualmente con con respecto a la clase positiva.\n",
        "2. El accuracy es que tan bien predice correctamente las etiquetas, si uno es seleccionado haya sido predicho como tal y si no lo es que haya sido predicho como que no lo es, el precision de todos los que se predijeron con la etiqueta positiva(seleccionado) que porcentaje efectivamente es seleccionado, por otra parte el recall muestra de todos los que son seleccionados qué porcentaje fue realmente predicho como seleccionado. Estos resultados son muy diferentes entre etiquetas porque están altamente desbalanceadas, si hubieran sido más los de etiqueta seleccionado habrían sido mejores los resultados.\n",
        "3. En este caso importa más bajar los falsos negativos, que los que son seleccionados efectivamente sean predichos como seleccionados, para esto se utiliza el recall, justamente esta es la métrica más baja para los modelos, el que tiene mayor esta métrica es el lightgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy5VMU6ae_g6"
      },
      "source": [
        "## 2. Predicción de posiciones de jugadores [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0PGg_hLgr4H"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://pbs.twimg.com/media/E1rfA1aWEAYU6Ny.jpg\" width=\"300\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6rSnAesfOm3"
      },
      "source": [
        "En una nueva jornada de desmesuradas transacciones deportivas, Renacín escuchó a sus colegas discutir acerca de que el precio de cada jugador depende en gran medida de la posición en la cancha en la que juega. Y además, que hay bastantes jugadores nuevos que no tienen muy claro en que posición verdaderamente brillarían, por lo que actualmente puede que actualmente estén jugando en posiciones sub-optimas.\n",
        "\n",
        "Viendo que los resultados del primer análisis no son tan esperanzadores, el corporeo los comanda a cambiar su tarea: ahora, les solicita que construyan un clasificador enfocado en predecir la mejor posición de los jugadores en la cancha según sus características.\n",
        "\n",
        "Para lograr esto, primero, les pide que etiqueten de la siguiente manera los valores que aparecen en el atributo `Club_Position`, pidiendo que agrupen los valores en los siguientes grupos:\n",
        "\n",
        "**Nota**:  Renacín les recalca que **no deben utilizar los valores ```Sub``` y ```Res``` de esta columna**.\n",
        "\n",
        "```python\n",
        "ataque = ['ST', 'CF']\n",
        "central_ataque = ['RW', 'CAM', 'LW']\n",
        "central = ['RM', 'CM', 'LM']\n",
        "central_defensa = ['RWB', 'CDM', 'LWB']\n",
        "defensa = ['RB', 'CB', 'LB']\n",
        "arquero = ['GK']\n",
        "```\n",
        "\n",
        "La elección del clasificador se justificar en base a la siguiente [guía](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) y se deben comentar los resultados obtenidos en la clasificación.\n",
        "\n",
        "**Tareas:** [1 punto por tarea]\n",
        "\n",
        "1. Aplique las etiquetas descritas anteriormente en cada uno de los valores señalados en esta sección.\n",
        "2. Cuente cuántos por clase quedan.\n",
        "3. Entrene el nuevo pipeline y ejecute una evaluación de este.  \n",
        "4. Comente los resultados obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBmSaWh8i2MI"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set(df['Club_Position'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede observar que hay más valores de posición que los que muestra el enunciado, estos se podrían agregar pero para mantener consistencia se trabajara solo con los mencionados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir_7zMh2i1vg"
      },
      "outputs": [],
      "source": [
        "def cat_CP(dfcol):\n",
        "    label_CP=[]\n",
        "    for i in dfcol:\n",
        "        if i in ['ST', 'CF']:\n",
        "            label_CP.append('ataque')\n",
        "        elif i in ['RW', 'CAM', 'LW']:\n",
        "            label_CP.append('central_ataque')\n",
        "        elif i in ['RM', 'CM', 'LM']:\n",
        "            label_CP.append('central')\n",
        "        elif i in ['RWB', 'CDM', 'LWB']:\n",
        "            label_CP.append('central_defensa')\n",
        "        elif i in ['RB', 'CB', 'LB']:\n",
        "            label_CP.append('defensa')\n",
        "        elif i =='GK':\n",
        "            label_CP.append('arquero')\n",
        "        else:\n",
        "            label_CP.append(np.nan)\n",
        "    return label_CP\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_model2=df.copy()\n",
        "df_model2['label']=cat_CP(df['Club_Position'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_model2.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.histogram(df_model2,x='label', title='Distribución de Label')\n",
        "fig.show()\n",
        "pd.DataFrame(df_model2['label']).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Para continuar con el modelo se dropean los que tienen el label =Nan y además se dropea la variable 'Club_Position' ya que esta es con la que se construyó el label, si se mantiene seria filtrar información.\n",
        "Además se aplicará la transformación del punto anterior para dejar todas la variables como numéricas(incluyendo los drops de variables como Nationality, Name, National Position)\n",
        "\n",
        "\n",
        "Segun la guia se debería usar Linear SVC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_model2.dropna(subset=['label'], inplace=True)\n",
        "df_y2=df_model2['label'].copy()\n",
        "df_x2=df_model2.drop(['label','Club_Position'], axis=1).copy()\n",
        "\n",
        "df_train_x2,df_test_x2, df_train_y2,df_test_y2= train_test_split(df_x2,df_y2, test_size=0.2, random_state=42, shuffle=True, stratify=df_y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "cate=get_cat(df_train_x,['Preffered_Foot', 'Work_Rate'])\n",
        "\n",
        "clf = svm.SVC()\n",
        "\n",
        "column_transformer2 = ColumnTransformer(transformers=[\n",
        "    ('numerical_to_scale', scale_transformations, cols_to_scale),\n",
        "    ('numerical_to_cent', cent_transformations, cols_to_div),\n",
        "    ('categorical_to_ohe', OHE_transformations, ['Preffered_Foot', 'Work_Rate'])], remainder='drop')\n",
        "\n",
        "\n",
        "pipeline_svm=Pipeline([('column_transformer2',column_transformer2),\n",
        "                           ('to_dataframe', FunctionTransformer(func=lambda x: pd.DataFrame(x, columns=cols_to_scale+ cols_to_div+cate))),\n",
        "                            ('classifier', clf)\n",
        "                           ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_svm.fit(df_train_x2,df_train_y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_svm=pipeline_svm.predict(df_test_x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "report = classification_report(df_test_y2, y_pred_svm)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede observar que las métricas de manera general son cercanas al 70%, pero algo muy importante a notar es el resultado para la clase arquero, todas la métricas son 100%, esto puede ser producto de data leakage, o quizás hay una variable que tiene mucha relación con ser arquero, por lo que se puede deducir la clase por esta variable,\n",
        "En cuanto a las otras clases los resultados son los esperados, aunque para las clases central... el rendimiento es bastante menor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bL2m8nNojXM"
      },
      "source": [
        "## 3. Predicciones de Seleccionados Nacionales para el Jere Klein [30 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2XmRsJdsEh_"
      },
      "source": [
        "<center>\n",
        "<img src='https://www.radioactiva.cl/wp-content/uploads/2024/04/Jere-Klein-1-768x432.webp' width=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgmUoVDsqUPu"
      },
      "source": [
        "Después de alcanzar la fama como cantante urbano, Jere Klein decide explorar una nueva faceta. Con su amor por el fútbol y convencido de que los artistas urbanos poseen un talento y versatilidad excepcionales, Jere se embarca en un proyecto innovador: desarrollar un sistema de inteligencia artificial capaz de identificar a jugadores que tienen potencial para convertirse en futbolistas profesionales. Su teoría es que muchos artistas del género urbano chileno, con sus habilidades únicas y su disciplina, podrían destacarse también en el deporte. Con este sistema, Jere espera no solo abrir nuevas oportunidades para sus colegas artistas, sino también demostrar la amplia gama de talentos que pueden ofrecer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD8pQ5Zfq8dE"
      },
      "source": [
        "### 2.1 ¿Qué modelo de árbol es más de \"pana\"? [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-KUA4g99eo"
      },
      "source": [
        "<center>\n",
        "<img src='https://64.media.tumblr.com/39189215a7d3d96823cb359f35b44e05/tumblr_psmrhrR3Xw1qf5hjqo4_540.gif' width=300 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL-moVhB9vPH"
      },
      "source": [
        "\n",
        "**Tareas**\n",
        "\n",
        "\n",
        "1. Considerando el la variable llamada `label` creada en la sección 1.1. Para determinar cuál modelo de árbol sería más adecuado para la tarea en cuestión, utilice PyCaret. Este deberá centrarse exclusivamente en modelos de tipo árbol. Jere ha especificado que busca un modelo que tome decisiones rápidamente y que tenga una baja tasa de falsos positivos, ya que planea invertir en estos jugadores. [3 puntos] Para la comparación, utilice los siguientes modelos:\n",
        "\n",
        "```python\n",
        "['et', 'rf', 'dt', 'xgboost', 'lightgbm', 'catboost']\n",
        "```\n",
        "\n",
        "3. Explique en brevemente que son los modelos de la siguiente lista `['et', 'rf', 'dt']` y como funcionan. [3 punto]\n",
        "\n",
        "4. Tras realizar la comparación de modelos, seleccione aquel que muestre el mejor rendimiento en términos de velocidad y precisión, especialmente en la reducción de falsos positivos. Utilice la función `evaluate_model` de PyCaret para revisar y analizar los resultados obtenidos en los siguientes aspectos:\n",
        "\n",
        "  - **Confusión Matrix**: ¿Cómo se encuentran la tasa de verdaderos positivos y verdaderos negativos?\n",
        "  - **Threshold**: ¿Es acaso el umbral por defecto del modelo el mejor para las predicciones?\n",
        "  - **Feature Importance**: ¿Cuáles son las variables con mejor desempeño? ¿A qué podría deberse esto?\n",
        "  - **Learning Curve**: ¿El modelo presenta algún problema?\n",
        "\n",
        "  [4 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#preprocesamiento\n",
        "\n",
        "df_model3=df_model1.copy()\n",
        "\n",
        "df_model3=df_model3.drop(['National_Position','Name',\t'Nationality'],axis=1)\n",
        "\n",
        "df_model3.dropna(subset=['Club_Position'], inplace=True)\n",
        "\n",
        "column_transformer3 = ColumnTransformer(transformers=[\n",
        "    ('numerical_to_scale', scale_transformations, cols_to_scale),\n",
        "    ('numerical_to_cent', cent_transformations, cols_to_div),\n",
        "    ('categorical_to_ohe', OHE_transformations, cols_to_OHE)], remainder='passthrough')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como se busca minimizar los falsos positivos, se ordenarán los modelos por precision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importar PyCaret\n",
        "import catboost\n",
        "from pycaret.classification import *\n",
        "df_y3=df_model3['label'].copy()\n",
        "\n",
        "df_x3=df_model3.drop(['label'], axis=1).copy()\n",
        "\n",
        "\n",
        "X3_train, X3_test,y3_train, y3_test= train_test_split(df_x3,df_y3, test_size=0.2, random_state=2024)\n",
        "\n",
        "y3_train.reset_index(drop=True, inplace=True)\n",
        "y3_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "cate=get_cat(df_model3,cols_to_OHE)\n",
        "\n",
        "Modelos3_proce=Pipeline([('column_transformer3',column_transformer3)\n",
        "                   ,('to_dataframe', FunctionTransformer(func=lambda x: pd.DataFrame(x, columns=cols_to_scale+ cols_to_div+cate)))                  \n",
        "                   ])\n",
        "\n",
        "X3_train_proce=Modelos3_proce.fit_transform(X3_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Configurar el entorno de PyCaret\n",
        "clf1 = setup(data=X3_train_proce, target=y3_train, session_id=123, verbose=False)\n",
        "\n",
        "# Comparar solo modelos de tipo árbol\n",
        "modelos = ['et', 'rf', 'dt', 'xgboost', 'lightgbm', 'catboost']\n",
        "mejor_modelo = compare_models(include=modelos, sort='Precision')\n",
        "\n",
        "# Ver la comparación de modelos\n",
        "comparacion_modelos = pull()\n",
        "\n",
        "\n",
        "evaluate_model(mejor_modelo)\n",
        "\n",
        "\n",
        "# Evaluar el mejor modelo seleccionado\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "metricas de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X3_test_proce=Modelos3_proce.fit_transform(X3_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelo_seleccion = finalize_model(mejor_modelo)\n",
        "\n",
        "\n",
        "# Hacer predicciones en datos de prueba\n",
        "predicciones = predict_model(modelo_seleccion, data=X3_test_proce)\n",
        "\n",
        "# Evaluar el modelo final\n",
        "evaluacion = classification_report(predicciones['prediction_label'], y3_test)\n",
        "print(evaluacion)\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "matriz_confusion_et = confusion_matrix( y3_test,predicciones['prediction_label'])\n",
        "\n",
        "# Visualizar la matriz de confusión utilizando seaborn\n",
        "sns.heatmap(matriz_confusion_et, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Etiquetas Predichas')\n",
        "plt.ylabel('Etiquetas Verdaderas')\n",
        "plt.title('Matriz de Confusión de Extra Trees Classifier')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY85nrViYROF"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Modelos:\n",
        "* dt= Decision Tree Classifier: es el modelo base de clasificación por árboles, este va dividiendo los features para encontrar una forma de caracterizar las diferentes clases, este puede tener diferentes criterios para la división, cada nodo es un feature para esta separación.\n",
        "* rf=Random Forest Classifier: Este modelo es una versión más compleja que el anterior ya que es del tipo ensemble, consta de muchos árboles que se entrenan con subconjuntos de las características de manera aleatoria, este modelo toma más tiempo en ser entrenado pero a su vez obtiene mejores resultados que un solo árbol.\n",
        "* et=Extra Trees Classifier: Este modelo es similar al random forest pero va un paso más allá, porque también selecciona de manera aleatoria el umbral de cada árbol, este modelo tiene menor varianza que el rf y toma menos tiempo en entrenarse, aunque no siempre tiene mejor resultado.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "4.  \n",
        "\n",
        "\n",
        "  - **Confusión Matrix**: ¿Cómo se encuentran la tasa de verdaderos positivos y verdaderos negativos?\n",
        "    - Como se enfocó principalmente en la métrica precisión, se minimizó los falsos positivos, teniendo en cuenta las medidas obtenidas en el test, las tasas son:\\\n",
        "        $FPR=\\frac{1}{(3295+1)}=0.0003$\\\n",
        "        $FNR=\\frac{210}{(210+12)}=0.9459$\n",
        "     \n",
        "  - **Threshold**: ¿Es acaso el umbral por defecto del modelo el mejor para las predicciones?\n",
        "    - el umbral por defecto según el gráfico sería 0.19, este sería el mejor para tener las métricas f1, recall y precisión con valores parecidos, pero en particular para este modelo se buscaba minimizar los falsos positivos, es decir maximizar la precisión, por lo que el threshold es mayor que el que muestra por defecto.\n",
        "  - **Feature Importance**: ¿Cuáles son las variables con mejor desempeño? ¿A qué podría deberse esto?\n",
        "    - Las variables con mejor desempeño son reactions, composure, stamina, vision, etc. esto se puede deber a que son las que más correlación tengan con el label del modelo.\n",
        "  - **Learning Curve**: ¿El modelo presenta algún problema?\n",
        "    -En particular para este caso no se ve algún problema, se consiguió valores altos para el cv y casi constantes en función de las instancias.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8DSS3u1xMpB"
      },
      "source": [
        "### 2.2 Reducción de dimensionalidad [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLu0543p876P"
      },
      "source": [
        "<center>\n",
        "<img src='https://i.kym-cdn.com/photos/images/original/002/258/560/668.gif' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT-bxJ0txwNF"
      },
      "source": [
        "A pesar de los resultados obtenidos previamente, el manager de Jere ha solicitado el entrenamiento de un modelo de XGBoost utilizando los datos disponibles. Además, se debe proceder a realizar una reducción de dimensionalidad basada en la importancia de las características.\n",
        "\n",
        "Para llevar a cabo esta tarea:\n",
        "\n",
        "1. Inicie entrenando un modelo XGBoost con todas las características disponibles. [2 puntos]\n",
        "\n",
        "2. Una vez el modelo esté entrenado, evalúe y clasifique las características según su importancia de forma descendente. [2 puntos]\n",
        "\n",
        "3. Utilice esta clasificación para ejecutar una búsqueda recursiva de eliminación de características, eliminando progresivamente las menos importantes y evaluando el impacto en el desempeño del modelo hasta identificar las N características más críticas. [2 puntos]\n",
        "\n",
        "4. Con este conjunto reducido de características, entrene un nuevo modelo y evalúe su rendimiento. [2 puntos]\n",
        "\n",
        "5. Posteriormente, responda a las siguientes preguntas para una comprensión más profunda de los cambios y beneficios:\n",
        "\n",
        "  - ¿El rendimiento del modelo con las características seleccionadas es similar al del modelo original? ¿Cómo se comparan en términos de precisión y robustez? [2 puntos]\n",
        "  - ¿Cuáles son los beneficios potenciales de eliminar variables del modelo? Considere factores como la simplificación del modelo, reducción del tiempo de entrenamiento, y mejora en la capacidad de generalización. [2 puntos]\n",
        "  - Comente si el modelo con menor dimensionalidad es más sencillo de explicar. Explique brevemente por qué la eliminación de ciertas características puede facilitar la comprensión y la explicación del comportamiento del modelo. [2 puntos]\n",
        "\n",
        "Notar que con esta metodologia buscamos encontrar un punto entermedio entre número de festures y desempeño. por esto, si observa que al aumentar festires el aumento es despreciable, puede no considerar agregar más features a su modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHfmK63TuDOS"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQwUd_nsuDOe"
      },
      "outputs": [],
      "source": [
        "xgb_model4 = xgb.XGBClassifier()\n",
        "\n",
        "pipeline_xgboost4=Pipeline([('column_transformer3',column_transformer),\n",
        "                           ('to_dataframe', FunctionTransformer(func=lambda x: pd.DataFrame(x, columns=cols_to_scale+ cols_to_div+cate)))\n",
        "                           ,('xgb_model',xgb_model4)\n",
        "                           ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model4=pipeline_xgboost4.fit(X3_train,y3_train)\n",
        "\n",
        "model4pred=model4.predict(X3_test)\n",
        "\n",
        "evaluacion = classification_report(model4pred, y3_test)\n",
        "print(evaluacion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "columns_names = cols_to_scale+ cols_to_div+cate\n",
        "\n",
        "\n",
        "feat_importances = pd.DataFrame(\n",
        "    model4['xgb_model'].feature_importances_,\n",
        "    index=columns_names, \n",
        "    columns=[\"Importance\"]\n",
        ")\n",
        "feat_importances.sort_values(by='Importance', ascending=True, inplace=True)\n",
        "feat_importances.plot(kind='barh', figsize=(10,12), legend=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "def plot_line(x, y):\n",
        "    # Crear una figura\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Añadir la línea principal\n",
        "    fig.add_trace(go.Scatter(x=x, y=y, mode='lines', name='Main Line'))\n",
        "\n",
        "\n",
        "    # Establecer el diseño del gráfico\n",
        "    fig.update_layout(title='Precisión del modelo con el número de features',\n",
        "                      template='simple_white',\n",
        "                      showlegend=False,\n",
        "                      xaxis_title='Número de features eliminadas',\n",
        "                      yaxis_title='Score')\n",
        "\n",
        "    # Mostrar el gráfico\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Obtenemos X para el train para el ejemplo\n",
        "array_X = model4['column_transformer3'].fit_transform(X3_train)\n",
        "cols_trans_name = cols_to_scale+ cols_to_div+cate\n",
        "new_X_train = pd.DataFrame(array_X, columns=cols_trans_name)\n",
        "\n",
        "# Lista para almacenar la precisión del modelo con cada número de características\n",
        "precision_scores = []\n",
        "\n",
        "# Crear un selector de características recursivo con validación cruzada\n",
        "clf = model4['xgb_model']\n",
        "\n",
        "# Iterar sobre las características y evaluar el modelo con cada adición\n",
        "for i in range(0, len(cols_trans_name) + 1):\n",
        "    # Seleccionar las primeras i características\n",
        "    selected_features = feat_importances.index[-(len(cols_trans_name)+1 -i):]\n",
        "    scores = cross_val_score(\n",
        "        clf, new_X_train[selected_features], \n",
        "        y3_train, cv=5, scoring='precision_macro'\n",
        "    )    \n",
        "    # Almacenar la precisión del modelo con i características\n",
        "    precision_scores.append(scores)\n",
        "\n",
        "# Calcular variación de los puntos\n",
        "x = [i for i in range(0, len(cols_trans_name) + 1)]\n",
        "y = np.array(precision_scores).mean(axis=1)\n",
        "std = np.array(precision_scores).std(axis=1)\n",
        "\n",
        "plot_line(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por el gráfico se puede ver que varía mucho cómo afecta el eliminar las diferentes variables, no se ve necesariamente una disminución de rendimiento, es más, ocurre lo contrario cuando solo quedan las variables más importantes, el rendimiento crece. Llegando al máximo dejando las 3 variables más importantes. Es por esto que se va a entrenar el modelo y evaluar con las tres variables principales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_features_filtered = feat_importances.index[-(len(cols_trans_name)+1 -71):]\n",
        "clf2= xgb.XGBClassifier()\n",
        "clf2.fit(new_X_train[selected_features_filtered],y3_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "array_X_test = model4['column_transformer3'].fit_transform(X3_test)\n",
        "cols_trans_name = cols_to_scale+ cols_to_div+cate\n",
        "new_X_test = pd.DataFrame(array_X_test, columns=cols_trans_name)\n",
        "\n",
        "ypred_4filtered=clf2.predict(new_X_test[selected_features_filtered])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluacion = classification_report(ypred_4filtered, y3_test)\n",
        "print(evaluacion)\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "matriz_confusion_et = confusion_matrix( y3_test,ypred_4filtered)\n",
        "\n",
        "# Visualizar la matriz de confusión utilizando seaborn\n",
        "sns.heatmap(matriz_confusion_et, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Etiquetas Predichas')\n",
        "plt.ylabel('Etiquetas Verdaderas')\n",
        "plt.title('Matriz de Confusión de Extra Trees Classifier')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Posteriormente, responda a las siguientes preguntas para una comprensión más profunda de los cambios y beneficios:\n",
        "\n",
        "\n",
        "  - ¿El rendimiento del modelo con las características seleccionadas es similar al del modelo original? ¿Cómo se comparan en términos de precisión y robustez? [2 puntos]\n",
        "    - el rendimiento en accuracy es similar pero con las otras métricas es menor para el modelo más simplificado, o al menos enfocado en la clase positiva, por eso en precisión es similar pero en robustez al ser un modelo más simple debería tender a ser más generalizable y por lo tanto más robusto.\n",
        "  - ¿Cuáles son los beneficios potenciales de eliminar variables del modelo? Considere factores como la simplificación del modelo, reducción del tiempo de entrenamiento, y mejora en la capacidad de generalización. [2 puntos]\n",
        "    - Eliminar variables del modelo simplifica el entrenamiento de este, esto se refleja en un menor tiempo de entrenamiento, en el caso de árboles, árboles con menos profundidad, además al tener menos variables se reduce la posibilidad de sobreajuste del modelo.\n",
        "  - Comente si el modelo con menor dimensionalidad es más sencillo de explicar. Explique brevemente por qué la eliminación de ciertas características puede facilitar la comprensión y la explicación del comportamiento del modelo. [2 puntos]\n",
        "    - El modelo efectivamente es más sencillo de explicar ya que hay menos variables que considerar y menos interrelaciones entre estas que puedan mostrar la influencia en las clases a predecir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTG5cH9r3M9g"
      },
      "source": [
        "### 2.3 Calibración Probabilistica [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDL0VqjR7yvb"
      },
      "source": [
        "<center>\n",
        "<img src='https://media2.giphy.com/media/l2Je4Ku0Cx292KWv6/200w.gif?cid=6c09b952y0sihtq9tb6sz8j2023x3zxxp3qx1ocgonkpkblj&ep=v1_gifs_search&rid=200w.gif&ct=g' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmOKxhAw3sic"
      },
      "source": [
        "Para lograr modelos más modulares, se recomienda realizar una calibración del modelo entrenado anteriormente, con el objetivo de obtener salidas que reflejen mayor modularidad.\n",
        "\n",
        "1. Se solicita que utilice un método de calibración que asegure que las probabilidades generadas incrementen de manera monótona. Una métrica ampliamente utilizada para evaluar la precisión de la calibración de un modelo es el Brier Score. Calcule el Brier Score para el modelo tanto antes como después de la calibración. Esto le permitirá realizar una comparación cuantitativa y determinar si la calibración ha mejorado el rendimiento del modelo. Para más información sobre el Brier Score, puede consultar el siguiente enlace: [Scikit-Learn - Brier Score Loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html). [3 puntos]\n",
        "\n",
        "2. Tras la calibración, examine y comente los resultados obtenidos. A su análisis añada una comparación visual de las ideales versus las salidas del modelo original (sin calibrar) y del modelo calibrado. [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIiYz_qLuD19"
      },
      "source": [
        "Para la calibración se utilizará el modelo reducido que fue el último que se entrenó."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0bfSuiFuD2I"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import brier_score_loss\n",
        "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
        "\n",
        "# Obtener las probabilidades predichas del modelo sin calibrar\n",
        "probabilities_uncalibrated = clf2.predict_proba(new_X_test[selected_features_filtered])[:, 1]\n",
        "\n",
        "# Calcular el Brier Score del modelo sin calibrar\n",
        "brier_score_uncalibrated = brier_score_loss(y3_test, probabilities_uncalibrated)\n",
        "print(f\"Brier Score (sin calibrar): {brier_score_uncalibrated}\")\n",
        "\n",
        "calibrated_model = CalibratedClassifierCV(clf2, method='isotonic', cv='prefit')\n",
        "calibrated_model.fit(new_X_train[selected_features_filtered],y3_train)\n",
        "\n",
        "# Obtener las probabilidades predichas del modelo calibrado\n",
        "probabilities_calibrated = calibrated_model.predict_proba(new_X_test[selected_features_filtered])[:, 1]\n",
        "\n",
        "# Calcular el Brier Score del modelo calibrado\n",
        "brier_score_calibrated = brier_score_loss(y3_test, probabilities_calibrated)\n",
        "print(f\"Brier Score (calibrado): {brier_score_calibrated}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generar el gráfico de calibración\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "\n",
        "fraction_of_positives_uncalibrated, mean_predicted_value_uncalibrated = calibration_curve(y3_test, probabilities_uncalibrated, n_bins=10)\n",
        "fraction_of_positives_calibrated, mean_predicted_value_calibrated = calibration_curve(y3_test, probabilities_calibrated, n_bins=10)\n",
        "\n",
        "plt.plot(mean_predicted_value_uncalibrated, fraction_of_positives_uncalibrated, \"s-\", label=\"Sin calibrar\")\n",
        "plt.plot(mean_predicted_value_calibrated, fraction_of_positives_calibrated, \"s-\", label=\"Calibrado\")\n",
        "\n",
        "# Graficar la línea de referencia perfecta\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfectamente calibrado\")\n",
        "\n",
        "plt.xlabel(\"Probabilidad predicha\")\n",
        "plt.ylabel(\"Fracción de positivos\")\n",
        "plt.title(\"Gráfico de Calibración\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta**\n",
        "Tras la calibración se puede notar un ligero aumento en la métrica Brier Score, en el gráfico también se puede notar una ligera diferencia en la calibración con respecto al original, la principal diferencia se encuentra en el valor de probabilidad predicha que se obtiene el 100% de fracción de positivos, siendo el modelo calibrado donde se corresponde mejor con la calibración perfecta."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "k-ao0mOU64Ru",
        "Jg_9jBqtgRDO",
        "JdcucZhp-M_0",
        "Qfre1YsSDqla",
        "Bv1HOfcNEPF4",
        "poc9HSNBFeKO",
        "uy5VMU6ae_g6",
        "9bL2m8nNojXM",
        "rD8pQ5Zfq8dE",
        "K8DSS3u1xMpB",
        "PTG5cH9r3M9g"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
