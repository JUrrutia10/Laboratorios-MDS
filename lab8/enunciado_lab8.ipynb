{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR6y997eegsr"
      },
      "source": [
        "<h1><center>Laboratorio 8: Predicciones y Recomendaciones 🔮🪄 </center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM11jRmpegss"
      },
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- **Profesores:** Ignacio Meza, Sebastián Tinoco\n",
        "- **Auxiliares:** Catherine Benavides, Consuelo Rojas\n",
        "- **Ayudante:** Nicolás Ojeda, Eduardo Moya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpbH7VYcegst"
      },
      "source": [
        "### **Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados**\n",
        "\n",
        "- Nombre de alumno 1:\n",
        "- Nombre de alumno 2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pg5Iz9tegst"
      },
      "source": [
        "### **Link de repositorio de GitHub:** `http://....`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZCCAQyqegsu"
      },
      "source": [
        "## Temas a tratar\n",
        "- Series de Tiempo.\n",
        "- Predicciones vía `Prophet`.\n",
        "- Implementar un sistema de recomendación utilizando `surprise`.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- Código que no se pueda ejecutar, no será revisado.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender qué es una serie de tiempo y su estructura.\n",
        "- Identificar tendencias, estacionalidades e irregularidades.\n",
        "- Armar un modelo predictivo para la serie.\n",
        "- Conocer y aplicar sistemas de recomendación.\n",
        "- Entender estructura y conocer casos de estudio.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SVTRREue_CR"
      },
      "outputs": [],
      "source": [
        "# Librerias globales\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKJ0AuRJpDa-"
      },
      "source": [
        "# **Forecasting (3.0 puntos)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q56pg4rpJ2d"
      },
      "source": [
        "## **Prophet, teoria**\n",
        "\n",
        "Prophet es una herramienta open-source de Facebook utilizada para realizar predicciones en series de tiempo. Esta se basa en la descomposición aditiva, donde tendencias no lineales se ajustan junto a la estacionalidad.\n",
        "\n",
        "En la ecuación de a continuación se puede ver una idea general de los elementos que construyen a un modelo aditivo como lo es Prophet.\n",
        "\n",
        "\\begin{equation}\n",
        "y(t) = g(t) + s(t) + h(t) + e(t)\n",
        "\\end{equation}\n",
        "\n",
        "Donde, $g(t)$ hace referencia a las tendencias, que corresponden a cambios graduales en largos periodos de tiempo. $s(t)$ corresponde a la estacionalidad, son cambios periodicos o cortos en el tiempo. $h(t)$ es el efecto que tienen las festividades sobre las predicciones, mientras que e(t) corresponde al error o ruido. Finalmente $y(t)$, es la predicción hecha por el modelo.\n",
        "\n",
        "Prophet trabaja por defecto con Piece-Wise Lineal Model, este es un modelo de regresión lineal, en el cual se buscan distintas zonas en que la data presente patrones o tendencias lineales, de estas zonas obtiene su regresión y luego las \"une\" de manera de representar toda la región, como se puede ver en la ecuación siguiente.\n",
        "\n",
        "\\begin{equation}\n",
        "y(x)=\n",
        "    \\begin{cases}\n",
        "        η_1 + \\beta_1(x-b_1), & b_1 < x  \\leqslant b_2 \\\\\n",
        "        η_2 + \\beta_2(x-b_2), & b_2 < x  \\leqslant b_3 \\\\\n",
        "        η_3 + \\beta_3(x-b_3), & b_3 < x  \\leqslant b_3 \\\\\n",
        "        ... \\\\\n",
        "        η_k + \\beta_{nb}(x-b_{nb-1}), & b_{n-1} < x  \\leqslant b_{nb} \\\\\n",
        "    \\end{cases}\n",
        "\\end{equation}\n",
        "\n",
        "Siendo $b_1$ el primer punto de quiebre en la serie y así hasta el punto $b_{nb}$ correspondiente al último punto de quiebre de la serie con una cantidad $nb$ de puntos.\n",
        "\n",
        "Para mayor información de Prophet y como utilizarla, pueden ver su [documentación](https://facebook.github.io/prophet/docs/quick_start.html#python-api), donde hay pueden encontrar un pequeño tutorial de la librería."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFyj8iydXsXX"
      },
      "source": [
        "## **Prophet, práctica**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ny57G6_jp6I"
      },
      "source": [
        "<center>\n",
        "<img src =\"https://static.wikia.nocookie.net/31minutos/images/d/d1/Don_Sergio.png/revision/latest?cb=20190926222900\" width = 250 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvst6Ow68DTN"
      },
      "source": [
        "Don Sergio quiere entrenar para participar en la maratón y como sabe que correr una maratón requiere de entrenamiento y una dieta balanceada.\n",
        "\n",
        "Por ello, necesita empezar a comer más balanceado, pero también necesita saber que tanto le va a costar esto, de manera de poder agregarlo a su presupuesto.\n",
        "\n",
        "Es así como ustedes tendrán que ayudar a Don Sergio a cumplir su sueño de correr la maratón de Santiago, manteniendo su economía del hogar que comparte con su espora Emerilda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "louYFm_B9vA5"
      },
      "source": [
        "**Datos**\n",
        "\n",
        "Para poder ayudar a Don Sergio, harán uso del dataset `fruit_vegetables.csv`que contiente las siguientes columnas:\n",
        "\n",
        "*   `SN:` Serial Number.\n",
        "*   `Commodity:` Nombre de las frutas o verduras.\n",
        "* `Date:` Fecha del registro.\n",
        "* `Unit:` Unidad del precio.\n",
        "* `Minumum:` Precio mínimo de venta.\n",
        "* `Maximum:` Precio máximo de venta.\n",
        "* `Average:` Precio promedio de venta.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKD2SH9fCGAP"
      },
      "source": [
        "### **1. Serie de Tiempo**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4V67aohCOtZ"
      },
      "source": [
        "#### **1.1 Pre-procesamiento**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfnxX7LiCVaf"
      },
      "source": [
        "Tareas de la sección:\n",
        "\n",
        "\n",
        "1.   Identificar elementos necesarios para generar la serie de tiempo.\n",
        "2.   Gráficar datos.\n",
        "3.   Ver la existencia de tendencias, estacionalidades o ruido.\n",
        "4.   Dividir datos para tener set de entrenamiento (80%) y testeo (20%). Graficar.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofMI3wNHDrDf"
      },
      "source": [
        "**Comida de Don Sergio**\n",
        "\n",
        "Don Sergio quiere nutricer lo mejor posible durante su tiempo de entrenamiento, por lo que necesita agregar más frutas y verduras a su dieta. Es por ello que decidío añadir los siguientes elementos a su compra diaria.\n",
        "\n",
        "*   Tomates\n",
        "*   Lechuga\n",
        "*   Manzana\n",
        "*   Plantanos\n",
        "*   Tofu\n",
        "\n",
        "**Nota:** Don Sergio prefiere comprar productos locales, compra un Kg diario de cada cosa y a precio promedio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7ZxeS8fLRcT"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYlJXFj28AmJ"
      },
      "outputs": [],
      "source": [
        "# Leer el dataset\n",
        "df=pd.read_csv('fruit_vegetables.csv')\n",
        "set(df['Commodity'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se sabe que elige local en caso de haber varias opciones, para el caso de las manzanas hay dos tipos, por lo que solo se elegirá la que tenga precio menor en general o que tenga más datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "manzanas=['Apple(Fuji)','Apple(Jholey)']\n",
        "dfapple=df[df['Commodity'].isin(manzanas)].copy()\n",
        "# Crear el gráfico de línea con Plotly Express\n",
        "fig = px.line(dfapple, x='Date', y='Average',color='Commodity' ,title='Registros por Fecha de Reclamo')\n",
        "\n",
        "# Mostrar el gráfico\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al ver el gráfico podemos ver que las manzanas del tipo jholey tienen mas datos, por lo que es este tipo el que se considerará."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYjZ4TEib_Vq"
      },
      "outputs": [],
      "source": [
        "# Crear máscara con elementos de búsqueda y seleccionar\n",
        "listacomodities=['Tofu','Tomato Small(Local)','Apple(Jholey)','Lettuce','Banana',]\n",
        "dfmasc= df[df['Commodity'].isin(listacomodities)]\n",
        "fig = px.line(dfmasc, x='Date', y='Average',color='Commodity' ,title='Registros por Fecha de Reclamo')\n",
        "\n",
        "# Mostrar el gráfico\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "aquí se puede ver que todos los commodities seleccionados tienen datos por las mismas fechas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0C-HN_icEab"
      },
      "outputs": [],
      "source": [
        "# Agrupar por fecha en la columna average y sumar, obtener serie de tiempo\n",
        "df_grouped_sum = dfmasc.groupby('Date')['Average'].sum().rename('Suma').copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpQIkrb5cNVw"
      },
      "outputs": [],
      "source": [
        "# Graficar serie de tiempo\n",
        "fig = px.line(x=df_grouped_sum.index, y=df_grouped_sum.values  ,title='Registros por Fecha de Reclamo')\n",
        "\n",
        "# Mostrar el gráfico\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_RHBuZkcU1t"
      },
      "outputs": [],
      "source": [
        "# Realizar descomposición de la señal, utilizado seasonal_decompose\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "df_descomp=seasonal_decompose(df_grouped_sum, model='additive', filt=None, period=365, two_sided=True, extrapolate_trend=0)#period es 365 porque se puede entender que es anual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trend = df_descomp.trend\n",
        "seasonal = df_descomp.seasonal\n",
        "resid = df_descomp.resid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig_trend = px.line(x=trend.index, y=trend.values, title='Tendencia')\n",
        "fig_seasonal = px.line(x=seasonal.index, y=seasonal.values, title='Estacionalidad')\n",
        "fig_residual = px.line(x=resid.index, y=resid.values, title='Residuo')\n",
        "\n",
        "# Mostrar los gráficos\n",
        "fig_trend.show()\n",
        "fig_seasonal.show()\n",
        "fig_residual.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede ver en los tres gráficos que existe tanto una tendencia de crecimiento, una estacionalidad en los datos y el residuo es de carácter estacionario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqjVme_Acn-4"
      },
      "outputs": [],
      "source": [
        "# Realizar Hold Out de 80/20\n",
        "\n",
        "trainsize=0.8\n",
        "dfsize=len(df_grouped_sum)\n",
        "\n",
        "dfserie_train=df_grouped_sum[:int(trainsize*dfsize)].copy()\n",
        "dfserie_test=df_grouped_sum[int(trainsize*dfsize):].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3rlcC1xNyYn"
      },
      "source": [
        "#### **1.2 Modelo Prophet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llzSzKI3OpPk"
      },
      "source": [
        "A continuación se genera un modelo Prophet para la predicción. Para ello se tiene que:\n",
        "1. Crear dataset, donde columna de tiempo tiene que ir en formate YYYY-MM-DD con el nombre de `ds` y columna objetivo con nombre `y`.\n",
        "2. Entrenar modelo.\n",
        "3. Generar predicción. Notar que el dataframe de predicción solo contiene una columna con nombre `ds`, al inicio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGUoUlEfSmDv"
      },
      "outputs": [],
      "source": [
        "# librerias extras\n",
        "from prophet import Prophet\n",
        "from prophet.plot import plot_plotly, plot_components_plotly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3RURg6jSwoY"
      },
      "source": [
        "**1. Generar dataframes de entrenamiento y testeo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_OVULN9S1W3"
      },
      "outputs": [],
      "source": [
        "# Respuesta\n",
        "df_train=pd.DataFrame()\n",
        "df_train['ds']=dfserie_train.index.copy()\n",
        "df_train['y']=dfserie_train.values.copy()\n",
        "\n",
        "df_test=pd.DataFrame()\n",
        "df_test['ds']=dfserie_test.index.copy()\n",
        "df_test['y']=dfserie_test.values.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UryjLQ-rS9NR"
      },
      "source": [
        "**2. Modelo y entrenamiento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-uZcmW-TAdw"
      },
      "outputs": [],
      "source": [
        "# Respuesta, tal vez si menciono más arriba que prophet usar la sintaxis de sklearn esto lo hacen solitos nomas\n",
        "model = Prophet()\n",
        "model.fit(df_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT7Rs32BT5wD"
      },
      "source": [
        "**3. Predicción.**\n",
        "\n",
        "¿Qué muestra el dataframe de predicción una vez realizada la predicción? ¿Qué siginifican las distintas columnas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANLvysLAUP3I"
      },
      "outputs": [],
      "source": [
        "# Respuesta\n",
        "predicted=model.predict(df_test)\n",
        "predicted.tail(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta**\n",
        "\n",
        "Las columnas muestran los valores de los coeficientes de la regresión que considera los componentes que según el modelo son los importantes, además de mostrar los valores para construir una banda para poder ver la variabilidad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS1HYaMDUXvB"
      },
      "source": [
        "**Gráficos de resultados**\n",
        "\n",
        "\n",
        "Ahora, vemos el resultado de la predicción hecha a través de los gráficos que vienen implementados en la libreria.\n",
        "\n",
        "Se tienen gráficos de la predicción del modelo y descomposición por componentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-9CIICFVMQ4"
      },
      "outputs": [],
      "source": [
        "# plot forecast, estático.\n",
        "f, ax = plt.subplots(figsize=(15, 5))\n",
        "f.set_figheight(5)\n",
        "f.set_figwidth(15)\n",
        "\n",
        "fig = model.plot(predicted, ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-t24dFfgWj-q"
      },
      "outputs": [],
      "source": [
        "# descomposición por componentes, estático\n",
        "fig = model.plot_components(predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYfb_VDxXFqg"
      },
      "source": [
        "#### **1.3 Resultados y métricas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_PhFomDXMV0"
      },
      "source": [
        "En la presente sección se van a ver los resultados de la predicción, comparando con los resultados originales, así se obtienen métricas de error. Para ello se hacen los siguientes pasos:\n",
        "1. Inspeccionar gráfica de predicción con los datos reales. Agregar tres vistas: predicción del primer 15% de los datos, 50% de los datos y 100% de la predicción.\n",
        "2. Calcular métricas de error (RMSE, MAE, MAPE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "se preparan en los subconjuntos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Respuesta\n",
        "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
        "df_test['ds'] = pd.to_datetime(df_test['ds'])\n",
        "predicted['ds'] = pd.to_datetime(predicted['ds'])\n",
        "\n",
        "testsize=len(df_test)\n",
        "pred_15=predicted[:int(testsize*0.15)].copy()\n",
        "df_test_15=df_test[:int(testsize*0.15)].copy()\n",
        "pred_50=predicted[:int(testsize*0.5)].copy()\n",
        "df_test_50=df_test[:int(testsize*0.5)].copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "15%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alinear las predicciones con los datos reales usando merge\n",
        "comparison_df_15 = df_test_15[['ds', 'y']].merge(pred_15[['ds', 'yhat']], on='ds', how='left')\n",
        "\n",
        "# Calcular las métricas de error\n",
        "rmse_15 = root_mean_squared_error(comparison_df_15['y'], comparison_df_15['yhat'])\n",
        "mae_15 = mean_absolute_error(comparison_df_15['y'], comparison_df_15['yhat'])\n",
        "mape_15 = np.mean(np.abs((comparison_df_15['y'] - comparison_df_15['yhat']) / comparison_df_15['y'])) * 100\n",
        "\n",
        "print(f'RMSE: {rmse_15}')\n",
        "print(f'MAE: {mae_15}')\n",
        "print(f'MAPE: {mape_15}%')\n",
        "\n",
        "# Graficar los resultados\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "\n",
        "# Graficar los valores reales\n",
        "ax.plot(comparison_df_15['ds'], comparison_df_15['y'], label='Datos Reales', color='blue')\n",
        "\n",
        "# Graficar las predicciones\n",
        "ax.plot(comparison_df_15['ds'], comparison_df_15['yhat'], label='Pronóstico', color='red')\n",
        "\n",
        "# Configurar etiquetas y título\n",
        "ax.set_xlabel('Fecha')\n",
        "ax.set_ylabel('Valor')\n",
        "ax.set_title('Comparación entre Datos Reales y Pronóstico')\n",
        "ax.legend()\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "50%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alinear las predicciones con los datos reales usando merge\n",
        "comparison_df_50 = df_test_50[['ds', 'y']].merge(pred_50[['ds', 'yhat']], on='ds', how='left')\n",
        "\n",
        "# Calcular las métricas de error\n",
        "rmse_50 = root_mean_squared_error(comparison_df_50['y'], comparison_df_50['yhat'])\n",
        "mae_50 = mean_absolute_error(comparison_df_50['y'], comparison_df_50['yhat'])\n",
        "mape_50 = np.mean(np.abs((comparison_df_50['y'] - comparison_df_50['yhat']) / comparison_df_50['y'])) * 100\n",
        "\n",
        "print(f'RMSE: {rmse_50}')\n",
        "print(f'MAE: {mae_50}')\n",
        "print(f'MAPE: {mape_50}%')\n",
        "\n",
        "# Graficar los resultados\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "\n",
        "# Graficar los valores reales\n",
        "ax.plot(comparison_df_50['ds'], comparison_df_50['y'], label='Datos Reales', color='blue')\n",
        "\n",
        "# Graficar las predicciones\n",
        "ax.plot(comparison_df_50['ds'], comparison_df_50['yhat'], label='Pronóstico', color='red')\n",
        "\n",
        "# Configurar etiquetas y título\n",
        "ax.set_xlabel('Fecha')\n",
        "ax.set_ylabel('Valor')\n",
        "ax.set_title('Comparación entre Datos Reales y Pronóstico')\n",
        "ax.legend()\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "100%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alinear las predicciones con los datos reales usando merge\n",
        "comparison_df = df_test[['ds', 'y']].merge(predicted[['ds', 'yhat']], on='ds', how='left')\n",
        "\n",
        "# Calcular las métricas de error\n",
        "rmse = root_mean_squared_error(comparison_df['y'], comparison_df['yhat'])\n",
        "mae = mean_absolute_error(comparison_df['y'], comparison_df['yhat'])\n",
        "mape = np.mean(np.abs((comparison_df['y'] - comparison_df['yhat']) / comparison_df['y'])) * 100\n",
        "\n",
        "print(f'RMSE: {rmse}')\n",
        "print(f'MAE: {mae}')\n",
        "print(f'MAPE: {mape}%')\n",
        "\n",
        "# Graficar los resultados\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "\n",
        "# Graficar los valores reales\n",
        "ax.plot(comparison_df['ds'], comparison_df['y'], label='Datos Reales', color='blue')\n",
        "\n",
        "# Graficar las predicciones\n",
        "ax.plot(comparison_df['ds'], comparison_df['yhat'], label='Pronóstico', color='red')\n",
        "\n",
        "# Configurar etiquetas y título\n",
        "ax.set_xlabel('Fecha')\n",
        "ax.set_ylabel('Valor')\n",
        "ax.set_title('Comparación entre Datos Reales y Pronóstico')\n",
        "ax.legend()\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "como se puede observar según las medidas de error, cuando solo se considera el 15% las métricas se comportan mejor, es cuando se considera el 50% que en particular para esta muestra de test las fechas contemplan los primeros meses de la pandemia, el error sube casi al doble debido a la discrepancia de lo predicho con los real, una vez se considera todo el conjunto de test, baja un poco el error, porque los precios son más parecidos a los presentes en los años anteriores y por ende la predicción es mejor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZQDOr66Yjqu"
      },
      "source": [
        "#### **1.4 Festividades y fechas importantes**\n",
        "\n",
        "Como a todos, a Don Sergio también le afectan las fechas importantes. Para ver como afectan estas fechas al presupuesto de Don Sergio tiene que realizar las siguientes tareas:\n",
        "\n",
        "1. Crear dataframe con fechas importantes y agregar las al modelo con el argumento `holiday`.\n",
        "2. Predecir las el dataframe de testeo\n",
        "3. Comparar resultados. Hacer una tabla con resultados RMSE, MAE, MAPE anteriores y al añadir las festividades.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sL5Q1s6s6LZ"
      },
      "source": [
        "**1. Festividades y agregar a modelo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suponiendo que Don Sergio vive en Chile se consideran fechas importantes, las fiestas patrias, año nuevo, semana santa, navidad. No se consideran todas los feriados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "fechas_importantes_lista = [\n",
        "    \"2013-01-01\",\n",
        "    \"2014-01-01\",\n",
        "    \"2015-01-01\",\n",
        "    \"2016-01-01\",\n",
        "    \"2017-01-01\",\n",
        "    \"2018-01-01\",\n",
        "    \"2019-01-01\",\n",
        "    \"2020-01-01\",\n",
        "\n",
        "    \"2013-09-18\",\n",
        "    \"2014-09-18\",\n",
        "    \"2015-09-18\",\n",
        "    \"2016-09-18\",\n",
        "    \"2017-09-18\",\n",
        "    \"2018-09-18\",\n",
        "    \"2019-09-18\",\n",
        "    \"2020-09-18\",\n",
        "\n",
        "    \"2013-09-19\",\n",
        "    \"2014-09-19\",\n",
        "    \"2015-09-19\",\n",
        "    \"2016-09-19\",\n",
        "    \"2017-09-19\",\n",
        "    \"2018-09-19\",\n",
        "    \"2019-09-19\",\n",
        "    \"2020-09-19\",\n",
        "\n",
        "    # Semana Santa (Viernes Santo y Domingo de Resurrección)\n",
        "    \"2013-03-29\", \"2013-03-30\", \"2013-03-31\",\n",
        "    \"2014-04-18\", \"2014-04-19\",\"2014-04-20\",\n",
        "    \"2015-04-03\", \"2015-04-04\",\"2015-04-05\",\n",
        "    \"2016-03-25\", \"2016-03-26\",\"2016-03-27\",\n",
        "    \"2017-04-14\", \"2017-04-15\",\"2017-04-16\",\n",
        "    \"2018-03-30\", \"2018-03-31\",\"2018-04-01\",\n",
        "    \"2019-04-19\", \"2019-04-20\",\"2019-04-21\",\n",
        "    \"2020-04-10\", \"2020-04-11\",\"2020-04-12\",\n",
        "    \"2021-04-02\", \"2021-04-03\",\"2021-04-04\",\n",
        "    # Navidad\n",
        "    \"2013-12-25\",\n",
        "    \"2014-12-25\",\n",
        "    \"2015-12-25\",\n",
        "    \"2016-12-25\",\n",
        "    \"2017-12-25\",\n",
        "    \"2018-12-25\",\n",
        "    \"2019-12-25\",\n",
        "    \"2020-12-25\"]\n",
        "\n",
        "fechas_importantes = pd.DataFrame({\n",
        "    'ds': pd.to_datetime(fechas_importantes_lista),\n",
        "    'holiday': 'feriado'\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bISIsinAn7W1"
      },
      "outputs": [],
      "source": [
        "# Respuesta\n",
        "df_holi=pd.DataFrame()\n",
        "df_holi['ds']=df_grouped_sum.index.copy()\n",
        "df_holi['y']=df_grouped_sum.values.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "se realiza el mismo holdout 80/20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Realizar Hold Out de 80/20\n",
        "\n",
        "trainsize=0.8\n",
        "dfsize=len(df_holi)\n",
        "\n",
        "df_holi_train=df_holi[:int(trainsize*dfsize)].copy()\n",
        "df_holi_test=df_holi[int(trainsize*dfsize):].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWj7458StJkO"
      },
      "source": [
        "**2. Predecir**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMKWSnqptJTW"
      },
      "outputs": [],
      "source": [
        "# Respuesta\n",
        "model2 = Prophet(holidays=fechas_importantes)\n",
        "model2.fit(df_holi_train)\n",
        "\n",
        "predicted_holi=model2.predict(df_holi_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMA7LvWwtPGm"
      },
      "source": [
        "**3. Resultados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = model2.plot_components(predicted_holi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Respuesta\n",
        "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
        "df_holi_test['ds'] = pd.to_datetime(df_holi_test['ds'])\n",
        "predicted_holi['ds'] = pd.to_datetime(predicted_holi['ds'])\n",
        "\n",
        "testsize_holi=len(df_holi_test)\n",
        "pred_holi_15=predicted_holi[:int(testsize_holi*0.15)].copy()\n",
        "df_holi_test_15=df_holi_test[:int(testsize_holi*0.15)].copy()\n",
        "pred_holi_50=predicted_holi[:int(testsize_holi*0.5)].copy()\n",
        "df_holi_test_50=df_holi_test[:int(testsize_holi*0.5)].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alinear las predicciones con los datos reales usando merge\n",
        "comparison_df_holi_15 = df_holi_test_15[['ds', 'y']].merge(pred_holi_15[['ds', 'yhat']], on='ds', how='left')\n",
        "\n",
        "# Calcular las métricas de error\n",
        "rmse_holi_15 = root_mean_squared_error(comparison_df_holi_15['y'], comparison_df_holi_15['yhat'])\n",
        "mae_holi_15 = mean_absolute_error(comparison_df_holi_15['y'], comparison_df_holi_15['yhat'])\n",
        "mape_holi_15 = np.mean(np.abs((comparison_df_holi_15['y'] - comparison_df_holi_15['yhat']) / comparison_df_holi_15['y'])) * 100\n",
        "\n",
        "print(f'RMSE: {rmse_holi_15}')\n",
        "print(f'MAE: {mae_holi_15}')\n",
        "print(f'MAPE: {mape_holi_15}%')\n",
        "\n",
        "# Graficar los resultados\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "\n",
        "# Graficar los valores reales\n",
        "ax.plot(comparison_df_holi_15['ds'], comparison_df_holi_15['y'], label='Datos Reales', color='blue')\n",
        "\n",
        "# Graficar las predicciones\n",
        "ax.plot(comparison_df_holi_15['ds'], comparison_df_holi_15['yhat'], label='Pronóstico', color='red')\n",
        "\n",
        "# Configurar etiquetas y título\n",
        "ax.set_xlabel('Fecha')\n",
        "ax.set_ylabel('Valor')\n",
        "ax.set_title('Comparación entre Datos Reales y Pronóstico')\n",
        "ax.legend()\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alinear las predicciones con los datos reales usando merge\n",
        "comparison_df_holi_50 = df_holi_test_50[['ds', 'y']].merge(pred_holi_50[['ds', 'yhat']], on='ds', how='left')\n",
        "\n",
        "# Calcular las métricas de error\n",
        "rmse_holi_50 = root_mean_squared_error(comparison_df_holi_50['y'], comparison_df_holi_50['yhat'])\n",
        "mae_holi_50 = mean_absolute_error(comparison_df_holi_50['y'], comparison_df_holi_50['yhat'])\n",
        "mape_holi_50 = np.mean(np.abs((comparison_df_holi_50['y'] - comparison_df_holi_50['yhat']) / comparison_df_holi_50['y'])) * 100\n",
        "\n",
        "print(f'RMSE: {rmse_holi_50}')\n",
        "print(f'MAE: {mae_holi_50}')\n",
        "print(f'MAPE: {mape_holi_50}%')\n",
        "\n",
        "# Graficar los resultados\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "\n",
        "# Graficar los valores reales\n",
        "ax.plot(comparison_df_holi_50['ds'], comparison_df_holi_50['y'], label='Datos Reales', color='blue')\n",
        "\n",
        "# Graficar las predicciones\n",
        "ax.plot(comparison_df_holi_50['ds'], comparison_df_holi_50['yhat'], label='Pronóstico', color='red')\n",
        "\n",
        "# Configurar etiquetas y título\n",
        "ax.set_xlabel('Fecha')\n",
        "ax.set_ylabel('Valor')\n",
        "ax.set_title('Comparación entre Datos Reales y Pronóstico')\n",
        "ax.legend()\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alinear las predicciones con los datos reales usando merge\n",
        "comparison_df_holi = df_holi_test[['ds', 'y']].merge(predicted_holi[['ds', 'yhat']], on='ds', how='left')\n",
        "\n",
        "# Calcular las métricas de error\n",
        "rmse_holi = root_mean_squared_error(comparison_df_holi['y'], comparison_df_holi['yhat'])\n",
        "mae_holi = mean_absolute_error(comparison_df_holi['y'], comparison_df_holi['yhat'])\n",
        "mape_holi = np.mean(np.abs((comparison_df_holi['y'] - comparison_df_holi['yhat']) / comparison_df_holi['y'])) * 100\n",
        "\n",
        "print(f'RMSE: {rmse_holi}')\n",
        "print(f'MAE: {mae_holi}')\n",
        "print(f'MAPE: {mape_holi}%')\n",
        "\n",
        "# Graficar los resultados\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "\n",
        "# Graficar los valores reales\n",
        "ax.plot(comparison_df_holi['ds'], comparison_df_holi['y'], label='Datos Reales', color='blue')\n",
        "\n",
        "# Graficar las predicciones\n",
        "ax.plot(comparison_df_holi['ds'], comparison_df_holi['yhat'], label='Pronóstico', color='red')\n",
        "\n",
        "# Configurar etiquetas y título\n",
        "ax.set_xlabel('Fecha')\n",
        "ax.set_ylabel('Valor')\n",
        "ax.set_title('Comparación entre Datos Reales y Pronóstico')\n",
        "ax.legend()\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yT4h_ZSCtO61"
      },
      "outputs": [],
      "source": [
        "metrics_values = {\n",
        "    'RMSE': {\n",
        "        'Original': {\n",
        "            '100%': rmse,\n",
        "            '50%': rmse_50,\n",
        "            '15%': rmse_15\n",
        "        },\n",
        "        'Holiday': {\n",
        "            '100%': rmse_holi,\n",
        "            '50%': rmse_holi_50,\n",
        "            '15%': rmse_holi_15\n",
        "        }\n",
        "    },\n",
        "    'MAE': {\n",
        "        'Original': {\n",
        "            '100%': mae,\n",
        "            '50%': mae_50,\n",
        "            '15%': mae_15\n",
        "        },\n",
        "        'Holiday': {\n",
        "            '100%': mae_holi,\n",
        "            '50%': mae_holi_50,\n",
        "            '15%': mae_holi_15\n",
        "        }\n",
        "    },\n",
        "    'MAPE': {\n",
        "        'Original': {\n",
        "            '100%': mape,\n",
        "            '50%': mape_50,\n",
        "            '15%': mape_15\n",
        "        },\n",
        "        'Holiday': {\n",
        "            '100%': mape_holi,\n",
        "            '50%': mape_holi_50,\n",
        "            '15%': mape_holi_15\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Crear DataFrames para cada métrica\n",
        "rmse_df = pd.DataFrame(metrics_values['RMSE'])\n",
        "mae_df = pd.DataFrame(metrics_values['MAE'])\n",
        "mape_df = pd.DataFrame(metrics_values['MAPE'])\n",
        "\n",
        "# Mostrar las matrices de métricas\n",
        "print(\"RMSE:\")\n",
        "print(rmse_df)\n",
        "print(\"\\nMAE:\")\n",
        "print(mae_df)\n",
        "print(\"\\nMAPE:\")\n",
        "print(mape_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tntuocYYt-Ci"
      },
      "source": [
        "¿Son más precisas las predicciones? ¿Qué otro festividad podría afectar a los precios de las frutas y verduras?\n",
        "\n",
        "**Respuesta**\n",
        "Las predicciones son ligeramente más precisas, aunque solo es una diferencia decimal en comparación al modelo sin holidays, es cerca de un 0.2 en RMSE para todos los casos, 0.15 de la misma forma para MAE y para MAPE que es porcentual es cerca de 0.07\n",
        "\n",
        "\n",
        "Con respecto a las fechas o festividades, tal vez podrían afectar fechas conflictivas, como el día del joven combatiente, o el 11 de septiembre estas podrían afectar los precios indirectamente, al alza.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaIZnr-Jyeha"
      },
      "source": [
        "#### **1.5 Regresores adicionales**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82TOv-tIylSU"
      },
      "source": [
        "Don Sergio sabe que la fruta y la verdura tiene temporadas y que por eso hay fechas en que hay ciertas cosas más caras que otras. Además, sabe que este tipo de alimentos sube de precio en invierno, por lo que necesita que tenga en cuenta estas fechas.\n",
        "\n",
        "\n",
        "---\n",
        " Para lograr lo anterior tendrán que:\n",
        " 1. Crear regresor con 1 y 0's según corresponda, para las fechas de invierno. Tomar invierno desde el 21/junio hasta el 21/septiembre de todos los años.\n",
        " 2. Agregar columna con el regresor tanto al dataframe original como al de testeo\n",
        " 3. Entrenar y predecir. Gráficar resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "como el titulo dice adicionales, se supondra que se trabaja sobre el modelo con holidays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRaaTdfpyk9h"
      },
      "outputs": [],
      "source": [
        "# Crear una lista de fechas de invierno para todos los años\n",
        "fechas_invierno = []\n",
        "for year in range(2013, 2022):\n",
        "    fechas_invierno.extend(pd.date_range(start=f'21-06-{year}', end=f'21-09-{year}'))\n",
        "\n",
        "# Convertir la lista de fechas a un DataFrame\n",
        "regresor_invierno_df = pd.DataFrame({\n",
        "    'ds': fechas_invierno,\n",
        "    'invierno': 1  # Asignar 1 para las fechas de invierno\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_holi2=df_holi.copy()\n",
        "df_holi2['ds'] = pd.to_datetime(df_holi2['ds'])\n",
        "df_holi2['mes_dia'] = df_holi2['ds'].dt.strftime('%m-%d')\n",
        "fechas_invierno_mes_dia = regresor_invierno_df['ds'].dt.strftime('%m-%d')\n",
        "df_holi2['invierno'] = df_holi2['mes_dia'].isin(fechas_invierno_mes_dia).astype(int)\n",
        "del df_holi2['mes_dia']\n",
        "\n",
        "df_holi2_train=df_holi2[:int(trainsize*dfsize)].copy()\n",
        "df_holi2_test=df_holi2[int(trainsize*dfsize):].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model3 = Prophet(holidays=fechas_importantes)\n",
        "model3.add_regressor('invierno')\n",
        "model3.fit(df_holi2_train)\n",
        "\n",
        "predicted_holi2=model3.predict(df_holi2_test)\n",
        "\n",
        "fig = model3.plot_components(predicted_holi2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alinear las predicciones con los datos reales usando merge\n",
        "comparison_df_holi2 = df_holi2_test[['ds', 'y']].merge(predicted_holi2[['ds', 'yhat']], on='ds', how='left')\n",
        "\n",
        "# Calcular las métricas de error\n",
        "rmse_holi2 = root_mean_squared_error(comparison_df_holi2['y'], comparison_df_holi2['yhat'])\n",
        "mae_holi2 = mean_absolute_error(comparison_df_holi2['y'], comparison_df_holi2['yhat'])\n",
        "mape_holi2 = np.mean(np.abs((comparison_df_holi2['y'] - comparison_df_holi2['yhat']) / comparison_df_holi2['y'])) * 100\n",
        "\n",
        "print(f'RMSE: {rmse_holi2}')\n",
        "print(f'MAE: {mae_holi2}')\n",
        "print(f'MAPE: {mape_holi2}%')\n",
        "\n",
        "# Graficar los resultados\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "\n",
        "# Graficar los valores reales\n",
        "ax.plot(comparison_df_holi2['ds'], comparison_df_holi2['y'], label='Datos Reales', color='blue')\n",
        "\n",
        "# Graficar las predicciones\n",
        "ax.plot(comparison_df_holi2['ds'], comparison_df_holi2['yhat'], label='Pronóstico', color='red')\n",
        "\n",
        "# Configurar etiquetas y título\n",
        "ax.set_xlabel('Fecha')\n",
        "ax.set_ylabel('Valor')\n",
        "ax.set_title('Comparación entre Datos Reales y Pronóstico')\n",
        "ax.legend()\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al agregar el regresor de la temporada de invierno, se puede observar una leve mejora de las métricas de error, de 0.31 para RMSE, 0.36 para MAE y 0.1 para MAPE, con respecto al  100% de las predicciones del modelo que considera los holiday"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente mencionar que sería interesante poder agregar como fechas a considerar con un regresor aparte, cuando hubo cuarentena total en el país, ya que las principales caídas de los precios coinciden con estas medidas el primer año de pandemia, similar con esto poder considerar los días que se aprobaron los retiros de pensiones en consecuencia de la pandemia, tal vez muestren las subidas repentinas en el conjunto de test. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLZrLUXrKpj1"
      },
      "source": [
        "# **Sistemas de Recomendación (3.0 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-ozzQByLBlc"
      },
      "source": [
        "<center>\n",
        "<img src = \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Shopping_online_with_bank_card.jpg/1024px-Shopping_online_with_bank_card.jpg\" / width = 350>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVsMCiMkqObV"
      },
      "source": [
        "Como no todo en la vida es correr y nutrirse, don Sergio desarrollo el hábito de comprar online y pasa horas y horas en Amazon viendo distintos objetos que le podrían servir, pero no sabe qué comprar, por lo que usted tendrá que ayudarlo a buscar los elementos más comprados por sus amigos para que él también pueda probarlos.\n",
        "\n",
        "---\n",
        "\n",
        "Las tareas a realizar son:\n",
        "\n",
        "1. Limpiar y explorar el dataset.\n",
        "2. Recomendación por Ranking (baseline).\n",
        "3. Recomendación basada en filtros colaborativos por usuarios.\n",
        "4. Recomendaciones basadas en filtros colaborativos por items.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2igMuCgqZjYl",
        "outputId": "5569f165-d989-40d5-9df6-79b4685a24b9"
      },
      "outputs": [],
      "source": [
        "# se instala surprise library\n",
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr2dIkMHFQWs"
      },
      "outputs": [],
      "source": [
        "# Librerias extras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from surprise import accuracy\n",
        "from surprise.reader import Reader\n",
        "from surprise.dataset import Dataset\n",
        "from surprise.prediction_algorithms.knns import KNNBasic\n",
        "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
        "\n",
        "import pandas as pd\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao0e_BVZs8Ss"
      },
      "source": [
        "Los datos presentan las siguientes columnas:\n",
        "* `iderId`: ID único de cada usuario\n",
        "* `productId:` ID único de cada producto\n",
        "* `Rating:` Rating que un usuario le dio a un producto\n",
        "* `timestamp:` Fecha del rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "P-IgbO7q4IHy",
        "outputId": "3336ec60-dbf7-4641-dcdf-e41907b02818"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wszCpxxItD8s",
        "outputId": "697a7c9b-2f59-4964-b524-381bdbe29246"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet('ratings_Electronics.parquet')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoRsl37V70N8",
        "outputId": "ad2d22f9-21a7-4cf0-d429-bde4d7df2b9d"
      },
      "outputs": [],
      "source": [
        "null_count = df.isnull().sum().sum()\n",
        "print('Number of null values:', null_count)\n",
        "print('Size:', df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBBUPWWE8FYI",
        "outputId": "125dbaab-e303-4034-e70e-0339a673786c"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3rzNRXJ9wTM"
      },
      "source": [
        "### **2.1.2 EDA (0.5 puntos)**\n",
        "\n",
        "Habiendo limpiado los datos, generemos un pequeño análisis exploratorio:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOZfN_0sWSk8"
      },
      "source": [
        "Reportar la cantidad de usuarios y productos únicos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImWrtTNRWR3B",
        "outputId": "1924bfe0-5245-4cd4-f0eb-af74d6a02d1f"
      },
      "outputs": [],
      "source": [
        "num_users = df['user_id'].nunique()\n",
        "num_products = df['prod_id'].nunique()\n",
        "\n",
        "print(f\"Cantidad de usuarios únicos: {num_users}\")\n",
        "print(f\"Cantidad de productos únicos: {num_products}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-Ft_fdRCjtE"
      },
      "source": [
        "Verificar que no hayan valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPx1nvEQ97bm",
        "outputId": "1919e10d-11e5-4386-963a-c82d9aeb43da"
      },
      "outputs": [],
      "source": [
        "null_counts = df.isnull().sum()\n",
        "\n",
        "print(\"Cantidad de valores nulos por columna:\")\n",
        "print(null_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84xPAfHd-IRx"
      },
      "source": [
        "Graficar distribución de los ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "RaVW2zIb-Q6Z",
        "outputId": "a90f88b0-255e-4278-c46d-32f58b94317a"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df['rating'], bins=[1, 2, 3, 4, 5, 6], edgecolor='k', alpha=0.7, align='left', rwidth=0.8)\n",
        "plt.title('Distribución de Ratings')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.xticks([1, 2, 3, 4, 5])\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKJ_RtRA-1b2"
      },
      "source": [
        "Reportar las siguientes listas:\n",
        "\n",
        "- Top 5 de usuarios con mayores interacciones\n",
        "- Top 5 de productos con mayores inteacciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkOtAVT---99",
        "outputId": "a09ad4ba-e171-44c4-9a06-8bf77b770808"
      },
      "outputs": [],
      "source": [
        "top_users = df.groupby('user_id')['rating'].count().sort_values(ascending=False).head(5)\n",
        "print(\"Top 5 de usuarios con mayores interacciones:\")\n",
        "print(top_users)\n",
        "\n",
        "top_products = df.groupby('prod_id')['rating'].count().sort_values(ascending=False).head(5)\n",
        "print(\"Top 5 de productos con mayores interacciones:\")\n",
        "print(top_products)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFsUjCpW_AYH"
      },
      "source": [
        "A partir de sus respuestas, escriba al menos 3 conclusiones.\n",
        "\n",
        "Escriba sus observaciones aquí:\n",
        "\n",
        "1. Es importante observar que no existen valores nulos. Estos podrían ser un problema al momento de entrenar modelos.\n",
        "2. El dataset tiene 164 mil filas, y sólo hay 8 mil usuarios y cerca de 7 mil productos. Es decir, cada usuario debe tener muchas interacciones con distintos productos, como se ve en el top 5 hecho.\n",
        "3. Hay una gran tendencia en que los productos estén calificados con 5 estrellas, pues la distribución de rating está concentrado hacia calificaciones más altas. Esto podría ser un problema si es que se busca recomendar productos con cierto puntaje, pues la gran mayoria tiene el puntaje máximo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3Zr0ucXF3r-"
      },
      "source": [
        "## **2.2 Holdout**\n",
        "\n",
        "Con los datos procesados, separe los datos de entrenamiento en train y test asignando 30% de los datos para el conjunto de test. Para replicabilidad de sus respuestas, fije la semilla en `42`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BK91BtkIYvfu"
      },
      "outputs": [],
      "source": [
        "reader = Reader(rating_scale=(0,5))\n",
        "\n",
        "df_collaborative = df[['user_id', 'prod_id', 'rating']].copy() # ordenamos dataset en user, producto, rating (paso clave para trabajar con Surprise)\n",
        "dataset = Dataset.load_from_df(df_collaborative, reader) # generamos Dataset de Surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29uATSF3YWtT",
        "outputId": "aaf6e025-6511-4ed6-9239-7daca600614e"
      },
      "outputs": [],
      "source": [
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "trainset, testset = train_test_split(dataset, test_size=0.3, random_state=42)\n",
        "\n",
        "num_train_ratings = sum(1 for _ in trainset.all_ratings())\n",
        "num_test_ratings = len(testset)\n",
        "print(f\"Tamaño del conjunto de entrenamiento: {num_train_ratings}\")\n",
        "print(f\"Tamaño del conjunto de prueba: {num_test_ratings}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3iQikR9AF2m"
      },
      "source": [
        "## **2.3 Baseline**\n",
        "\n",
        "El objetivo de esta sección es generar un *baseline* en las recomendaciones a partir de una aproximación *dummy* para resolver el problema de recomendación. En particular, se le pide lo siguiente:\n",
        "- Entrenar modelo baseline `NormalPredictor` de `surprise` con los datos de entrenamiento\n",
        "- Generar predicciones usando el modelo entrenado\n",
        "- Evaluar predicciones usando el error cuadrático medio. Entregue una interpretación de su resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "x3oj2gyrB1Fz",
        "outputId": "d238bbe4-6999-4d65-edc2-e4207e8b03d4"
      },
      "outputs": [],
      "source": [
        "from surprise.prediction_algorithms.random_pred import NormalPredictor\n",
        "\n",
        "model = NormalPredictor()\n",
        "model.fit(trainset)\n",
        "predictions = model.test(testset)\n",
        "pd.DataFrame(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC2SE9ZZB6BK",
        "outputId": "1f3b5daa-24fc-46fc-c2a3-510902641afb"
      },
      "outputs": [],
      "source": [
        "# Evaluar con MAE\n",
        "from surprise.accuracy import mae\n",
        "mae(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc5CkAVGGDIy"
      },
      "source": [
        "Un MAE de 0.9919 significa que, en promedio, las predicciones del modelo están a 0.9919 unidades de distancia de los valores reales. Dado que los ratings en el dataset van de 1 a 5, un error promedio de 0.9919 es relativamente bajo, ya que la diferencia máxima posible es de 4 (si alguien predice 1 y el valor real es 5 o viceversa). En términos prácticos, esto significa que si, por ejemplo, un usuario da un rating de 4 a un producto, el modelo, en promedio, predice algo entre aproximadamente 3 y 5 (4 ± 0.9919). Un MAE cercano a 1 indica que el modelo está bastante cerca de los valores reales, pero todavía hay margen para mejorar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhEZGMZ0rShK"
      },
      "source": [
        "## **Filtros Colaborativos Basados en Memoria**\n",
        "\n",
        "A modo de mejorar esta sección, se le pide que implementar filtros colaborativos basados en memoria por medio de algoritmos basados en KNN. En específico, se le pide implementar:\n",
        "- Filtro Colaborativo KNN enfocado en el Usuario\n",
        "- Filtro Colaborativo KNN enfocado en el Producto\n",
        "- Use `KNNBasic` y similitud coseno para ambos modelos\n",
        "\n",
        "Luego **para cada uno de los modelos**, responda:\n",
        "\n",
        "- Obtenga el error cuadrático medio de sus recomendaciones y comente. ¿Qué enfoque tienen un mejor rendimiento? ¿Se alcanza un mejor rendimiento con respecto al Baseline?\n",
        "- Obtenga el rating que le asignaria el usuario `3` al producto `3906`. ¿Son diferentes sus resultados? ¿Porqué?\n",
        "- Obtenga las 5 mejores recomendaciones para el usuario `2170` usando ambos enfoques y compare sus resultados.\n",
        "\n",
        "*Hint: Le podría servir apoyarse de esta [documentación](https://surprise.readthedocs.io/en/stable/prediction_algorithms.html#similarity-measures-configuration).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOlimH3YDujY"
      },
      "outputs": [],
      "source": [
        "def get_user_top_k(predictions, user, k = 10):\n",
        "\n",
        "  # predecir los rating filtrados por usuario user\n",
        "  predicted_ratings = [pred for pred in predictions if pred.uid == user]\n",
        "\n",
        "  # Ordenar las predicciones\n",
        "  sorted_predicted_ratings = sorted(predicted_ratings, key=lambda x: x.est, reverse=True)\n",
        "\n",
        "  return sorted_predicted_ratings[:k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ivAzo0a3_Vr",
        "outputId": "0c1193e4-ed3f-445c-d26e-c208b034c994"
      },
      "outputs": [],
      "source": [
        "from surprise.accuracy import mse\n",
        "\n",
        "# entrenar algoritmo en base a usuario\n",
        "\n",
        "sim_options_user = {'name': 'cosine',\n",
        "               'user_based': True}\n",
        "\n",
        "# algoritmo base a usuario.\n",
        "user_model =  KNNBasic(sim_options=sim_options_user)\n",
        "\n",
        "# entrenar\n",
        "user_model.fit(trainset)\n",
        "\n",
        "#predecir en dataframe de testeo\n",
        "\n",
        "user_predictions =  user_model.test(testset) # retornar un dataframe con el rating estimado para cada (user_id, item_id)\n",
        "\n",
        "# obtener mse\n",
        "mse_user = accuracy.mse(user_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wWHq0_QEhe_",
        "outputId": "d88a8698-2c01-4224-b57d-34f459180281"
      },
      "outputs": [],
      "source": [
        "# ejemplo\n",
        "example = [(3, 3906, None)]\n",
        "print(user_model.test(example))\n",
        "get_user_top_k(user_predictions, user = 2170, k = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z_NJtPVGwYG",
        "outputId": "88c050b1-c275-44f3-988b-ed44c9dd2992"
      },
      "outputs": [],
      "source": [
        "# entrenar algoritmo base a items, obtener MSE\n",
        "\n",
        "sim_options_item = {'name': 'cosine', 'user_based': False}\n",
        "\n",
        "# algoritmo base a items.\n",
        "\n",
        "item_model = KNNBasic(sim_options=sim_options_item)\n",
        "\n",
        "# entrenar\n",
        "item_model.fit(trainset)\n",
        "\n",
        "#predecir en dataframe de testeo\n",
        "\n",
        "item_predictions = item_model.test(testset)\n",
        "\n",
        "# obtener mse\n",
        "mse_item = accuracy.mse(item_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xUtWiuSGeOx",
        "outputId": "d72bb7a8-9c70-4c95-8dc8-076e9991eb8b"
      },
      "outputs": [],
      "source": [
        "example = [(3, 3906, None)]\n",
        "print(item_model.test(example))\n",
        "\n",
        "get_user_top_k(item_predictions, user = 2170, k = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4j4YyBeOMBD"
      },
      "source": [
        "*  En este caso, el MSE más bajo indica un mejor rendimiento, ya que representa una menor discrepancia entre las predicciones del modelo y los valores reales. Dado que el MSE del filtro colaborativo KNN basado en usuario (1.2122) es menor que el MSE del filtro colaborativo KNN basado en ítem (1.2328), podemos concluir que el enfoque basado en usuario tiene un mejor rendimiento en este escenario. Luego, como el MSE del Baseline es menor que los MSE de los modelos KNN, entonces el Baseline tiene un mejor rendimiento.\n",
        "\n",
        "*  Los resultados son diferentes para el mismo usuario y producto entre los enfoques basados en usuario y en ítem. Esto se debe a las diferencias en cómo se calculan las similitudes entre usuarios e ítems y cómo se utilizan esas similitudes para generar predicciones.\n",
        "\n",
        "* Algunos productos recomendados son los mismos en ambos enfoques, como los productos con ID 1326, 2679 y 4650. Sin embargo, el orden de las recomendaciones puede variar. También hay diferencias en los productos recomendados entre los enfoques. Por ejemplo, en el enfoque usuario, el producto con ID 4363 es recomendado, mientras que en el enfoque ítem, el producto con ID 3595 es recomendado. Los ratings estimados para los mismos productos pueden variar entre los enfoques. Por ejemplo, para el producto con ID 1326, el rating estimado es 4.7998 en el enfoque usuario y 5 en el enfoque ítem. Aunque los productos recomendados pueden ser los mismos, los ratings estimados pueden ser diferentes debido a las diferencias en cómo se calculan las predicciones en cada enfoque."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEKzANYNrhKN"
      },
      "source": [
        "## **Filtros Colaborativos Basados en Modelo**\n",
        "\n",
        "Finalmente, se le pide implementar el modelo `SVD` para resolver el problema. Al igual que en las secciones anteriores, entrene este modelo y luego evalúe sus predicciones en el conjunto de test. Luego, responda:\n",
        "\n",
        "- ¿En qué se diferencia este tipo de modelos de los modelos basados en memoria?\n",
        "- ¿Qué significa el parámetro `num_factors`? ¿De qué manera podría impactar en el ajuste del modelo?\n",
        "- ¿Qué indican los parámetros $\\mu$, $b_u$, $b_i$? ¿Qué cuidado se debe tener al utilizarlos?\n",
        "- Obtenga el error cuadrático medio de sus recomendaciones y comente. ¿Se alcanza un mejor rendimiento con respecto al Baseline?\n",
        "- Obtenga el rating que le asignaria el usuario `3` al producto `3906`. ¿Son diferentes sus resultados? ¿Porqué?\n",
        "- Obtenga las 5 mejores recomendaciones para el usuario `2170` usando ambos enfoques y compare sus resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgqwVLs1HQTW"
      },
      "outputs": [],
      "source": [
        "# Respuesta\n",
        "svd_model = SVD()\n",
        "\n",
        "svd_model.fit(trainset)\n",
        "\n",
        "# predicciones, retornar un dataframe con el rating estimado para cada (user_id, item_id)\n",
        "\n",
        "svd_predictions = svd_model.test(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHXiWNZtHaNc",
        "outputId": "3dcbd248-f90c-43e8-8ea4-c3c8a7d09772"
      },
      "outputs": [],
      "source": [
        "# calcular mae\n",
        "from surprise.accuracy import mae\n",
        "mae(svd_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUDV6qHSadex",
        "outputId": "d6700d4b-bee4-4e74-aed4-fed1ab35de89"
      },
      "outputs": [],
      "source": [
        "example = [(3, 3906, None)]\n",
        "print(svd_model.test(example))\n",
        "get_user_top_k(svd_predictions, user = 2170, k = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsqYQPyRXpLq"
      },
      "source": [
        "* Los modelos basados en memoria utilizan medidas de similitud para calcular la similitud entre usuarios o ítems y generar recomendaciones. Además, estos modelos pueden enfrentar problemas de escalabilidad y esparcidad en conjuntos de datos grandes y dispersos, ya que calculan la similitud entre cada par de usuarios o ítems. Por otra parte, los modelos SVD utilizan técnicas de factorización de matrices para aprender patrones latentes en los datos y generar recomendaciones basadas en esos patrones. Las recomendaciones se generan utilizando los factores latentes aprendidos, que pueden ser más abstractos y difíciles de interpretar directamente. Además, Los modelos SVD son más escalables y pueden manejar de manera más efectiva la esparcidad de los datos al factorizar la matriz de interacciones.\n",
        "\n",
        "* El parámetro `num_factors` en el modelo SVD representa el número de factores latentes que el modelo utilizará para representar tanto a los usuarios como a los ítems en el espacio de características latentes. Cada factor latente captura una dimensión abstracta o característica oculta que influye en la interacción entre usuarios e ítems. El impacto del parámetro `num_factors` en el ajuste del modelo es significativo y está relacionado con la capacidad del modelo para capturar la complejidad y las características latentes presentes en los datos de interacción usuario-ítem. Un valor más alto permitirá al modelo capturar más complejidad en los datos, ya que habrá más factores latentes disponibles para modelar las interacciones entre usuarios e ítems. Sin embargo, un valor excesivamente alto puede llevar a un sobreajuste del modelo, especialmente en conjuntos de datos pequeños, donde el modelo puede aprender ruido en lugar de patrones significativos. Un valor demasiado bajo de `num_factors` puede llevar a un modelo simplificado que no puede capturar completamente la estructura latente en los datos, lo que resulta en un rendimiento deficiente en el conjunto de prueba. El número de factores latentes afecta directamente la complejidad computacional del modelo. Cuantos más factores latentes haya, más operaciones computacionales serán necesarias para entrenar y hacer predicciones con el modelo.\n",
        "\n",
        "* $\\mu$ representa la media global de todos los ratings en el conjunto de datos. Es decir, es el promedio de todos los ratings dados por todos los usuarios a todos los ítems. Al utilizar $\\mu$, es importante considerar si se desean centrar los datos o no. Centrar los datos puede ser útil para capturar las desviaciones individuales de la media global, pero también puede eliminar información importante sobre la distribución de los ratings.\n",
        "\n",
        "* $b_u$ representa el sesgo de un usuario específico en sus ratings. Es decir, es la desviación promedio de los ratings dados por un usuario en comparación con la media global $\\mu$. Al utilizar $b_u$, es importante considerar el efecto del sesgo de usuario en el modelo. Un valor de $b_u$ positivo indica que el usuario tiende a dar ratings más altos que la media global, mientras que un valor negativo indica lo contrario.\n",
        "\n",
        "* $b_i$ representa el sesgo de un ítem específico en sus ratings. Es decir, es la desviación promedio de los ratings dados a un ítem en comparación con la media global $\\mu$. Al utilizar $b_i$, es importante considerar el efecto del sesgo de ítem en el modelo. Un valor de $b_i$ positivo indica que el ítem tiende a recibir ratings más altos que la media global, mientras que un valor negativo indica lo contrario.\n",
        "\n",
        "* El modelo SVD tiende a cometer errores de aproximadamente 0.6934 unidades al predecir los ratings de los usuarios en el conjunto de prueba en este caso, po lo que alcanza un mejor rendiminento que el baseline.\n",
        "\n",
        "* Sí, los resultados son diferentes entre el Baseline y el modelo SVD. La predicción para el rating que el usuario 3 asignaría al producto 3906 es aproximadamente 3.0372 según el modelo SVD. La diferencia en los resultados puede deberse a las diferentes aproximaciones y técnicas utilizadas por cada modelo. Por ejemplo, el modelo SVD utiliza una descomposición de valor singular para aprender los patrones latentes en los datos de interacción usuario-ítem.\n",
        "\n",
        "* Aunque hay cierta superposición en los productos recomendados entre los enfoques, las diferencias en los ratings estimados y en el orden de las recomendaciones muestran que los resultados pueden variar según el enfoque utilizado. Esto destaca la importancia de evaluar y comparar múltiples enfoques en sistemas de recomendación para encontrar el más adecuado para un conjunto de datos y un contexto específico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5H52or1WSL7"
      },
      "source": [
        "###**Comentarios Finales**\n",
        "\n",
        "* ¿Qué sistema de recomendación presenta mejores métricas? ¿A qué se podría deber esto?\n",
        "\n",
        "El modelo SVD presenta el MAE más bajo de todos los sistemas de recomendación evaluados. Esto indica que, en promedio, las predicciones del modelo SVD están más cerca de los valores reales en el conjunto de prueba en comparación con los otros sistemas de recomendación. El modelo SVD utiliza una técnica avanzada de factorización de matrices para capturar patrones latentes en los datos de interacción usuario-ítem, lo que puede permitir una mejor comprensión de las preferencias de los usuarios y las características de los ítems. Además, este modelo puede generalizar mejor a partir de los datos de entrenamiento y evitar el sobreajuste en comparación con los filtros colaborativos basados en memoria, lo que puede conducir a un mejor rendimiento en datos no vistos.\n",
        "\n",
        "* ¿Es posible mejorar sus resultados? Si es así, proponga al menos 2 mejoras.\n",
        "\n",
        "Sí, es posible mejorar los resultados del modelo SVD y de otros sistemas de recomendación. El modelo SVD y otros sistemas de recomendación a menudo tienen hiperparámetros que pueden ajustarse para mejorar su rendimiento.\n",
        "Por ejemplo, en el caso del modelo SVD, se puede ajustar `num_factors` para encontrar el valor óptimo que equilibre la complejidad del modelo y su capacidad para capturar patrones en los datos. Además, otros hiperparámetros, como la tasa de aprendizaje y el número de iteraciones en el proceso de optimización, pueden ajustarse para mejorar el rendimiento del modelo.\n",
        "Se podría experimentar con diferentes valores de hiperparámetros y utilizar técnicas de validación cruzada para evaluar el impacto que ocasionan en las métricas de evaluación, y así encontrar la configuración óptima del modelo."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jKJ0AuRJpDa-"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
